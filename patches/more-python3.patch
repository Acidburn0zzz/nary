diff --git i/inary-cli w/inary-cli
index 117980ab..060c3d74 100644
--- i/inary-cli
+++ w/inary-cli
@@ -55,7 +55,7 @@ def handle_exception(exception, value, tb):
         ui.error(_("System error. Program terminated."))
 
     if show_traceback:
-        ui.error("%s: %s" % (exception, str(value)))
+        ui.error("{}: {}".format(exception, str(value)))
     else:
         msg = str(value)
         if msg:
diff --git i/inary/actionsapi/autotools.py w/inary/actionsapi/autotools.py
index a376f931..b59704ba 100644
--- i/inary/actionsapi/autotools.py
+++ w/inary/actionsapi/autotools.py
@@ -37,7 +37,7 @@ class ConfigureError(inary.actionsapi.Error):
         self.value = value
         ctx.ui.error(value)
         if can_access_file('config.log'):
-            ctx.ui.error(_('Please attach the config.log to your bug report:\n%s/config.log') % os.getcwd())
+            ctx.ui.error(_('Please attach the config.log to your bug report:\n{}/config.log').format(os.getcwd()))
 
 class MakeError(inary.actionsapi.Error):
     def __init__(self, value=''):
@@ -65,18 +65,16 @@ def configure(parameters = ''):
 
         prefix = get.emul32prefixDIR() if get.buildTYPE() == "emul32" else get.defaultprefixDIR()
         args = './configure \
-                --prefix=/%s \
-                --build=%s \
-                --mandir=/%s \
-                --infodir=/%s \
-                --datadir=/%s \
-                --sysconfdir=/%s \
-                --localstatedir=/%s \
-                --libexecdir=/%s \
-                %s%s' % (prefix, \
-                         get.HOST(), get.manDIR(), \
-                         get.infoDIR(), get.dataDIR(), \
-                         get.confDIR(), get.localstateDIR(), get.libexecDIR(),
+                --prefix=/{0} \
+                --build={1.HOST()} \
+                --mandir=/{1.manDIR()} \
+                --infodir=/{1.infoDIR()} \
+                --datadir=/{1.dataDIR()} \
+                --sysconfdir=/{1.confDIR()} \
+                --localstatedir=/{1.localstateDIR()} \
+                --libexecdir=/{1.libexecDIR()} \
+                {2}{3}'.format(prefix, \
+                         get,
                          "--libdir=/usr/lib32 " if get.buildTYPE() == "emul32" else "",
                          parameters)
 
@@ -90,29 +88,29 @@ def rawConfigure(parameters = ''):
     if can_access_file('configure'):
         gnuconfig_update()
 
-        if system('./configure %s' % parameters):
+        if system('./configure {}'.format(parameters)):
             raise ConfigureError(_('Configure failed.'))
     else:
         raise ConfigureError(_('No configure script found.'))
 
 def compile(parameters = ''):
-    system('%s %s %s' % (get.CC(), get.CFLAGS(), parameters))
+    system('{0} {1} {2}'.format(get.CC(), get.CFLAGS(), parameters))
 
 def make(parameters = ''):
     '''make source with given parameters = "all" || "doc" etc.'''
-    if system('make %s %s' % (get.makeJOBS(), parameters)):
+    if system('make {0} {1}'.format(get.makeJOBS(), parameters)):
         raise MakeError(_('Make failed.'))
 
 def fixInfoDir():
-    infoDir = '%s/usr/share/info/dir' % get.installDIR()
+    infoDir = '{}/usr/share/info/dir'.format(get.installDIR())
     if can_access_file(infoDir):
         unlink(infoDir)
 
 def fixpc():
     ''' fix .pc files in installDIR()/usr/lib32/pkgconfig'''
-    path = "%s/usr/lib32/pkgconfig" % get.installDIR()
+    path = "{}/usr/lib32/pkgconfig".format(get.installDIR())
     if isDirectory(path):
-        for f in ls("%s/*.pc" % path):
+        for f in ls("{}/*.pc".format(path)):
             dosed(f, get.emul32prefixDIR(), get.defaultprefixDIR())
 
 def install(parameters = '', argument = 'install'):
@@ -143,40 +141,40 @@ def install(parameters = '', argument = 'install'):
 
     if get.buildTYPE() == "emul32":
         fixpc()
-        if isDirectory("%s/emul32" % get.installDIR()): removeDir("/emul32")
+        if isDirectory("{}/emul32".format(get.installDIR())): removeDir("/emul32")
 
 def rawInstall(parameters = '', argument = 'install'):
     '''install source into install directory with given parameters = PREFIX=%s % get.installDIR()'''
-    if system('make %s %s' % (parameters, argument)):
+    if system('make {0} {1}'.format(parameters, argument)):
         raise InstallError(_('Install failed.'))
     else:
         fixInfoDir()
 
     if get.buildTYPE() == "emul32":
         fixpc()
-        if isDirectory("%s/emul32" % get.installDIR()): removeDir("/emul32")
+        if isDirectory("{}/emul32".format(get.installDIR())): removeDir("/emul32")
 
 def aclocal(parameters = ''):
     '''generates an aclocal.m4 based on the contents of configure.in.'''
-    if system('aclocal %s' % parameters):
+    if system('aclocal {}'.format(parameters)):
         raise RunTimeError(_('Running aclocal failed.'))
 
 def autoconf(parameters = ''):
     '''generates a configure script'''
-    if system('autoconf %s' % parameters):
+    if system('autoconf {}'.format(parameters)):
         raise RunTimeError(_('Running autoconf failed.'))
 
 def autoreconf(parameters = ''):
     '''re-generates a configure script'''
-    if system('autoreconf %s' % parameters):
+    if system('autoreconf {}'.format(parameters)):
         raise RunTimeError(_('Running autoreconf failed.'))
 
 def automake(parameters = ''):
     '''generates a makefile'''
-    if system('automake %s' % parameters):
+    if system('automake {}'.format(parameters)):
         raise RunTimeError(_('Running automake failed.'))
 
 def autoheader(parameters = ''):
     '''generates templates for configure'''
-    if system('autoheader %s' % parameters):
+    if system('autoheader {}'.format(parameters)):
         raise RunTimeError(_('Running autoheader failed.'))
diff --git i/inary/actionsapi/cmaketools.py w/inary/actionsapi/cmaketools.py
index ecff1ff8..cc835920 100644
--- i/inary/actionsapi/cmaketools.py
+++ w/inary/actionsapi/cmaketools.py
@@ -33,7 +33,7 @@ class ConfigureError(inary.actionsapi.Error):
         self.value = value
         ctx.ui.error(value)
         if can_access_file('config.log'):
-            ctx.ui.error(_('Please attach the config.log to your bug report:\n%s/config.log') % os.getcwd())
+            ctx.ui.error(_('Please attach the config.log to your bug report:\n{}/config.log').format(os.getcwd()))
 
 class MakeError(inary.actionsapi.Error):
     def __init__(self, value=''):
@@ -53,14 +53,14 @@ class RunTimeError(inary.actionsapi.Error):
         self.value = value
         ctx.ui.error(value)
 
-def configure(parameters = '', installPrefix = '/%s' % get.defaultprefixDIR(), sourceDir = '.'):
+def configure(parameters = '', installPrefix = '/{}'.format(get.defaultprefixDIR()), sourceDir = '.'):
     '''configure source with given cmake parameters = "-DCMAKE_BUILD_TYPE -DCMAKE_CXX_FLAGS ... "'''
     if can_access_file(join_path(sourceDir, 'CMakeLists.txt')):
-        args = 'cmake -DCMAKE_INSTALL_PREFIX=%s \
-                      -DCMAKE_C_FLAGS="%s" \
-                      -DCMAKE_CXX_FLAGS="%s" \
-                      -DCMAKE_LD_FLAGS="%s" \
-                      -DCMAKE_BUILD_TYPE=RelWithDebInfo %s %s' % (installPrefix, get.CFLAGS(), get.CXXFLAGS(), get.LDFLAGS(), parameters, sourceDir)
+        args = 'cmake -DCMAKE_INSTALL_PREFIX={0} \
+                      -DCMAKE_C_FLAGS="{1}" \
+                      -DCMAKE_CXX_FLAGS="{2}" \
+                      -DCMAKE_LD_FLAGS="{3}" \
+                      -DCMAKE_BUILD_TYPE=RelWithDebInfo {4} {5}'.format(installPrefix, get.CFLAGS(), get.CXXFLAGS(), get.LDFLAGS(), parameters, sourceDir)
 
         if system(args):
             raise ConfigureError(_('Configure failed.'))
@@ -70,15 +70,15 @@ def configure(parameters = '', installPrefix = '/%s' % get.defaultprefixDIR(), s
 def make(parameters = ''):
     '''build source with given parameters'''
     if ctx.config.get_option("verbose") and ctx.config.get_option("debug"):
-        command = 'make VERBOSE=1 %s %s' % (get.makeJOBS(), parameters)
+        command = 'make VERBOSE=1 {0} {1}'.format(get.makeJOBS(), parameters)
     else:
-        command = 'make %s %s' % (get.makeJOBS(), parameters)
+        command = 'make {0} {1} '.format(get.makeJOBS(), parameters)
 
     if system(command):
         raise MakeError(_('Make failed.'))
 
 def fixInfoDir():
-    infoDir = '%s/usr/share/info/dir' % get.installDIR()
+    infoDir = '{}/usr/share/info/dir'.format(get.installDIR())
     if can_access_file(infoDir):
         unlink(infoDir)
 
@@ -102,7 +102,7 @@ def install(parameters = '', argument = 'install'):
 def rawInstall(parameters = '', argument = 'install'):
     '''install source into install directory with given parameters = PREFIX=%s % get.installDIR()'''
     if can_access_file('makefile') or can_access_file('Makefile') or can_access_file('GNUmakefile'):
-        if system('make %s %s' % (parameters, argument)):
+        if system('make {} {} '.format(parameters, argument)):
             raise InstallError(_('Install failed.'))
         else:
             fixInfoDir()
diff --git i/inary/actionsapi/get.py w/inary/actionsapi/get.py
index f582a253..773ff2d1 100644
--- i/inary/actionsapi/get.py
+++ w/inary/actionsapi/get.py
@@ -46,7 +46,7 @@ def curKERNEL():
 def curPYTHON():
     ''' returns currently used python's version'''
     (a, b, c, x, y) = sys.version_info
-    return 'python%s.%s' % (a, b)
+    return 'python{0}.{1}'.format(a, b)
 
 def curPERL():
     ''' returns currently used perl's version'''
@@ -92,10 +92,10 @@ def srcRELEASE():
     return env.src_release
 
 def srcTAG():
-    return '%s-%s-%s' % (env.src_name, env.src_version, env.src_release)
+    return '{0}-{1}-{2}'.format(env.src_name, env.src_version, env.src_release)
 
 def srcDIR():
-    return '%s-%s' % (env.src_name, env.src_version)
+    return '{0}-{1}'.format(env.src_name, env.src_version)
 
 # Build Related Functions
 
@@ -175,13 +175,12 @@ def existBinary(bin):
     return False
 
 def getBinutilsInfo(util):
-    cross_build_name = '%s-%s' % (HOST(), util)
+    cross_build_name = '{0}-{1}'.format(HOST(), util)
     if not existBinary(cross_build_name):
         if not existBinary(util):
-            raise BinutilsError(_('Util %s cannot be found') % util)
+            raise BinutilsError(_('Util {} cannot be found').format(util))
         else:
-            ctx.ui.debug(_('Warning: %s does not exist, using plain name %s') \
-                     % (cross_build_name, util))
+            ctx.ui.debug(_('Warning: {0} does not exist, using plain name {1}').format(cross_build_name, util))
             return util
     else:
         return cross_build_name
diff --git i/inary/actionsapi/inarytools.py w/inary/actionsapi/inarytools.py
index ca19541f..a05acb31 100644
--- i/inary/actionsapi/inarytools.py
+++ w/inary/actionsapi/inarytools.py
@@ -77,11 +77,11 @@ def dohtml(*sourceFiles, **kw):
     for sourceFile in sourceFiles:
         sourceFileGlob = glob.glob(sourceFile)
         if len(sourceFileGlob) == 0:
-            raise FileError(_("No file matched pattern \"%s\"") % sourceFile)
+            raise FileError(_("No file matched pattern \"{}\"") % sourceFile)
 
         for source in sourceFileGlob:
             if os.path.isfile(source) and os.path.splitext(source)[1] in allowed_extensions:
-                system('install -m0644 "%s" %s' % (source, destionationDirectory))
+                system('install -m0644 "{0}" {1}'.format(source, destionationDirectory))
             if os.path.isdir(source) and os.path.basename(source) not in disallowed_directories:
                 eraser = os.path.split(source)[0]
                 for root, dirs, files in os.walk(source):
@@ -89,7 +89,7 @@ def dohtml(*sourceFiles, **kw):
                     for sourcename in files:
                         if os.path.splitext(sourcename)[1] in allowed_extensions:
                             makedirs(join_path(destionationDirectory, newRoot))
-                            system('install -m0644 %s %s' % (join_path(root, sourcename), join_path(destionationDirectory, newRoot, sourcename)))
+                            system('install -m0644 {0} {1}'.format(join_path(root, sourcename), join_path(destionationDirectory, newRoot, sourcename)))
 
 def doinfo(*sourceFiles):
     '''inserts the into files in the list of files into /usr/share/info'''
@@ -126,7 +126,7 @@ def dolib_so(sourceFile, destinationDirectory = '/usr/lib'):
 def doman(*sourceFiles):
     '''inserts the man pages in the list of files into /usr/share/man/'''
 
-    '''example call: inarytools.doman("man.1", "pardus.*")'''
+    '''example call: inarytools.doman("man.1", "sulin.*")'''
     manDIR = join_path(get.installDIR(), get.manDIR())
     if not can_access_directory(manDIR):
         makedirs(manDIR)
@@ -134,7 +134,7 @@ def doman(*sourceFiles):
     for sourceFile in sourceFiles:
         sourceFileGlob = glob.glob(sourceFile)
         if len(sourceFileGlob) == 0:
-            raise FileError(_("No file matched pattern \"%s\"") % sourceFile)
+            raise FileError(_("No file matched pattern \"{}\"").format(sourceFile))
 
         for source in sourceFileGlob:
             compressed = source.endswith("gz") and source
@@ -144,12 +144,12 @@ def doman(*sourceFiles):
                 pageName, pageDirectory = source[:source.rindex('.')], \
                                           source[source.rindex('.')+1:]
             except ValueError:
-                error(_('ActionsAPI [doman]: Wrong man page file: %s') % (source))
+                error(_('ActionsAPI [doman]: Wrong man page file: {}').format(source))
 
-            manPDIR = join_path(manDIR, '/man%s' % pageDirectory)
+            manPDIR = join_path(manDIR, '/man{}'.format(pageDirectory))
             makedirs(manPDIR)
             if not compressed:
-                system('install -m0644 %s %s' % (source, manPDIR))
+                system('install -m0644 {} {}'.format(source, manPDIR))
             else:
                 uncompress(compressed, targetDir=manPDIR)
 
@@ -158,9 +158,9 @@ def domo(sourceFile, locale, destinationFile, localeDirPrefix = '/usr/share/loca
 
     '''example call: inarytools.domo("po/tr.po", "tr", "pam_login.mo")'''
 
-    system('msgfmt %s' % sourceFile)
-    makedirs('%s%s/%s/LC_MESSAGES/' % (get.installDIR(), localeDirPrefix, locale))
-    move('messages.mo', '%s%s/%s/LC_MESSAGES/%s' % (get.installDIR(), localeDirPrefix, locale, destinationFile))
+    system('msgfmt {}'.format(sourceFile))
+    makedirs('{0}{1}/{2}/LC_MESSAGES/'.format(get.installDIR(), localeDirPrefix, locale))
+    move('messages.mo', '{0}{1}/{2}/LC_MESSAGES/{3}'.format(get.installDIR(), localeDirPrefix, locale, destinationFile))
 
 def domove(sourceFile, destination, destinationFile = ''):
     '''moves sourceFile/Directory into destinationFile/Directory'''
@@ -171,7 +171,7 @@ def domove(sourceFile, destination, destinationFile = ''):
 
     sourceFileGlob = glob.glob(join_path(get.installDIR(), sourceFile))
     if len(sourceFileGlob) == 0:
-        raise FileError(_("No file matched pattern \"%s\". 'domove' operation failed.") % sourceFile)
+        raise FileError(_("No file matched pattern \"{}\". 'domove' operation failed.").format(sourceFile))
 
     for filePath in sourceFileGlob:
         if not destinationFile:
@@ -190,7 +190,7 @@ def rename(sourceFile, destinationFile):
     try:
         os.rename(join_path(get.installDIR(), sourceFile), join_path(get.installDIR(), baseDir, destinationFile))
     except OSError as e:
-        error(_('ActionsAPI [rename]: %s: %s') % (e, sourceFile))
+        error(_('ActionsAPI [rename]: {}: {}').format(e, sourceFile))
 
 def dosed(sources, findPattern, replacePattern = '', filePattern = '', deleteLine = False, level = -1):
     '''replaces patterns in sources'''
@@ -212,7 +212,7 @@ def dosed(sources, findPattern, replacePattern = '', filePattern = '', deleteLin
             if not level == -1 and currentLevel > level: continue
             for f in files:
                 if re.search(pattern, f):
-                    res.append("%s/%s" % (root, f))
+                    res.append("{0}/{1}".format(root, f))
         return res
 
     backupExtension = ".inary-backup"
@@ -227,11 +227,11 @@ def dosed(sources, findPattern, replacePattern = '', filePattern = '', deleteLin
 
     #if there is no match, raise exception
     if len(sourceFiles) == 0:
-        raise FileError(_('No such file matching pattern: "%s". \'dosed\' operation failed.') % filePattern if filePattern else sources)
+        raise FileError(_('No such file matching pattern: "{}". \'dosed\' operation failed.').format(filePattern if filePattern else sources))
 
     for sourceFile in sourceFiles:
         if can_access_file(sourceFile):
-            backupFile = "%s%s" % (sourceFile, backupExtension)
+            backupFile = "{0}{1}".format(sourceFile, backupExtension)
             for line in fileinput.input(sourceFile, inplace = 1, backup = backupExtension):
                 #FIXME: In-place filtering is disabled when standard input is read
                 if re.search(findPattern, line):
@@ -241,11 +241,11 @@ def dosed(sources, findPattern, replacePattern = '', filePattern = '', deleteLin
                 # By default, filecmp.cmp() compares two files by looking file sizes.
                 # shallow=False tells cmp() to look file content.
                 if filecmp.cmp(sourceFile, backupFile, shallow=False):
-                    ctx.ui.warning(_('dosed method has not changed file \'%s\'.') % sourceFile)
-                else: ctx.ui.info("%s has been changed by dosed method." % sourceFile, verbose=True)
+                    ctx.ui.warning(_('dosed method has not changed file \'{}\'.').format(sourceFile))
+                else: ctx.ui.info(_("{} has been changed by dosed method.").format(sourceFile), verbose=True)
                 os.unlink(backupFile)
         else:
-            raise FileError(_('File does not exist or permission denied: %s') % sourceFile)
+            raise FileError(_('File does not exist or permission denied: {}').format(sourceFile))
 
 def dosbin(sourceFile, destinationDirectory = '/usr/sbin'):
     '''insert a executable file into /sbin or /usr/sbin'''
@@ -262,7 +262,7 @@ def dosym(sourceFile, destinationFile):
     try:
         os.symlink(sourceFile, join_path(get.installDIR() ,destinationFile))
     except OSError:
-        error(_('ActionsAPI [dosym]: File already exists: %s') % (destinationFile))
+        error(_('ActionsAPI [dosym]: File already exists: {}').format(destinationFile))
 
 def insinto(destinationDirectory, sourceFile,  destinationFile = '', sym = True):
     '''insert a sourceFile into destinationDirectory as a destinationFile with same uid/guid/permissions'''
@@ -271,7 +271,7 @@ def insinto(destinationDirectory, sourceFile,  destinationFile = '', sym = True)
     if not destinationFile:
         sourceFileGlob = glob.glob(sourceFile)
         if len(sourceFileGlob) == 0:
-            raise FileError(_("No file matched pattern \"%s\".") % sourceFile)
+            raise FileError(_("No file matched pattern \"{}\".").format(sourceFile))
 
         for filePath in sourceFileGlob:
             if can_access_file(filePath):
@@ -298,7 +298,7 @@ def remove(sourceFile):
     '''removes sourceFile'''
     sourceFileGlob = glob.glob(join_path(get.installDIR(), sourceFile))
     if len(sourceFileGlob) == 0:
-        raise FileError(_("No file matched pattern \"%s\". Remove operation failed.") % sourceFile)
+        raise FileError(_("No file matched pattern \"{}\". Remove operation failed.").format(sourceFile))
 
     for filePath in sourceFileGlob:
         unlink(filePath)
@@ -307,7 +307,7 @@ def removeDir(destinationDirectory):
     '''removes destinationDirectory and its subtrees'''
     destdirGlob = glob.glob(join_path(get.installDIR(), destinationDirectory))
     if len(destdirGlob) == 0:
-        raise FileError(_("No directory matched pattern \"%s\". Remove directory operation failed.") % destinationDirectory)
+        raise FileError(_("No directory matched pattern \"{}\". Remove directory operation failed.").format(destinationDirectory))
 
     for directory in destdirGlob:
         unlinkDir(directory)
diff --git i/inary/actionsapi/inarytoolsfunctions.py w/inary/actionsapi/inarytoolsfunctions.py
index 915c0ec5..25df8ea2 100644
--- i/inary/actionsapi/inarytoolsfunctions.py
+++ w/inary/actionsapi/inarytoolsfunctions.py
@@ -50,11 +50,11 @@ def executable_insinto(destinationDirectory, *sourceFiles):
     for sourceFile in sourceFiles:
         sourceFileGlob = glob.glob(sourceFile)
         if len(sourceFileGlob) == 0:
-            raise FileError(_("No executable file matched pattern \"%s\".") % sourceFile)
+            raise FileError(_("No executable file matched pattern \"{}\".").format(sourceFile))
 
         for source in sourceFileGlob:
             # FIXME: use an internal install routine for these
-            system('install -m0755 -o root -g root %s %s' % (source, destinationDirectory))
+            system('install -m0755 -o root -g root {0} {1}'.format(source, destinationDirectory))
 
 def readable_insinto(destinationDirectory, *sourceFiles):
     '''inserts file list into destinationDirectory'''
@@ -68,10 +68,10 @@ def readable_insinto(destinationDirectory, *sourceFiles):
     for sourceFile in sourceFiles:
         sourceFileGlob = glob.glob(sourceFile)
         if len(sourceFileGlob) == 0:
-            raise FileError(_("No file matched pattern \"%s\".") % sourceFile)
+            raise FileError(_("No file matched pattern \"{}\".").format(sourceFile))
 
         for source in sourceFileGlob:
-            system('install -m0644 "%s" %s' % (source, destinationDirectory))
+            system('install -m0644 "{0}" {1}'.format(source, destinationDirectory))
 
 def lib_insinto(sourceFile, destinationDirectory, permission = 0o644):
     '''inserts a library fileinto destinationDirectory with given permission'''
@@ -85,4 +85,4 @@ def lib_insinto(sourceFile, destinationDirectory, permission = 0o644):
     if os.path.islink(sourceFile):
         os.symlink(os.path.realpath(sourceFile), os.path.join(destinationDirectory, sourceFile))
     else:
-        system('install -m0%o %s %s' % (permission, sourceFile, destinationDirectory))
+        system('install -m0{0} {1} {2}'.format(permission, sourceFile, destinationDirectory))
diff --git i/inary/actionsapi/kde.py w/inary/actionsapi/kde.py
index 6aba00a9..80f314de 100644
--- i/inary/actionsapi/kde.py
+++ w/inary/actionsapi/kde.py
@@ -31,7 +31,7 @@ class ConfigureError(inary.actionsapi.Error):
         self.value = value
         ctx.ui.error(value)
         if can_access_file('config.log'):
-            ctx.ui.error(_('\n!!! Please attach the config.log to your bug report:\n%s/config.log') % os.getcwd())
+            ctx.ui.error(_('\n!!! Please attach the config.log to your bug report:\n{}/config.log').format(os.getcwd()))
 
 class MakeError(inary.actionsapi.Error):
     def __init__(self, value=''):
@@ -49,17 +49,17 @@ def configure(parameters = ''):
     ''' parameters = '--with-nls --with-libusb --with-something-usefull '''
     if can_access_file('configure'):
         args = './configure \
-                --prefix=%s \
-                --build=%s \
+                --prefix={0.kdeDIR()} \
+                --build={0.HOST()} \
                 --with-x \
                 --enable-mitshm \
                 --with-xinerama \
-                --with-qt-dir=%s \
+                --with-qt-dir={0.qtDIR()} \
                 --enable-mt \
-                --with-qt-libraries=%s/lib \
+                --with-qt-libraries={0.qtDIR}/lib \
                 --disable-dependency-tracking \
                 --disable-debug \
-                %s' % (get.kdeDIR(), get.HOST(), get.qtDIR(), get.qtDIR(), parameters)
+                {1}'.format(get, parameters)
 
         if system(args):
             raise ConfigureError(_('Configure failed.'))
@@ -68,12 +68,12 @@ def configure(parameters = ''):
 
 def make(parameters = ''):
     '''make source with given parameters = "all" || "doc" etc.'''
-    if system('make %s %s' % (get.makeJOBS(), parameters)):
+    if system('make {0} {1}'.format(get.makeJOBS(), parameters)):
         raise MakeError(_('Make failed.'))
 
 def install(parameters = 'install'):
     if can_access_file('Makefile'):
-        args = 'make DESTDIR=%s destdir=%s %s' % (get.installDIR(), get.installDIR(), parameters)
+        args = 'make DESTDIR={0} destdir={0} {1}'.format(get.installDIR(), parameters)
 
         if system(args):
             raise InstallError(_('Install failed.'))
diff --git i/inary/actionsapi/kde4.py w/inary/actionsapi/kde4.py
index 00eb5ff0..ea56f645 100644
--- i/inary/actionsapi/kde4.py
+++ w/inary/actionsapi/kde4.py
@@ -16,24 +16,24 @@ from inary.actionsapi import shelltools
 
 basename = "kde4"
 
-prefix = "/%s" % get.defaultprefixDIR()
-libdir = "%s/lib" % prefix
-bindir = "%s/bin" % prefix
-modulesdir = "%s/%s" % (libdir, basename)
-libexecdir = "%s/libexec" % modulesdir
-iconsdir = "%s/share/icons" % prefix
-applicationsdir = "%s/share/applications/%s" % (prefix, basename)
-mandir = "/%s" % get.manDIR()
-sharedir = "%s/share/%s" % (prefix, basename)
-appsdir = "%s/apps" % sharedir
-configdir = "%s/config" % sharedir
+prefix = "/{}".format(get.defaultprefixDIR())
+libdir = "{}/lib".format(prefix)
+bindir = "{}/bin".format(prefix)
+modulesdir = "{0}/{1}".format(libdir, basename)
+libexecdir = "{}/libexec".format(modulesdir)
+iconsdir = "{}/share/icons".format(prefix)
+applicationsdir = "{0}/share/applications/{1}".format(prefix, basename)
+mandir = "/{}" % get.manDIR()
+sharedir = "{0}/share/{1}".format(prefix, basename)
+appsdir = "{}/apps".format(sharedir)
+configdir = "{}/config".format(sharedir)
 sysconfdir= "/etc"
-servicesdir = "%s/services" % sharedir
-servicetypesdir = "%s/servicetypes" % sharedir
-includedir = "%s/include/%s" % (prefix, basename)
-docdir = "/%s/%s" % (get.docDIR(), basename)
-htmldir = "%s/html" % docdir
-wallpapersdir = "%s/share/wallpapers" % prefix
+servicesdir = "{}/services".format(sharedir)
+servicetypesdir = "{}/servicetypes".format(sharedir)
+includedir = "{0}/include/{1}".format(prefix, basename)
+docdir = "/{0}/{1}".format(get.docDIR(), basename)
+htmldir = "{}/html".format(docdir)
+wallpapersdir = "{}/share/wallpapers".format(prefix)
 
 def configure(parameters = '', installPrefix = prefix, sourceDir = '..'):
     ''' parameters -DLIB_INSTALL_DIR="hede" -DSOMETHING_USEFUL=1'''
@@ -41,20 +41,20 @@ def configure(parameters = '', installPrefix = prefix, sourceDir = '..'):
     shelltools.makedirs("build")
     shelltools.cd("build")
 
-    cmaketools.configure("-DDATA_INSTALL_DIR:PATH=%s \
-            -DINCLUDE_INSTALL_DIR:PATH=%s \
-            -DCONFIG_INSTALL_DIR:PATH=%s \
-            -DLIBEXEC_INSTALL_DIR:PATH=%s \
-            -DSYSCONF_INSTALL_DIR:PATH=%s \
-            -DHTML_INSTALL_DIR:PATH=%s \
-            -DMAN_INSTALL_DIR:PATH=%s \
+    cmaketools.configure("-DDATA_INSTALL_DIR:PATH={0} \
+            -DINCLUDE_INSTALL_DIR:PATH={1} \
+            -DCONFIG_INSTALL_DIR:PATH={2} \
+            -DLIBEXEC_INSTALL_DIR:PATH={3} \
+            -DSYSCONF_INSTALL_DIR:PATH={4} \
+            -DHTML_INSTALL_DIR:PATH={5} \
+            -DMAN_INSTALL_DIR:PATH={6} \
             -DCMAKE_SKIP_RPATH:BOOL=ON \
-            -DLIB_INSTALL_DIR:PATH=%s %s" % (appsdir, includedir, configdir, libexecdir, sysconfdir, htmldir, mandir, libdir, parameters), installPrefix, sourceDir)
+            -DLIB_INSTALL_DIR:PATH={7} {8}".format(appsdir, includedir, configdir, libexecdir, sysconfdir, htmldir, mandir, libdir, parameters), installPrefix, sourceDir)
 
     shelltools.cd("..")
 
 def make(parameters = ''):
-    cmaketools.make('-C build %s' % parameters)
+    cmaketools.make('-C build {}'.format(parameters))
 
 def install(parameters = '', argument = 'install'):
-    cmaketools.install('-C build %s' % parameters, argument)
+    cmaketools.install('-C build {}'.format(parameters), argument)
diff --git i/inary/actionsapi/kerneltools.py w/inary/actionsapi/kerneltools.py
index bd9d28c5..3a226d68 100644
--- i/inary/actionsapi/kerneltools.py
+++ w/inary/actionsapi/kerneltools.py
@@ -73,7 +73,7 @@ def __getSuffix():
     """Read and return the value read from .suffix file."""
     suffix = get.srcVERSION()
     if __getFlavour():
-        suffix += "-%s" % __getFlavour()
+        suffix += "-{}".format(__getFlavour())
     return suffix
 
 def __getExtraVersion():
@@ -89,7 +89,7 @@ def __getExtraVersion():
 
     # Append pae, default, rt, etc. to the extraversion if available
     if __getFlavour():
-        extraversion += "-%s" % __getFlavour()
+        extraversion += "-{}".format(__getFlavour())
 
     return extraversion
 
@@ -114,22 +114,22 @@ def getKernelVersion(flavour=None):
         return open(kverfile, "r").read().strip()
     else:
         # Fail
-        raise ConfigureError(_("Can't find kernel version information file %s.") % kverfile)
+        raise ConfigureError(_("Can't find kernel version information file {}.").format(kverfile))
 
 def configure():
     # Copy the relevant configuration file
-    shutil.copy("configs/kernel-%s-config" % get.ARCH(), ".config")
+    shutil.copy("configs/kernel-{}-config".format(get.ARCH()), ".config")
 
     # Set EXTRAVERSION
-    inarytools.dosed("Makefile", "EXTRAVERSION =.*", "EXTRAVERSION = %s" % __getExtraVersion())
+    inarytools.dosed("Makefile", "EXTRAVERSION =.*", "EXTRAVERSION = {}".format(__getExtraVersion()))
 
     # Configure the kernel interactively if
     # configuration contains new options
-    autotools.make("ARCH=%s oldconfig" % __getKernelARCH())
+    autotools.make("ARCH={} oldconfig".format(__getKernelARCH()))
 
     # Check configuration with listnewconfig
     try:
-        autotools.make("ARCH=%s listnewconfig" % __getKernelARCH())
+        autotools.make("ARCH={} listnewconfig".format(__getKernelARCH()))
     except:
         pass
 
@@ -152,7 +152,7 @@ def build(debugSymbols=False):
         # Enable debugging symbols (-g -gdwarf2)
         extra_config.append("CONFIG_DEBUG_INFO=y")
 
-    autotools.make("ARCH=%s %s" % (__getKernelARCH(), " ".join(extra_config)))
+    autotools.make("ARCH={0} {1}".format(__getKernelARCH(), " ".join(extra_config)))
 
 
 def install():
@@ -162,26 +162,26 @@ def install():
     dumpVersion()
 
     # Install kernel image
-    inarytools.insinto("/boot/", "arch/x86/boot/bzImage", "kernel-%s" % suffix)
+    inarytools.insinto("/boot/", "arch/x86/boot/bzImage", "kernel-{}".formar(suffix))
 
     # Install the modules
     # mod-fw= avoids firmwares from installing
     # Override DEPMOD= to not call depmod as it will be called
     # during module-init-tools' package handler
-    autotools.rawInstall("INSTALL_MOD_PATH=%s/" % get.installDIR(),
+    autotools.rawInstall("INSTALL_MOD_PATH={}/".format(get.installDIR()),
                          "DEPMOD=/bin/true modules_install mod-fw=")
 
     # Remove symlinks first
-    inarytools.remove("/lib/modules/%s/source" % suffix)
-    inarytools.remove("/lib/modules/%s/build" % suffix)
+    inarytools.remove("/lib/modules/{}/source".format(suffix))
+    inarytools.remove("/lib/modules/{}/build".format(suffix))
 
     # Install Module.symvers and System.map here too
-    shutil.copy("Module.symvers", "%s/lib/modules/%s/" % (get.installDIR(), suffix))
-    shutil.copy("System.map", "%s/lib/modules/%s/" % (get.installDIR(), suffix))
+    shutil.copy("Module.symvers", "{0}/lib/modules/{1}/".format(get.installDIR(), suffix))
+    shutil.copy("System.map", "{0}/lib/modules/{1}/".format(get.installDIR(), suffix))
 
     # Create extra/ and updates/ subdirectories
     for _dir in ("extra", "updates"):
-        inarytools.dodir("/lib/modules/%s/%s" % (suffix, _dir))
+        inarytools.dodir("/lib/modules/{0}/{1}".format(suffix, _dir))
 
 
 def installHeaders(extraHeaders=None):
@@ -199,58 +199,57 @@ def installHeaders(extraHeaders=None):
     wanted = ["Makefile*", "Kconfig*", "Kbuild*", "*.sh", "*.pl", "*.lds"]
 
     suffix = __getSuffix()
-    headersDirectoryName = "usr/src/linux-headers-%s" % suffix
+    headersDirectoryName = "usr/src/linux-headers-{}".format(suffix)
 
     # Get the destination directory for header installation
     destination = os.path.join(get.installDIR(), headersDirectoryName)
     shelltools.makedirs(destination)
 
     # First create the skel
-    find_cmd = "find . -path %s -prune -o -type f \( -name %s \) -print" % \
-                (
-                    " -prune -o -path ".join(["'./%s/*'" % l for l in pruned]),
-                    " -o -name ".join(["'%s'" % k for k in wanted])
-                ) + " | cpio -pVd --preserve-modification-time %s" % destination
+    find_cmd = "find . -path {0} -prune -o -type f \( -name {1} \) -print".format(
+                    " -prune -o -path ".join(["'./{}/*'".format(l for l in pruned)]),
+                    " -o -name ".join(["'{}'".format(k for k in wanted)])
+                ) + " | cpio -pVd --preserve-modification-time {}".format(destination)
 
     shelltools.system(find_cmd)
 
     # Install additional headers
     for headers in extras:
-        shelltools.system("cp -a %s/*.h %s/%s" % (headers, destination, headers))
+        shelltools.system("cp -a {0}/*.h {1}/{2}".format(headers, destination, headers))
 
     # Install remaining headers
-    shelltools.system("cp -a %s %s" % (" ".join(pruned), destination))
+    shelltools.system("cp -a {0} {1}".format(" ".join(pruned), destination))
 
     # Cleanup directories
-    shelltools.system("rm -rf %s/scripts/*.o" % destination)
-    shelltools.system("rm -rf %s/scripts/*/*.o" % destination)
-    shelltools.system("rm -rf %s/Documentation/DocBook" % destination)
+    shelltools.system("rm -rf {}/scripts/*.o".format(destination))
+    shelltools.system("rm -rf {}/scripts/*/*.o".format(destination))
+    shelltools.system("rm -rf {}/Documentation/DocBook".format(destination))
 
     # Finally copy the include directories found in arch/
     shelltools.system("(find arch -name include -type d -print | \
                         xargs -n1 -i: find : -type f) | \
-                        cpio -pd --preserve-modification-time %s" % destination)
+                        cpio -pd --preserve-modification-time {}".format(destination))
 
     # Copy Modules.symvers and System.map
-    shutil.copy("Module.symvers", "%s/" % destination)
-    shutil.copy("System.map", "%s/" % destination)
+    shutil.copy("Module.symvers", "{}/".format(destination))
+    shutil.copy("System.map", "{}/".format(destination))
 
     # Copy .config file which will be needed by some external modules
-    shutil.copy(".config", "%s/" % destination)
+    shutil.copy(".config", "{}/".format(destination))
 
     # Settle the correct build symlink to this headers
-    inarytools.dosym("/%s" % headersDirectoryName, "/lib/modules/%s/build" % suffix)
-    inarytools.dosym("build", "/lib/modules/%s/source" % suffix)
+    inarytools.dosym("/{}".format(headersDirectoryName), "/lib/modules/{}/build".format(suffix))
+    inarytools.dosym("build", "/lib/modules/{}/source".format(suffix))
 
 
 def installLibcHeaders(excludes=None):
     headers_tmp = os.path.join(get.installDIR(), 'tmp-headers')
     headers_dir = os.path.join(get.installDIR(), 'usr/include')
 
-    make_cmd = "O=%s INSTALL_HDR_PATH=%s/install" % (headers_tmp, headers_tmp)
+    make_cmd = "O={0} INSTALL_HDR_PATH={0}/install".format(headers_tmp)
 
     # Cleanup temporary header directory
-    shelltools.system("rm -rf %s" % headers_tmp)
+    shelltools.system("rm -rf {}".format(headers_tmp))
 
     # Create directories
     shelltools.makedirs(headers_tmp)
@@ -258,33 +257,33 @@ def installLibcHeaders(excludes=None):
     
     ###################Workaround begins here ...
     #Workaround information -- http://patches.openembedded.org/patch/33433/
-    cpy_src="%s/linux-*/arch/x86/include/generated" % (get.workDIR())
-    cpy_tgt="%s/arch/x86/include" % (headers_tmp)
+    cpy_src="{}/linux-*/arch/x86/include/generated".format(get.workDIR())
+    cpy_tgt="{}/arch/x86/include".format(headers_tmp)
     shelltools.makedirs(cpy_tgt)
-    
-    copy_cmd ="cp -Rv %s %s " % (cpy_src, cpy_tgt)
-    
+
+    copy_cmd ="cp -Rv {0} {1} ".format(cpy_src, cpy_tgt)
+
     shelltools.system(copy_cmd)
     #######################Workaround ends here ...
-    
+
     # make defconfig and install the headers
-    autotools.make("%s defconfig" % make_cmd)
+    autotools.make("{} defconfig".format(make_cmd))
     autotools.rawInstall(make_cmd, "headers_install")
 
     oldwd = os.getcwd()
 
     shelltools.cd(os.path.join(headers_tmp, "install", "include"))
     shelltools.system("find . -name '.' -o -name '.*' -prune -o -print | \
-                       cpio -pVd --preserve-modification-time %s" % headers_dir)
+                       cpio -pVd --preserve-modification-time {}".format(headers_dir))
 
     # Remove sound/ directory which is installed by alsa-headers
-    shelltools.system("rm -rf %s/sound" % headers_dir)
+    shelltools.system("rm -rf {}/sound".format(headers_dir))
 
     # Remove possible excludes given by actions.py
     if excludes:
-        shelltools.system("rm -rf %s" % " ".join(["%s/%s" % (headers_dir, exc.strip("/")) for exc in excludes]))
+        shelltools.system("rm -rf {}" .format(" ".join(["{0}/{1}".format(headers_dir, exc.strip("/")) for exc in excludes])))
 
     shelltools.cd(oldwd)
 
     # Remove tmp directory
-    shelltools.system("rm -rf %s" % headers_tmp)
+    shelltools.system("rm -rf {}".format(headers_tmp))
diff --git i/inary/actionsapi/libtools.py w/inary/actionsapi/libtools.py
index d274a94a..99613d7e 100644
--- i/inary/actionsapi/libtools.py
+++ w/inary/actionsapi/libtools.py
@@ -34,7 +34,7 @@ class RunTimeError(inary.actionsapi.Error):
 def preplib(sourceDirectory = '/usr/lib'):
     sourceDirectory = join_path(get.installDIR(), sourceDirectory)
     if can_access_directory(sourceDirectory):
-        if system('/sbin/ldconfig -n -N %s' % sourceDirectory):
+        if system('/sbin/ldconfig -n -N {}'.format(sourceDirectory)):
             raise RunTimeError(_('Running ldconfig failed.'))
 
 def gnuconfig_update():
@@ -47,21 +47,21 @@ def gnuconfig_update():
                     unlink(targetFile)
 
                 try:
-                    copy('/usr/share/gnuconfig/%s' % fileName, join_path(root, fileName))
+                    copy('/usr/share/gnuconfig/{}'.format(fileName), join_path(root, fileName))
                 except:
                     ctx.ui.info(_('Can not make GNU Config Update... Passing...'))
                 else:
                     ctx.ui.info(_('GNU Config Update Finished.'))
 
 def libtoolize(parameters = ''):
-    if system('/usr/bin/libtoolize %s' % parameters):
+    if system('/usr/bin/libtoolize {}'.format(parameters)):
         raise RunTimeError(_('Running libtoolize failed.'))
 
 def gen_usr_ldscript(dynamicLib):
 
-    makedirs('%s/usr/lib' % get.installDIR())
+    makedirs('{}/usr/lib'.format(get.installDIR()))
 
-    destinationFile = open('%s/usr/lib/%s' % (get.installDIR(), dynamicLib), 'w')
+    destinationFile = open('{0}/usr/lib/{1}'.format(get.installDIR(), dynamicLib), 'w')
     content = '''
 /* GNU ld script
     Since Pardus has critical dynamic libraries
@@ -69,9 +69,9 @@ def gen_usr_ldscript(dynamicLib):
     we need to have a "fake" dynamic lib in /usr/lib,
     otherwise we run into linking problems.
 */
-GROUP ( /lib/%s )
-''' % dynamicLib
+GROUP ( /lib/{} )
+'''.format(dynamicLib)
 
     destinationFile.write(content)
     destinationFile.close()
-    chmod('%s/usr/lib/%s' % (get.installDIR(), dynamicLib))
+    chmod('{0}/usr/lib/{1}'.format(get.installDIR(), dynamicLib))
diff --git i/inary/actionsapi/perlmodules.py w/inary/actionsapi/perlmodules.py
index 468816d7..598a714c 100644
--- i/inary/actionsapi/perlmodules.py
+++ w/inary/actionsapi/perlmodules.py
@@ -51,25 +51,25 @@ def configure(parameters = ''):
     '''configure source with given parameters.'''
     export('PERL_MM_USE_DEFAULT', '1')
     if can_access_file('Build.PL'):
-        if system('perl Build.PL installdirs=vendor destdir=%s' % get.installDIR()):
+        if system('perl Build.PL installdirs=vendor destdir={}'.format(get.installDIR())):
             raise ConfigureError(_('Configure failed.'))
     else:
-        if system('perl Makefile.PL %s PREFIX=/usr INSTALLDIRS=vendor DESTDIR=%s' % (parameters, get.installDIR())):
+        if system('perl Makefile.PL {0} PREFIX=/usr INSTALLDIRS=vendor DESTDIR={1}'.format(parameters, get.installDIR())):
             raise ConfigureError(_('Configure failed.'))
 
 def make(parameters = ''):
     '''make source with given parameters.'''
     if can_access_file('Makefile'):
-        if system('make %s' % parameters):
+        if system('make {}'.format(parameters)):
             raise MakeError(_('Make failed.'))
     else:
-        if system('perl Build %s' % parameters):
+        if system('perl Build {}'.format(parameters)):
             raise MakeError(_('perl build failed.'))
 
 def install(parameters = 'install'):
     '''install source with given parameters.'''
     if can_access_file('Makefile'):
-        if system('make %s' % parameters):
+        if system('make {}'.format(parameters)):
             raise InstallError(_('Make failed.'))
     else:
         if system('perl Build install'):
@@ -80,22 +80,22 @@ def install(parameters = 'install'):
 
 def removePacklist(path = 'usr/lib/perl5/'):
     ''' cleans .packlist file from perl packages '''
-    full_path = '%s/%s' % (get.installDIR(), path)
+    full_path = '{0}/{1}'.format(get.installDIR(), path)
     for root, dirs, files in os.walk(full_path):
         for packFile in files:
             if packFile == ".packlist":
-                if can_access_file('%s/%s' % (root, packFile)):
-                    unlink('%s/%s' % (root, packFile))
+                if can_access_file('{0}/{1}'.format(root, packFile)):
+                    unlink('{0}/{1}'.format(root, packFile))
                     removeEmptydirs(root)
 
 def removePodfiles(path = 'usr/lib/perl5/'):
     ''' cleans *.pod files from perl packages '''
-    full_path = '%s/%s' % (get.installDIR(), path)
+    full_path = '{0}/{1}'.format(get.installDIR(), path)
     for root, dirs, files in os.walk(full_path):
         for packFile in files:
             if packFile.endswith(".pod"):
-                if can_access_file('%s/%s' % (root, packFile)):
-                    unlink('%s/%s' % (root, packFile))
+                if can_access_file('{0}/{1}'.format(root, packFile)):
+                    unlink('{0}/{1}'.format(root, packFile))
                     removeEmptydirs(root)
 
 def removeEmptydirs(d):
diff --git i/inary/actionsapi/pkgconfig.py w/inary/actionsapi/pkgconfig.py
index 2d7aac4e..861f47f6 100644
--- i/inary/actionsapi/pkgconfig.py
+++ w/inary/actionsapi/pkgconfig.py
@@ -30,8 +30,8 @@ def getVariableForLibrary(library, variable):
     # Returns a specific variable provided in the library .pc file
     try:
         proc = subprocess.Popen(["pkg-config",
-                                 "--variable=%s" % variable,
-                                 "%s" % library],
+                                 "--variable={}".format(variable),
+                                 "{}".format(library)],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE)
         return_code = proc.wait()
@@ -70,7 +70,7 @@ def getLibraryCFLAGS(library):
     try:
         proc = subprocess.Popen(["pkg-config",
                                  "--cflags",
-                                 "%s" % library],
+                                 "{}".format(library)],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE)
         return_code = proc.wait()
@@ -90,7 +90,7 @@ def getLibraryLIBADD(library):
     try:
         proc = subprocess.Popen(["pkg-config",
                                  "--libs",
-                                 "%s" % library],
+                                 "{}".format(library)],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE)
         return_code = proc.wait()
@@ -130,7 +130,7 @@ def libraryExists(library):
     try:
         result = subprocess.call(["pkg-config",
                                    "--exists",
-                                   "%s" % library])
+                                   "{}".format(library)])
     except OSError as exception:
         if exception.errno == 2:
             raise PkgconfigError(_("pkg-config is not installed on your system."))
diff --git i/inary/actionsapi/pythonmodules.py w/inary/actionsapi/pythonmodules.py
index 2b2b7c20..a2a44a9e 100644
--- i/inary/actionsapi/pythonmodules.py
+++ w/inary/actionsapi/pythonmodules.py
@@ -52,18 +52,18 @@ class RunTimeError(inary.actionsapi.Error):
 
 def configure(parameters = '', pyVer = ''):
     '''does python setup.py configure'''
-    if system('python%s setup.py configure %s' % (pyVer, parameters)):
+    if system('python{0} setup.py configure {1}'.format(pyVer, parameters)):
         raise ConfigureError(_('Configuration failed.'))
 
 
 def compile(parameters = '', pyVer = ''):
     '''compile source with given parameters.'''
-    if system('python%s setup.py build %s' % (pyVer, parameters)):
+    if system('python{0} setup.py build {1}'.format(pyVer, parameters)):
         raise CompileError(_('Make failed.'))
 
 def install(parameters = '', pyVer = ''):
     '''does python setup.py install'''
-    if system('python%s setup.py install --root=%s --no-compile -O0 %s' % (pyVer, get.installDIR(), parameters)):
+    if system('python{0} setup.py install --root={1} --no-compile -O0 {2}'.format(pyVer, get.installDIR(), parameters)):
         raise InstallError(_('Install failed.'))
 
     docFiles = ('AUTHORS', 'CHANGELOG', 'CONTRIBUTORS', 'COPYING*', 'COPYRIGHT',
@@ -77,13 +77,13 @@ def install(parameters = '', pyVer = ''):
 
 def run(parameters = '', pyVer = ''):
     '''executes parameters with python'''
-    if system('python%s %s' % (pyVer, parameters)):
-        raise RunTimeError(_('Running %s failed.') % parameters)
+    if system('python{0} {1}'.format(pyVer, parameters)):
+        raise RunTimeError(_('Running {} failed.').format(parameters))
 
-def fixCompiledPy(lookInto = '/usr/lib/%s/' % get.curPYTHON()):
+def fixCompiledPy(lookInto = '/usr/lib/{}/'.format(get.curPYTHON())):
     ''' cleans *.py[co] from packages '''
-    for root, dirs, files in os.walk('%s/%s' % (get.installDIR(),lookInto)):
+    for root, dirs, files in os.walk('{0}/{1}'.format(get.installDIR(),lookInto)):
         for compiledFile in files:
             if compiledFile.endswith('.pyc') or compiledFile.endswith('.pyo'):
-                if can_access_file('%s/%s' % (root,compiledFile)):
-                    unlink('%s/%s' % (root,compiledFile))
+                if can_access_file('{0}/{1}'.format(root,compiledFile)):
+                    unlink('{0}/{1}'.format(root,compiledFile))
diff --git i/inary/actionsapi/qt4.py w/inary/actionsapi/qt4.py
index 130776fc..2d066bf3 100644
--- i/inary/actionsapi/qt4.py
+++ w/inary/actionsapi/qt4.py
@@ -27,19 +27,19 @@ from inary.actionsapi import shelltools
 
 basename = "qt4"
 
-prefix = "/%s" % get.defaultprefixDIR()
-libdir = "%s/lib" % prefix
-bindir = "%s/bin" % prefix
-datadir = "%s/share/%s" % (prefix, basename)
-includedir = "%s/include" % prefix
-docdir = "/%s/%s" % (get.docDIR(), basename)
-examplesdir = "%s/%s/examples" % (libdir, basename)
-demosdir = "%s/%s/demos" % (libdir, basename)
-importdir = "%s/%s/imports" % (libdir, basename)
-plugindir = "%s/%s/plugins" % (libdir, basename)
-translationdir = "%s/translations" % datadir
+prefix = "/{}".format(get.defaultprefixDIR())
+libdir = "{}/lib".format(prefix)
+bindir = "{}/bin".format(prefix)
+datadir = "{0}/share/{1}".format(prefix, basename)
+includedir = "{}/include".format(prefix)
+docdir = "/{0}/{1}".format(get.docDIR(), basename)
+examplesdir = "{0}/{1}/examples".format(libdir, basename)
+demosdir = "{0}/{1}/demos".format(libdir, basename)
+importdir = "{0}/{1}/imports".format(libdir, basename)
+plugindir = "{0}/{1}/plugins".format(libdir, basename)
+translationdir = "{}/translations".format(datadir)
 sysconfdir= "/etc"
-qmake = "%s/qmake" % bindir
+qmake = "{}/qmake".format(bindir)
 
 class ConfigureError(inary.actionsapi.Error):
     def __init__(self, value=''):
@@ -49,17 +49,17 @@ class ConfigureError(inary.actionsapi.Error):
 
 def configure(projectfile='', parameters='', installPrefix=prefix):
     if projectfile != '' and not shelltools.can_access_file(projectfile):
-        raise ConfigureError(_("Project file '%s' not found.") % projectfile)
+        raise ConfigureError(_("Project file '{}' not found.").format(projectfile))
 
     profiles = glob.glob("*.pro")
     if len(profiles) > 1 and projectfile == '':
-        raise ConfigureError(_("It seems there are more than one .pro file, you must specify one. (Possible .pro files: %s)") % ", ".join(profiles))
+        raise ConfigureError(_("It seems there are more than one .pro file, you must specify one. (Possible .pro files: {})").format(", ".join(profiles)))
 
-    shelltools.system("%s -makefile %s PREFIX='%s' QMAKE_CFLAGS+='%s' QMAKE_CXXFLAGS+='%s' %s" % (qmake, projectfile, installPrefix, get.CFLAGS(), get.CXXFLAGS(), parameters))
+    shelltools.system("{0} -makefile {1} PREFIX='{2}' QMAKE_CFLAGS+='{3.CFLAGS()}' QMAKE_CXXFLAGS+='{3.CXXFLAGS()}' {4}".format(qmake, projectfile, installPrefix, get, parameters))
 
 def make(parameters=''):
     cmaketools.make(parameters)
 
 def install(parameters='', argument='install'):
-    cmaketools.install('INSTALL_ROOT="%s" %s' % (get.installDIR(), parameters), argument)
+    cmaketools.install('INSTALL_ROOT="{0}" {1}'.format(get.installDIR(), parameters), argument)
 
diff --git i/inary/actionsapi/qt5.py w/inary/actionsapi/qt5.py
index 42df702e..6a0aa769 100644
--- i/inary/actionsapi/qt5.py
+++ w/inary/actionsapi/qt5.py
@@ -27,27 +27,27 @@ from inary.actionsapi import shelltools
 
 basename = "qt5"
 
-prefix = "/%s" % get.defaultprefixDIR()
-libdir = "%s/lib" % prefix
-libexecdir = "%s/libexec" % prefix
+prefix = "/{}".format(get.defaultprefixDIR())
+libdir = "{}/lib".format(prefix)
+libexecdir = "{}/libexec".format(prefix)
 sysconfdir= "/etc"
-bindir = "%s/bin" % prefix
-includedir = "%s/include" % prefix
+bindir = "{}/bin".format(prefix)
+includedir = "{}/include".format(prefix)
 
 # qt5 spesific variables
 
-headerdir = "%s/include/%s" % (prefix, basename)
-datadir = "%s/share/%s" % (prefix, basename)
-docdir = "/%s/%s" % (get.docDIR(), basename)
-archdatadir = "%s/%s" % (libdir, basename)
-examplesdir = "%s/%s/examples" % (libdir, basename)
-importdir = "%s/%s/imports" % (libdir, basename)
-plugindir = "%s/%s/plugins" % (libdir, basename)
-qmldir = "%s/%s/qmldir" % (libdir, basename)
-testdir = "%s/share/%s" % (prefix, basename)
-translationdir = "%s/translations" % datadir
+headerdir = "{}/include/{}".format(prefix, basename)
+datadir = "{}/share/{}".format(prefix, basename)
+docdir = "/{}/{}".format(get.docDIR(), basename)
+archdatadir = "{}/{}".format(libdir, basename)
+examplesdir = "{}/{}/examples".format(libdir, basename)
+importdir = "{}/{}/imports".format(libdir, basename)
+plugindir = "{}/{}/plugins".format(libdir, basename)
+qmldir = "{}/{}/qmldir".format(libdir, basename)
+testdir = "{}/share/{}".format(prefix, basename)
+translationdir = "{}/translations".format(datadir)
 
-qmake = "%s/qmake-qt5" % bindir
+qmake = "{}/qmake-qt5" % bindir
 
 class ConfigureError(inary.actionsapi.Error):
     def __init__(self, value=''):
@@ -57,17 +57,17 @@ class ConfigureError(inary.actionsapi.Error):
 
 def configure(projectfile='', parameters='', installPrefix=prefix):
     if projectfile != '' and not shelltools.can_access_file(projectfile):
-        raise ConfigureError(_("Project file '%s' not found.") % projectfile)
+        raise ConfigureError(_("Project file '{}' not found.").format(projectfile))
 
     profiles = glob.glob("*.pro")
     if len(profiles) > 1 and projectfile == '':
         raise ConfigureError(_("It seems there are more than one .pro file, you must specify one. (Possible .pro files: %s)") % ", ".join(profiles))
 
-    shelltools.system("%s -makefile %s PREFIX='%s' QMAKE_CFLAGS+='%s' QMAKE_CXXFLAGS+='%s' %s" % (qmake, projectfile, installPrefix, get.CFLAGS(), get.CXXFLAGS(), parameters))
+    shelltools.system("{0} -makefile {1} PREFIX='{2}' QMAKE_CFLAGS+='{3.CFLAGS()}' QMAKE_CXXFLAGS+='{3.CXXFLAGS()}' {5}".format(qmake, projectfile, installPrefix, get, parameters))
 
 def make(parameters=''):
     cmaketools.make(parameters)
 
 def install(parameters='', argument='install'):
-    cmaketools.install('INSTALL_ROOT="%s" %s' % (get.installDIR(), parameters), argument)
+    cmaketools.install('INSTALL_ROOT="{0}" {1}'.format(get.installDIR(), parameters), argument)
 
diff --git i/inary/actionsapi/rubymodules.py w/inary/actionsapi/rubymodules.py
index eee38d2c..d7dcbc8e 100644
--- i/inary/actionsapi/rubymodules.py
+++ w/inary/actionsapi/rubymodules.py
@@ -52,7 +52,7 @@ class RunTimeError(inary.actionsapi.Error):
         ctx.ui.error(value)
 
 def get_config(config):
-    return os.popen("ruby -rrbconfig -e 'puts Config::CONFIG[\"%s\"]'" % config).read().strip()
+    return os.popen("ruby -rrbconfig -e 'puts Config::CONFIG[\"{}\"]'".format(config)).read().strip()
 
 def get_ruby_version():
     return get_config('ruby_version')
@@ -88,14 +88,14 @@ def auto_dodoc():
 
 def install(parameters=''):
     '''does ruby setup.rb install'''
-    if system('ruby -w setup.rb --prefix=/%s --destdir=%s %s' % (get.defaultprefixDIR(), get.installDIR(), parameters)):
+    if system('ruby -w setup.rb --prefix=/{0.defaultprefixDIR()} --destdir={0.installDIR()} {1}'.format(get, parameters)):
         raise InstallError(_('Install failed.'))
 
     auto_dodoc()
 
 def rake_install(parameters=''):
     '''execute rake script for installation'''
-    if system('rake -t -l %s %s' % (os.path.join('/', get.defaultprefixDIR(), 'lib'), parameters)):
+    if system('rake -t -l {0} {1}'.format(os.path.join('/', get.defaultprefixDIR(), 'lib'), parameters)):
         raise InstallError(_('Install failed.'))
 
     auto_dodoc()
@@ -104,5 +104,5 @@ def run(parameters=''):
     '''executes parameters with ruby'''
     export('DESTDIR', get.installDIR())
 
-    if system('ruby %s' % parameters):
-        raise RuntimeError(_("Running 'ruby %s' failed.") % parameters)
+    if system('ruby {}'.format(parameters)):
+        raise RuntimeError(_("Running 'ruby {}' failed.").format(parameters))
diff --git i/inary/actionsapi/scons.py w/inary/actionsapi/scons.py
index 502c3532..77dce021 100644
--- i/inary/actionsapi/scons.py
+++ w/inary/actionsapi/scons.py
@@ -35,9 +35,9 @@ class InstallError(inary.actionsapi.Error):
         ctx.ui.error(value)
 
 def make(parameters = ''):
-    if system('scons %s %s' % (get.makeJOBS(), parameters)):
+    if system('scons {0} {1}'.format(get.makeJOBS(), parameters)):
         raise MakeError(_('Make failed.'))
 
 def install(parameters = 'install', prefix = get.installDIR(), argument='prefix'):
-    if system('scons %s=%s %s' % (argument, prefix, parameters)):
+    if system('scons {0}={1} {2}'.format(argument, prefix, parameters)):
         raise InstallError(_('Install failed.'))
diff --git i/inary/actionsapi/shelltools.py w/inary/actionsapi/shelltools.py
index 20f9da42..3822c038 100644
--- i/inary/actionsapi/shelltools.py
+++ w/inary/actionsapi/shelltools.py
@@ -46,31 +46,30 @@ def makedirs(destinationDirectory):
         if not os.access(destinationDirectory, os.F_OK):
             os.makedirs(destinationDirectory)
     except OSError:
-        error(_('Cannot create directory %s') % destinationDirectory)
+        error(_('Cannot create directory {}').format(destinationDirectory))
 
 def echo(destionationFile, content):
     try:
         f = open(destionationFile, 'a')
-        f.write('%s\n' % content)
+        f.write('{}\n'.format(content))
         f.close()
     except IOError:
-        error(_('ActionsAPI [echo]: Can\'t append to file %s.') % (destionationFile))
+        error(_('ActionsAPI [echo]: Can\'t append to file {}.').format(destionationFile))
 
 def chmod(filePath, mode = 0o755):
     '''change the mode of filePath to the mode'''
     filePathGlob = glob.glob(filePath)
     if len(filePathGlob) == 0:
-        error(_("ActionsAPI [chmod]: No file matched pattern \"%s\".") % filePath)
+        error(_("ActionsAPI [chmod]: No file matched pattern \"{}\".").format(filePath))
 
     for fileName in filePathGlob:
         if can_access_file(fileName):
             try:
                 os.chmod(fileName, mode)
             except OSError:
-                ctx.ui.error(_('ActionsAPI [chmod]: Operation not permitted: %s (mode: 0%o)') \
-                                                                % (fileName, mode))
+                ctx.ui.error(_('ActionsAPI [chmod]: Operation not permitted: {0} (mode: 0{1})').format(fileName, mode))
         else:
-            ctx.ui.error(_('ActionsAPI [chmod]: File %s doesn\'t exists.') % (fileName))
+            ctx.ui.error(_('ActionsAPI [chmod]: File {} doesn\'t exists.').format(fileName))
 
 def chown(filePath, uid = 'root', gid = 'root'):
     '''change the owner and group id of filePath to uid and gid'''
@@ -78,23 +77,22 @@ def chown(filePath, uid = 'root', gid = 'root'):
         try:
             os.chown(filePath, pwd.getpwnam(uid)[2], grp.getgrnam(gid)[2])
         except OSError:
-            ctx.ui.error(_('ActionsAPI [chown]: Operation not permitted: %s (uid: %s, gid: %s)') \
-                                                 % (filePath, uid, gid))
+            ctx.ui.error(_('ActionsAPI [chown]: Operation not permitted: {0} (uid: {1}, gid: {2})').format(filePath, uid, gid))
     else:
-        ctx.ui.error(_('ActionsAPI [chown]: File %s doesn\'t exists.') % filePath)
+        ctx.ui.error(_('ActionsAPI [chown]: File {} doesn\'t exists.').format(filePath))
 
 def sym(source, destination):
     '''creates symbolic link'''
     try:
         os.symlink(source, destination)
     except OSError:
-        ctx.ui.error(_('ActionsAPI [sym]: Permission denied: %s to %s') % (source, destination))
+        ctx.ui.error(_('ActionsAPI [sym]: Permission denied: {0} to {1}').format(source, destination))
 
 def unlink(pattern):
     '''remove the file path'''
     filePathGlob = glob.glob(pattern)
     if len(filePathGlob) == 0:
-        ctx.ui.error(_("No file matched pattern \"%s\". Remove operation failed.") % pattern)
+        ctx.ui.error(_("No file matched pattern \"{}\". Remove operation failed.").format(pattern))
         return
 
     for filePath in filePathGlob:
@@ -102,11 +100,11 @@ def unlink(pattern):
             try:
                 os.unlink(filePath)
             except OSError:
-                ctx.ui.error(_('ActionsAPI [unlink]: Permission denied: %s.') % (filePath))
+                ctx.ui.error(_('ActionsAPI [unlink]: Permission denied: {}.').format(filePath))
         elif isDirectory(filePath):
             pass
         else:
-            ctx.ui.error(_('ActionsAPI [unlink]: File %s doesn\'t exists.') % (filePath))
+            ctx.ui.error(_('ActionsAPI [unlink]: File {} doesn\'t exists.').format(filePath))
 
 def unlinkDir(sourceDirectory):
     '''delete an entire directory tree'''
@@ -114,40 +112,40 @@ def unlinkDir(sourceDirectory):
         try:
             shutil.rmtree(sourceDirectory)
         except OSError:
-            error(_('ActionsAPI [unlinkDir]: Operation not permitted: %s') % (sourceDirectory))
+            error(_('ActionsAPI [unlinkDir]: Operation not permitted: {}').format(sourceDirectory))
     elif isFile(sourceDirectory):
         pass
     else:
-        error(_('ActionsAPI [unlinkDir]: Directory %s doesn\'t exists.') % (sourceDirectory))
+        error(_('ActionsAPI [unlinkDir]: Directory {} doesn\'t exists.').format(sourceDirectory))
 
 def move(source, destination):
     '''recursively move a "source" file or directory to "destination"'''
     sourceGlob = glob.glob(source)
     if len(sourceGlob) == 0:
-        error(_("ActionsAPI [move]: No file matched pattern \"%s\".") % source)
+        error(_("ActionsAPI [move]: No file matched pattern \"{}\".").format(source))
 
     for filePath in sourceGlob:
         if isFile(filePath) or isLink(filePath) or isDirectory(filePath):
             try:
                 shutil.move(filePath, destination)
             except OSError:
-                error(_('ActionsAPI [move]: Permission denied: %s to %s') % (filePath, destination))
+                error(_('ActionsAPI [move]: Permission denied: {0} to {1}').format(filePath, destination))
         else:
-            error(_('ActionsAPI [move]: File %s doesn\'t exists.') % (filePath))
+            error(_('ActionsAPI [move]: File {} doesn\'t exists.').format(filePath))
 
 # FIXME: instead of passing a sym parameter, split copy and copytree into 4 different function
 def copy(source, destination, sym = True):
     '''recursively copy a "source" file or directory to "destination"'''
     sourceGlob = glob.glob(source)
     if len(sourceGlob) == 0:
-        error(_("ActionsAPI [copy]: No file matched pattern \"%s\".") % source)
+        error(_("ActionsAPI [copy]: No file matched pattern \"{}\".").format(source))
 
     for filePath in sourceGlob:
         if isFile(filePath) and not isLink(filePath):
             try:
                 shutil.copy(filePath, destination)
             except IOError:
-                error(_('ActionsAPI [copy]: Permission denied: %s to %s') % (filePath, destination))
+                error(_('ActionsAPI [copy]: Permission denied: {0} to {1}').format(filePath, destination))
         elif isLink(filePath) and sym:
             if isDirectory(destination):
                 os.symlink(os.readlink(filePath), join_path(destination, os.path.basename(filePath)))
@@ -163,7 +161,7 @@ def copy(source, destination, sym = True):
         elif isDirectory(filePath):
             copytree(filePath, destination, sym)
         else:
-            error(_('ActionsAPI [copy]: File %s does not exist.') % filePath)
+            error(_('ActionsAPI [copy]: File {} does not exist.').format(filePath))
 
 def copytree(source, destination, sym = True):
     '''recursively copy an entire directory tree rooted at source'''
@@ -178,9 +176,9 @@ def copytree(source, destination, sym = True):
         try:
             shutil.copytree(source, destination, sym)
         except OSError as e:
-            error(_('ActionsAPI [copytree] %s to %s: %s') % (source, destination, e))
+            error(_('ActionsAPI [copytree] {0} to {1}: {2}').format(source, destination, e))
     else:
-        error(_('ActionsAPI [copytree]: Directory %s doesn\'t exists.') % (source))
+        error(_('ActionsAPI [copytree]: Directory {} doesn\'t exists.').format(source))
 
 def touch(filePath):
     '''changes the access time of the 'filePath', or creates it if it does not exist'''
@@ -188,7 +186,7 @@ def touch(filePath):
 
     if filePathGlob:
         if len(filePathGlob) == 0:
-            error(_("ActionsAPI [touch]: No file matched pattern \"%s\".") % filePath)
+            error(_("ActionsAPI [touch]: No file matched pattern \"{}\".").format(filePath))
 
         for f in filePathGlob:
             os.utime(f, None)
@@ -197,7 +195,7 @@ def touch(filePath):
             f = open(filePath, 'w')
             f.close()
         except IOError:
-            error(_('ActionsAPI [touch]: Permission denied: %s') % (filePath))
+            error(_('ActionsAPI [touch]: Permission denied: {}').format(filePath))
 
 def cd(directoryName = ''):
     '''change directory'''
@@ -256,6 +254,6 @@ def system(command):
 
     #if return value is different than 0, it means error, raise exception
     if retValue != 0:
-        error(_("Command \"%s\" failed, return value was %d.") % (command, retValue))
+        error(_("Command \"{0}\" failed, return value was {1}.").format(command, retValue))
 
     return retValue
diff --git i/inary/actionsapi/texlivemodules.py w/inary/actionsapi/texlivemodules.py
index 0ad08b58..5344f12f 100644
--- i/inary/actionsapi/texlivemodules.py
+++ w/inary/actionsapi/texlivemodules.py
@@ -28,7 +28,7 @@ from inary.actionsapi.shelltools import *
 from inary.actionsapi.inarytools import dodoc, dodir, domove, dosym, insinto, removeDir
 
 
-WorkDir = "%s-%s" % (get.srcNAME(), get.srcVERSION().split('_')[-1])
+WorkDir = "{0.srcNAME()}-{0.srcVERSION().split('_')[-1]}".format(get)
 
 class CompileError(inary.actionsapi.Error):
     def __init__(self, value=''):
@@ -86,83 +86,83 @@ def install(parameters = ''):
 
 def createSymlinksFormat2Engines():
     '''Create symlinks from format to engines'''
-    for formatfile in ls("%s/texmf/fmtutil/format*.cnf" % get.curDIR()):
+    for formatfile in ls("{}/texmf/fmtutil/format*.cnf".format(get.curDIR())):
         symfile = open(formatfile, "r")
         for line in symfile.readlines():
             if not line.startswith("#"):
                 symbin = line.split(None)
                 if "cont-" in symbin[0] or "metafun" in symbin[0] or "mptopdf" in symbin[0]:
-                     ctx.ui.info(_('Symlink %s skipped (special case)') % symbin[0])
+                     ctx.ui.info(_('Symlink {} skipped (special case)').format(symbin[0]))
                 elif "mf" in symbin[0]:
-                    ctx.ui.info(_('Symlink %s -> %s skipped (texlive-core takes care of it.') % (symbin[0], symbin[1]))
+                    ctx.ui.info(_('Symlink {0[0]} -> {0[1]} skipped (texlive-core takes care of it.').format(symbin))
                 else:
                     if symbin[0] == symbin[1]:
-                        ctx.ui.info(_('Symlink %s -> %s skipped.') % (symbin[0], symbin[1]))
-                    elif can_access_file("%s/usr/bin/%s" % (get.installDIR(), symbin[0])):
-                        ctx.ui.info(_('Symlink %s skipped (file exists.)') % symbin[0])
+                        ctx.ui.info(_('Symlink {0[0]} -> {0[1]} skipped.').format(symbin))
+                    elif can_access_file("{0}/usr/bin/{1}".format(get.installDIR(), symbin[0])):
+                        ctx.ui.info(_('Symlink {} skipped (file exists.)').format(symbin[0]))
                     else:
-                        ctx.ui.info(_('Making symlink from %s to %s') % (symbin[0], symbin[1]))
+                        ctx.ui.info(_('Making symlink from {0[0]} to {0[1]}').format(symbin))
                         dodir("/usr/bin")
-                        sym(symbin[1], "%s/usr/bin/%s" % (get.installDIR(), symbin[0]))
+                        sym(symbin[1], "{0}/usr/bin/{1}".format(get.installDIR(), symbin[0]))
         symfile.close()
 
 def installDocFiles():
     '''Installing docs'''
     if "documentation" in get.srcNAME():
-        if os.path.isdir("%s/texmf-doc" % get.curDIR()):
-            copytree("texmf-doc", "%s/usr/share/texmf-doc" % get.installDIR())
+        if os.path.isdir("{}/texmf-doc".format(get.curDIR())):
+            copytree("texmf-doc", "{}/usr/share/texmf-doc".format(get.installDIR()))
     else:
         for removedir in ["texmf", "texmf-dist"]:
-            if os.path.isdir("%s/%s/doc/" % (get.curDIR(), removedir)):
-                shutil.rmtree("%s/%s/doc" % (get.curDIR(),removedir))
+            if os.path.isdir("{0}/{1}/doc/".format(get.curDIR(), removedir)):
+                shutil.rmtree("{0}/{1}/doc".format(get.curDIR(),removedir))
 
 def installTexmfFiles():
     '''Installing texmf, texmf-dist, tlpkg, texmf-var'''
     for installdoc in ["texmf", "texmf-dist", "tlpkg", "texmf-var"]:
-        if os.path.isdir("%s/%s" % (get.curDIR(), installdoc)):
+        if os.path.isdir("{0}/{1}".format(get.curDIR(), installdoc)):
             if not installdoc == "texmf-var":
-                shutil.copytree(installdoc, "%s/usr/share/%s" % (get.installDIR(),installdoc))
+                shutil.copytree(installdoc, "{0}/usr/share/{1}".format(get.installDIR(),installdoc))
             else:
-                copytree(installdoc, "%s/var/lib/texmf" % get.installDIR())
+                copytree(installdoc, "{}/var/lib/texmf".format(get.installDIR()))
 
 def installConfigFiles():
     '''Installing config files'''
-    if can_access_file("%s/%s.cfg" % (get.curDIR(), get.srcNAME())):
-        insinto("/etc/texmf/updmap.d", "%s/%s.cfg" % ( get.curDIR(), get.srcNAME()))
+    if can_access_file("{0.curDIR()}/{0.srcNAME()}.cfg".format(get)):
+        insinto("/etc/texmf/updmap.d", "{0.curDIR()}/{0.srcNAME()}.cfg".format(get))
 
-    if can_access_file("%s/%s-config.ps" % (get.curDIR(), get.srcNAME())):
-        insinto("/etc/texmf/dvips.d", "%s/%s-config.ps" % (get.curDIR(), get.srcNAME()))
+    if can_access_file("{0.curDIR()}/{0.srcNAME()}.config.ps".format(get)):
+        insinto("/etc/texmf/dvips.d", "{0.curDIR()}/{0.srcNAME()}.config.ps".format(get))
 
-    if can_access_file("%s/%s-config" % (get.curDIR(), get.srcNAME())):
-        insinto("/etc/texmf/dvipdfm/config", "%s/%s-config" % (get.curDIR(), get.srcNAME()))
+    if can_access_file("{0.curDIR()}/{0.srcNAME()}.config".format(get)):
+        insinto("/etc/texmf/dvipdfm/config", "{0.curDIR()}/{0.srcNAME()}.config".format(get))
 
-    if can_access_file("%s/language.%s.def" % (get.curDIR(), get.srcNAME())):
-        insinto("/etc/texmf/language.def.d", "%s/language.%s.def" % (get.curDIR(), get.srcNAME()))
+    if can_access_file("{0.curDIR()}/language/{0.srcNAME().def}.config".format(get)):
+        insinto("/etc/texmf/language.def.d", "{0.curDIR()}/language.{0.srcNAME()}.def".format(get))
 
-    if can_access_file("%s/language.%s.dat" % (get.curDIR(), get.srcNAME())):
-        insinto( "/etc/texmf/language.dat.d", "%s/language.%s.dat" % (get.curDIR(), get.srcNAME()))
+    if can_access_file("{0.curDIR()}/language.{0.srcNAME()}.dat".format(get)):
+        insinto("/etc/texmf/language.dat.d", "{0.curDIR()}/language.{0.srcNAME()}.dat".format())
 
 def handleConfigFiles():
     '''Handling config files'''
-    for root, dirs,files in os.walk("%s/usr/share/texmf" % get.installDIR()):
+    for root, dirs,files in os.walk("{}/usr/share/texmf".format(get.installDIR())):
         if not ("config" in root or "doc" in root):
             for configFile in files:
                 if configFile.endswith(("cfg", "cnf")):
                     dirname = root.split("/")[-1]
-                    if not os.path.isdir("%s/etc/texmf/%s.d" % (get.installDIR(),dirname)):
-                        ctx.ui.info(_('Creating /etc/texmf/%s.d') % dirname)
-                        dodir("/etc/texmf/%s.d" % dirname)
-                    ctx.ui.info(_('Moving (and symlinking) /usr/share/texmf/%s to /etc/texmf/%s.d') % (configFile,dirname))
-                    domove("/usr/share/texmf/%s/%s" % (dirname,configFile), "/etc/texmf/%s.d" % dirname)
-                    dosym("/etc/texmf/%s.d/%s" % (dirname, configFile), "/usr/share/texmf/%s/%s" %(dirname, configFile))
+                    if not os.path.isdir("{0}/etc/texmf/{1}.d".format(get.installDIR(),dirname)):
+                        ctx.ui.info(_('Creating /etc/texmf/{}.d').format(dirname))
+                        dodir("/etc/texmf/{}.d".format(dirname))
+                    ctx.ui.info(_('Moving (and symlinking) /usr/share/texmf/{0} to /etc/texmf/{1}.d').format(configFile,dirname))
+                    domove("/usr/share/texmf/{0}/{1}".format(dirname,configFile), "/etc/texmf/{}.d".format(dirname))
+                    dosym("/etc/texmf/{0}.d/{1}".format(dirname, configFile), "/usr/share/texmf/{0}/{1}".format(dirname, configFile))
 
 def addFormat(parameters):
     '''Add format files'''
-    if not os.path.isdir("%s/texmf/fmtutil/" % get.curDIR()):
-        makedirs("%s/texmf/fmtutil/" % get.curDIR())
-    if not os.path.isfile("%s/texmf/fmtutil/format.%s.cnf" % (get.curDIR(),get.srcNAME())):
-        cnf_file = open("%s/texmf/fmtutil/format.%s.cnf" % (get.curDIR(),get.srcNAME()), "w")
-        cnf_file.write("# Generated for %s by actionsapi/texlivemodules.py\n" % get.srcNAME())
+    if not os.path.isdir("{}/texmf/fmtutil/".format(get.curDIR())):
+        makedirs("{}/texmf/fmtutil/".format(get.curDIR()))
+    if not os.path.isfile("{0.curDIR()}/texmf/fmtutil/format.{0.srcNAME()}.cnf".format(get)):
+        cnf_file = open("{0.curDIR()}/texmf/fmtutil/format.{0.srcNAME()}.cnf".format(get), "w")
+        cnf_file.write("# Generated for {} by actionsapi/texlivemodules.py\n".format(get.srcNAME()))
         cnf_file.close()
 
     # TODO: Use regex for code simplification
@@ -179,34 +179,34 @@ def addFormat(parameters):
             elif not pair[0] == 'patterns':
                 para_dict["patterns"] = '-'
 
-    cnf_file = open('%s/texmf/fmtutil/format.%s.cnf' % (get.curDIR(),get.srcNAME()), 'a')
-    cnf_file.write("%s\t%s\t%s\t%s\n" % (para_dict["name"], para_dict["engine"], para_dict["patterns"], para_dict["options"]))
+    cnf_file = open('{0.curDIR()}/texmf/fmtutil/format.{0.srcNAME()}.cnf'.format(get), 'a')
+    cnf_file.write('{0["name"]}\t{0["engine"]}\t{0["patterns"]}\t{0["options"]}\n'.format(para_dict))
     cnf_file.close()
 
 def moveSources():
     reloc = "texmf-dist"
 
     for tlpobjfile in os.listdir("tlpkg/tlpobj/"):
-        jobsfile=open("tlpkg/tlpobj/%s" % tlpobjfile, "r")
+        jobsfile=open("tlpkg/tlpobj/{}".format(tlpobjfile), "r")
         for line in jobsfile.readlines():
             if "RELOC" in line:
                 path = line.split("/", 1)[-1]
                 path = path.strip()
                 filename = path.split("/", -1)
                 dirname = os.path.dirname(path)
-                if not os.path.isdir("%s/%s" % (reloc,dirname)):
-                    os.system("mkdir -p %s/%s" % (reloc,dirname))
-                shutil.move("%s" % path , "%s/%s" % (reloc,dirname))
+                if not os.path.isdir("{0}/{1}".format(reloc,dirname)):
+                    os.system("mkdir -p {0}/{1}".format(reloc,dirname))
+                shutil.move("{}".format(path) , "{0}/{1}".format(reloc,dirname))
 
 def buildFormatFiles():
     '''Build format files'''
-    if os.path.isdir("%s/texmf/fmtutil/" % get.curDIR()):
-        for formatfile in ls("%s/texmf/fmtutil/format*.cnf" % get.curDIR()):
-            makedirs("%s/texmf-var/web2c/" % get.curDIR())
-            ctx.ui.info(_('Building format file %s') % formatfile)
-            export("TEXMFHOME", "%s/texmf:/%stexmf-dist:%s/texmf-var" %(get.curDIR(), get.curDIR(), get.curDIR() ))
+    if os.path.isdir("{}/texmf/fmtutil/".format(get.curDIR())):
+        for formatfile in ls("{}/texmf/fmtutil/format*.cnf".format(get.curDIR())):
+            makedirs("{}/texmf-var/web2c/".format(get.curDIR()))
+            ctx.ui.info(_('Building format file {}').format(formatfile))
+            export("TEXMFHOME", "{0}/texmf:/{0}texmf-dist:{0}/texmf-var".format(get.curDIR()))
             export("VARTEXFONTS", "fonts")
-            system("env -u TEXINPUTS fmtutil --cnffile %s --fmtdir texmf-var/web2c --all" % formatfile)
+            system("env -u TEXINPUTS fmtutil --cnffile {} --fmtdir texmf-var/web2c --all".format(formatfile))
 
 def addLanguageDat(parameter):
     '''Create language.*.dat files'''
@@ -217,13 +217,13 @@ def addLanguageDat(parameter):
         if len(pair) == 2: #That's just a caution, the pair should have two items, not more not less
             para_dict[pair[0]] = pair[1]
 
-    language_dat = open('%s/language.%s.dat' % (get.curDIR(),get.srcNAME())  , 'a')
-    language_dat.write("%s\t%s\n" % (para_dict["name"], para_dict["file"]))
+    language_dat = open('{0.curDIR()}/language.{0.srcNAME()}.dat'.format(get)  , 'a')
+    language_dat.write('{0["name"]}\t{0["file"]}\n"'.format(para_dict))
     language_dat.close()
 
     if "synonyms" in para_dict:
-        language_dat = open('%s/language.%s.dat' % (get.curDIR(),get.srcNAME())  , 'a')
-        language_dat.write("=%s\n" % para_dict["synonyms"])
+        language_dat = open('{0.curDIR()}/language.{0.srcNAME()}.dat'.format(get)  , 'a')
+        language_dat.write("={}\n".format(para_dict["synonyms"]))
         language_dat.close()
 
 def addLanguageDef(parameter):
@@ -259,25 +259,25 @@ def generateConfigFiles():
                 command = splitline[1]
                 parameter = splitline[2].strip()
                 if command == "addMap":
-                    echo("%s/%s.cfg" % (get.curDIR(), get.srcNAME()), "Map %s" % parameter)
-                    ctx.ui.info(_('Map %s is added to %s/%s.cfg') % (parameter, get.curDIR(), get.srcNAME()))
+                    echo("{0.curDIR()}/{0.srcNAME()}.cfg".format(get), "Map {}".format(parameter))
+                    ctx.ui.info(_('Map {0} is added to {1.curDIR()}/{1.srcNAME()}.cfg').format(parameter, get))
                 elif command == "addMixedMap":
-                    echo("%s/%s.cfg" % (get.curDIR(), get.srcNAME()), "MixedMap %s" % parameter)
-                    ctx.ui.info(_('MixedMap %s is added to %s/%s.cfg') % (parameter, get.curDIR(), get.srcNAME()))
+                    echo("{0.curDIR()}/{0.srcNAME()}.cfg".format(get), "MixedMap {}".format(parameter))
+                    ctx.ui.info(_('MixedMap {0} is added to {1.curDIR()}/{1.srcNAME()}.cfg').format(parameter, get))
                 elif command == "addDvipsMap":
-                    echo("%s/%s-config.ps" % (get.curDIR(), get.srcNAME()), "p +%s" % parameter)
-                    ctx.ui.info(_('p +%s is added to %s/%s-config.ps') % (parameter, get.curDIR(), get.srcNAME()))
+                    echo("{0.curDIR()}/{0.srcNAME()}-config.ps".format(get), "p +{}".format(parameter))
+                    ctx.ui.info(_('p +{0} is added to {1.curDIR()}/{1.srcNAME()}-config.ps').format(parameter, get))
                 elif command == "addDvipdfmMap":
-                    echo("%s/%s-config" % (get.curDIR(), get.srcNAME()), "f %s" % parameter)
-                    ctx.ui.info(_('f %s is added to %s/%s-config') % (parameter, get.curDIR(), get.srcNAME()))
+                    echo("{0.curDIR()}/{0.srcNAME()}-config".format(get), "f {}".format(parameter))
+                    ctx.ui.info(_('f {0} is added to {1.curDIR()}/{1.srcNAME()}-config').format(parameter, get))
                 elif command == "AddHyphen":
                     addLanguageDat(parameter)
                     addLanguageDef(parameter)
                 elif command == "AddFormat":
                     addFormat(parameter)
                 elif command == "BuildFormat":
-                    ctx.ui.info(_('Language file  %s  already generated.') % parameter)
+                    ctx.ui.info(_('Language file  {}  already generated.').format(parameter))
                 elif command == "BuildLanguageDat":
-                    ctx.ui.info(_('No rule to proccess %s. Please file a bug.') % command)
+                    ctx.ui.info(_('No rule to proccess {}. Please file a bug.').format(command))
         jobsfile.close()
 
diff --git i/inary/actionsapi/variables.py w/inary/actionsapi/variables.py
index f5ffc31c..f77c11a6 100644
--- i/inary/actionsapi/variables.py
+++ w/inary/actionsapi/variables.py
@@ -35,8 +35,8 @@ def exportFlags():
     os.environ['JOBS'] = values.build.jobs
 
     # http://liste.pardus.org.tr/gelistirici/2009-January/016442.html
-    os.environ['CC'] = "%s-gcc" % values.build.host
-    os.environ['CXX'] = "%s-g++" % values.build.host
+    os.environ['CC'] = "{}-gcc".format(values.build.host)
+    os.environ['CXX'] = "{}-g++".format(values.build.host)
 
 class Env(object):
     '''General environment variables used in actions API'''
diff --git i/inary/analyzer/pkgconfig.py w/inary/analyzer/pkgconfig.py
index 9e1aa993..1466a4fd 100644
--- i/inary/analyzer/pkgconfig.py
+++ w/inary/analyzer/pkgconfig.py
@@ -118,7 +118,7 @@ class LDD:
                     pkgconfig_list.append((result_broken, result_unused, result_undefined, result_lists, result_runpath, package_name))
 
             else:
-                raise Error("'%s' is not a valid .inary file or an installed package" % package)
+                raise Error("'{}' is not a valid .inary file or an installed package".format(package))
 
         return pkgconfig_list
 
@@ -159,7 +159,7 @@ class LDD:
         for obj in objdump_needed:
             # Find the absolute path of libraries from their SONAME's
             if obj in result_main_ldd:
-                result_needed.append(os.popen("readlink -f %s" % result_main_ldd[obj]).read().strip())
+                result_needed.append(os.popen("readlink -f {}".format(result_main_ldd[obj]).read().strip()))
             else:
                 result_needed.append(obj)
 
@@ -182,7 +182,7 @@ class LDD:
                     dependency_name = inary.api.search_file(obj_dump)[0][0]
                 except IndexError:
                     dependency_name = "broken"
-                    ctx.ui.info("%s (probably broken dependency)" % needed)
+                    ctx.ui.info("{} (probably broken dependency)".format(needed))
             result_needed.append((obj_dump, dependency_name))
         return result_needed
 
@@ -190,14 +190,14 @@ class LDD:
         '''check for .pc files created by pkgconfig and shipped with the package
            these .pc files have requirements tags that can be used for dependencies'''
         result_needed = []
-        requires = set(os.popen("pkg-config --print-requires --print-requires-private %s | gawk '{ print $1 }'" % \
-                os.path.basename(pc_file).replace(".pc", "")).read().split("\n")[:-1])
+        requires = set(os.popen("pkg-config --print-requires --print-requires-private {} | gawk '{ print $1 }'".format(
+                os.path.basename(pc_file).replace(".pc", ""))).read().split("\n")[:-1])
 
         for require in requires:
-            require_file = "/usr/share/pkgconfig/%s.pc" % require
+            require_file = "/usr/share/pkgconfig/{}.pc".format(require)
 
             if not os.path.exists(require_file):
-                require_file = "/usr/lib/pkgconfig/%s.pc" % require
+                require_file = "/usr/lib/pkgconfig/{}.pc".format(require)
             try:
                 dependency_name = inary.api.search_file(require_file)[0][0]
             except IndexError:
@@ -225,14 +225,14 @@ class LDD:
         result_must_removed = list(set(package_deps) & set(systembase_packages))
         for deps in package_deps:
             if deps in result_must_removed:
-                package_deps[package_deps.index(deps)] = "%s (base)" % deps
+                package_deps[package_deps.index(deps)] = "{} (base)".format(deps)
 
         # look for packages that are system.devel but are written as dependency
         # mark them with "*"
         result_must_removed = list(set(package_deps) & set(systemdevel_packages))
         for deps in package_deps:
             if deps in result_must_removed:
-                package_deps[package_deps.index(deps)] = "%s (devel)" % deps
+                package_deps[package_deps.index(deps)] = "{} (devel)".format(deps)
 
         # extract the dependency package names and store them in result_deps
         # dependencies tagged as broken or given itself are eliminated
@@ -252,11 +252,11 @@ class LDD:
             result_must_removed = list(set(result_deps) & set(systembase_packages))
             for deps in result_deps:
                 if deps in result_must_removed:
-                    result_deps[result_deps.index(deps)] = "%s (base)" % deps
+                    result_deps[result_deps.index(deps)] = "{} (base)".format(deps)
             result_must_removed = list(set(result_deps) & set(systemdevel_packages))
             for deps in result_deps:
                 if deps in result_must_removed:
-                    result_deps[result_deps.index(deps)] = "%s (devel)" % deps
+                    result_deps[result_deps.index(deps)] = "{} (devel)".format(deps)
             result_deps = list(set(result_deps))
 
         # remove packages that already are written in metadata.xml (runtime dependencies written in pspec.xml)
@@ -286,12 +286,12 @@ class LDD:
 
         # Two options are available. Checking for a inary file or an installed package in the database
         if package_dir:
-            package_files = os.popen("find %s" % package_dir).read().strip().split("\n")
-            package_pc_files = glob.glob("%s/usr/*/pkgconfig/*.pc" % package_dir)
+            package_files = os.popen("find {}".format(package_dir)).read().strip().split("\n")
+            package_pc_files = glob.glob("{}/usr/*/pkgconfig/*.pc".format(package_dir))
         else:
-            package_files = set(["/%s" % file_name.path \
+            package_files = set(["/{}".format(file_name.path) \
                 for file_name in INSTALLDB.get_files(package_name).list])
-            package_pc_files = set([os.path.realpath("/%s" % file_name.path) \
+            package_pc_files = set([os.path.realpath("/{}".format(file_name.path)) \
                     for file_name in INSTALLDB.get_files(package_name).list \
                     if fnmatch.fnmatch(file_name.path, "*/pkgconfig/*.pc")])
 
@@ -326,7 +326,7 @@ class LDD:
                                           env = os.environ).communicate()[0].strip().split(": ")
 
             objdump_needed = [line.strip().split()[1] for line in \
-                    os.popen("objdump -p \"%s\" | grep 'NEEDED'" % elf_file).readlines()]
+                    os.popen("objdump -p \"{}\" | grep 'NEEDED'".format(elf_file)).readlines()]
 
 
             # Process the various ldd and objdump outputs
diff --git i/inary/analyzer/urgent-packages.py w/inary/analyzer/urgent-packages.py
index 3fd0f1f1..02712542 100644
--- i/inary/analyzer/urgent-packages.py
+++ w/inary/analyzer/urgent-packages.py
@@ -29,11 +29,11 @@ def loadFile(_file):
 def getXmlData(_file):
     if os.path.exists(_file):
         return ciksemel.parse(_file)
-    elif os.path.exists("%s.bz2" % _file):
-        indexdata = bz2.decompress(file("%s.bz2" % _file).read())
+    elif os.path.exists("{}.bz2".format(_file)):
+        indexdata = bz2.decompress(open("{}.bz2".format(_file)).read())
         return ciksemel.parseString(indexdata)
     else:
-        print("%s not found" % indexfile)
+        print("{} not found".format(indexfile))
         sys.exit(1)
 
 def fillPackageDict(tag, _hasSpecFile, packageOf):
@@ -45,7 +45,7 @@ def fillPackageDict(tag, _hasSpecFile, packageOf):
         else:
             PackagePackagerName = tag.getTag("Source").getTag("Packager").getTagData("Name")
 
-        fullpath = "%s/%s" % (PackagePartOf.replace(".", "/"), PackageName)
+        fullpath = "{0}/{1}".format(PackagePartOf.replace(".", "/"), PackageName)
 
         if not PackagePackagerName in packageOf:
             packageOf[PackagePackagerName] = []
@@ -70,7 +70,7 @@ def findRequiredPackages(packageList, packagersList):
     for pkg in packageList:
         for packager in packagersList:
             for sourcePackage in packagersList[packager]:
-                if sourcePackage.endswith("/%s" % pkg):
+                if sourcePackage.endswith("/{}".format(pkg)):
                     if not packager in pkgdict:
                         pkgdict[packager] = []
                     pkgdict[packager].append(pkg)
@@ -78,7 +78,7 @@ def findRequiredPackages(packageList, packagersList):
     return pkgdict
 
 def urgent_packages(index, packages):
-    indexfile = "%s/%s" % (index, "inary-index.xml")
+    indexfile = "{0}/{1}".format(index, "inary-index.xml")
     packageList = loadFile(packages)
 
     xmldata = getXmlData(indexfile)
@@ -89,8 +89,8 @@ def urgent_packages(index, packages):
     tmp = list(requiredPackages.keys())
     tmp.sort()
 
-    for i in tmp:
-        print("-> %s" % i)
-        for k in requiredPackages[i]:
-             print("\t%s" % k)
+#    for i in tmp:
+#        print("-> %s" % i)
+#        for k in requiredPackages[i]:
+#             print("\t%s" % k)
 
diff --git i/inary/archive.py w/inary/archive.py
index a145c9f1..eeae7fc9 100644
--- i/inary/archive.py
+++ w/inary/archive.py
@@ -345,7 +345,7 @@ class ArchiveTar(ArchiveBase):
                                 if not new_path.startswith("/"):
                                     new_path = "/" + new_path
                                 print("Moving:", old_path, " -> ", new_path)
-                                os.system("mv -f %s %s" % (old_path, new_path))
+                                os.system("mv -f {0} {1}".format(old_path, new_path))
                             else:
                                 raise
                     try:
@@ -358,12 +358,12 @@ class ArchiveTar(ArchiveBase):
                                 if path.endswith("dbus") and "pid" in files:
                                     startservices.append("dbus")
                                     for service in ("NetworkManager", "connman", "wicd"):
-                                        if os.path.isfile("/etc/mudur/services/enabled/%s" % service):
+                                        if os.path.isfile("/etc/scom/services/enabled/{}".format(service)):
                                             startservices.append(service)
                                             os.system("service % stop" % service)
                                     os.system("service dbus stop")
                                     break
-                            os.system("mv -f %s %s.old" % (tarinfo.name, tarinfo.name))
+                            os.system("mv -f {0} {0}.old".format(tarinfo.name))
                         else:
                             raise
 
@@ -377,14 +377,14 @@ class ArchiveTar(ArchiveBase):
                     # Try to rename directory
                     try:
                         os.rename(tarinfo.name,
-                                  "%s.renamed-by-inary" % tarinfo.name)
+                                  "{}.renamed-by-inary".format(tarinfo.name))
                     except:
                         # If fails, try to remove it
                         shutil.rmtree(tarinfo.name)
 
             try:
                 self.tar.extract(tarinfo)
-                for service in startservices: os.system("service %s start" % service)
+                for service in startservices: os.system("service {} start".format(service))
             except OSError as e:
                 # Handle the case where an upper directory cannot
                 # be created because of a conflict with an existing
@@ -518,11 +518,9 @@ class ArchiveTarZ(ArchiveBase):
         self.file_path = util.remove_suffix(".Z", self.file_path)
 
         ret, out, err = util.run_batch(
-                "uncompress -cf %s.Z > %s" % (self.file_path, self.file_path))
+                "uncompress -cf {0}.Z > {0}".format(self.file_path))
         if ret != 0:
-            raise RuntimeError(
-                        _("Problem occured while uncompressing %s.Z file")
-                        % self.file_path)
+            raise RuntimeError(_("Problem occured while uncompressing {}.Z file").format(self.file_path))
 
         self.tar = tarfile.open(self.file_path)
 
@@ -583,7 +581,7 @@ class Archive7Zip(ArchiveBase):
         """Unpack 7z archive to a given target directory(target_dir)."""
 
         # e.g. 7z x -bd -o<target_directory> <archive.7z>
-        inary.util.run_batch("%s x -bd -o%s %s" % (self.cmd, target_dir, self.file_path))
+        inary.util.run_batch("{0} x -bd -o{1} {2}".format(self.cmd, target_dir, self.file_path))
 
 
 class ArchiveZip(ArchiveBase):
diff --git i/inary/atomicoperations.py w/inary/atomicoperations.py
index 0fa766c2..144dd354 100644
--- i/inary/atomicoperations.py
+++ w/inary/atomicoperations.py
@@ -68,7 +68,7 @@ class Install(AtomicOperation):
         repo = packagedb.which_repo(name)
         if repo:
             repodb = inary.db.repodb.RepoDB()
-            ctx.ui.info(_("Package %s found in repository %s") % (name, repo))
+            ctx.ui.info(_("Package {0} found in repository {1}").format(name, repo))
 
             repo = repodb.get_repo(repo)
             pkg = packagedb.get_package(name)
@@ -99,7 +99,7 @@ class Install(AtomicOperation):
                 pkg_path = os.path.join(os.path.dirname(repo.indexuri.get_uri()),
                                         str(uri.path()))
 
-            ctx.ui.info(_("Package URI: %s") % pkg_path, verbose=True)
+            ctx.ui.info(_("Package URI: {}").format(pkg_path), verbose=True)
 
             # Bug 4113
             cached_file = inary.package.Package.is_cached(pkg_path)
@@ -117,7 +117,7 @@ class Install(AtomicOperation):
 
             return install_op
         else:
-            raise Error(_("Package %s not found in any active repository.") % name)
+            raise Error(_("Package {} not found in any active repository.").format(name))
 
     def __init__(self, package_fname, ignore_dep = None, ignore_file_conflicts = None):
         if not ctx.filesdb: ctx.filesdb = inary.db.filesldb.FilesLDB()
@@ -144,9 +144,8 @@ class Install(AtomicOperation):
         # Any package should remove the package it replaces before
         self.check_replaces()
 
-        ctx.ui.status(_('Installing %s, version %s, release %s') %
-                (self.pkginfo.name, self.pkginfo.version,
-                 self.pkginfo.release))
+        ctx.ui.status(_('Installing {0.name}, version {0.version}, release {0.release}').format(self.pkginfo))
+
         ctx.ui.notify(inary.ui.installing, package=self.pkginfo, files=self.files)
 
         self.ask_reinstall = ask_reinstall
@@ -190,14 +189,13 @@ class Install(AtomicOperation):
             int(release)
             inary.version.make_version(version)
         except (ValueError, inary.version.InvalidVersionError):
-            raise Error(_("%s-%s is not a valid INARY version format") % (version, release))
+            raise Error(_("{}-{} is not a valid INARY version format").format(version, release))
 
     def check_relations(self):
         # check dependencies
         if not ctx.config.get_option('ignore_dependency'):
             if not self.pkginfo.installable():
-                raise Error(_("%s package cannot be installed unless the dependencies are satisfied") %
-                            self.pkginfo.name)
+                raise Error(_("{} package cannot be installed unless the dependencies are satisfied").format(self.pkginfo.name))
 
         # If it is explicitly specified that package conflicts with this package and also
         # we passed check_conflicts tests in operations.py than this means a non-conflicting
@@ -220,8 +218,8 @@ class Install(AtomicOperation):
         if file_conflicts:
             file_conflicts_str = ""
             for (pkg, existing_file) in file_conflicts:
-                file_conflicts_str += _("/%s from %s package\n") % (existing_file, pkg)
-            msg = _('File conflicts:\n%s') % file_conflicts_str
+                file_conflicts_str += _("/{0} from {1} package\n").format(existing_file, pkg)
+            msg = _('File conflicts:\n{}').format(file_conflicts_str)
             if self.ignore_file_conflicts:
                 ctx.ui.warning(msg)
             else:
@@ -248,7 +246,7 @@ class Install(AtomicOperation):
                 if ctx.get_option('store_lib_info') and pkg_version > iversion:
                     self.store_old_paths = os.path.join(ctx.config.old_paths_cache_dir(), pkg.name)
                     ctx.ui.info(_('Storing old paths info'))
-                    open(self.store_old_paths, "w").write("Version: %s\n" % iversion_s)
+                    open(self.store_old_paths, "w").write("Version: {}\n".format(iversion_s))
 
                 pkg_release = int(pkg.release)
                 irelease = int(irelease_s)
@@ -292,7 +290,7 @@ class Install(AtomicOperation):
         # Chowning for additional files
         for _file in self.package.get_files().list:
             fpath = util.join_path(ctx.config.dest_dir(), _file.path)
-            #print ("** chowning in postinstall (%s:%s)" % (_file.uid, _file.gid))
+            ctx.ui.debug("** chowning in postinstall ({0}:{1})".format(_file.uid, _file.gid))
             os.chown(fpath, int(_file.uid), int(_file.gid))
 
         if ctx.scom:
@@ -318,7 +316,7 @@ class Install(AtomicOperation):
                     )
                 ctx.ui.notify(inary.ui.configured, package = self.pkginfo, files = self.files)
             except inary.scomiface.Error:
-                ctx.ui.warning(_('%s configuration failed.') % self.pkginfo.name)
+                ctx.ui.warning(_('{} configuration failed.').format(self.pkginfo.name))
                 self.config_later = True
         else:
             self.config_later = True
@@ -410,7 +408,7 @@ class Install(AtomicOperation):
             if missing_old_files:
                 ctx.ui.warning(_("Unable to relocate following files. Reinstallation of this package is strongly recommended."))
                 for f in sorted(missing_old_files):
-                    ctx.ui.warning("    - %s" % f)
+                    ctx.ui.warning("    - {}".format(f))
 
         # remove left over files from the old package.
         def clean_leftovers():
@@ -507,7 +505,7 @@ class Install(AtomicOperation):
             fpath = os.path.join(ctx.const.scom_dir, pscom.script)
             # comar prefix is added to the pkg_dir while extracting comar
             # script file. so we'll use pkg_dir as destination.
-            ctx.ui.info(_('Storing %s') % fpath, verbose=True)
+            ctx.ui.info(_('Storing {}').format(fpath), verbose=True)
             self.package.extract_file_synced(fpath, self.package.pkg_dir())
 
     def update_databases(self):
@@ -575,13 +573,13 @@ class Remove(AtomicOperation):
         except inary.Error as e:
             # for some reason file was deleted, we still allow removes!
             ctx.ui.error(str(e))
-            ctx.ui.warning(_('File list could not be read for package %s, continuing removal.') % package_name)
+            ctx.ui.warning(_('File list could not be read for package {}, continuing removal.').format(package_name))
             self.files = inary.files.Files()
 
     def run(self):
         """Remove a single package"""
 
-        ctx.ui.status(_('Removing package %s') % self.package_name)
+        ctx.ui.status(_('Removing package {}').format(self.package_name))
         ctx.ui.notify(inary.ui.removing, package = self.package, files = self.files)
         if not self.installdb.has_package(self.package_name):
             raise Exception(_('Trying to remove nonexistent package ')
@@ -623,7 +621,7 @@ class Remove(AtomicOperation):
         # another as in #2911)
         #pkg, existing_file = ctx.filesdb.get_file(fileinfo.path)
         #if pkg != package_name:
-        #    ctx.ui.warning(_('Not removing conflicted file : %s') % fpath)
+        #    ctx.ui.warning(_('Not removing conflicted file : {}').format(fpath))
         #    return
 
         if fileinfo.type == ctx.const.conf:
@@ -649,11 +647,11 @@ class Remove(AtomicOperation):
             if os.path.isfile(fpath) or os.path.islink(fpath):
                 os.unlink(fpath)
                 if store_old_paths:
-                    open(store_old_paths, "a").write("%s\n" % fpath)
+                    open(store_old_paths, "a").write("{}\n".format(fpath))
             elif os.path.isdir(fpath) and not os.listdir(fpath):
                 os.rmdir(fpath)
             else:
-                ctx.ui.warning(_('Installed file %s does not exist on system [Probably you manually deleted]') % fpath)
+                ctx.ui.warning(_('Installed file {} does not exist on system [Probably you manually deleted]').format(fpath))
                 return
 
         # remove emptied directories
diff --git i/inary/cli/__init__.py w/inary/cli/__init__.py
index 983d775a..f4b0165b 100644
--- i/inary/cli/__init__.py
+++ w/inary/cli/__init__.py
@@ -30,23 +30,23 @@ class Exception(inary.Exception):
     pass
 
 #in old releases used this printu function
-#def printu(obj, err = False):
-#    if not isinstance(obj, str):
-#        obj = str(obj)
-#    if err:
-#        out = sys.stderr
-#    else:
-#        out = sys.stdout
-#    out.write(str(obj))
-#    out.flush()
-#
-
-def printu(obj,err = False):
+def printu(obj, err = False):
+    if not isinstance(obj, str):
+        obj = str(obj)
     if err:
-       sys.stdout.write(str(obj))
-    
-    else: 
-       sys.stdout.write(str(obj))
+        out = sys.stderr
+    else:
+        out = sys.stdout
+    out.write(str(obj))
+    out.flush()
+
+
+#def printu(obj,err = False):
+#    if err:
+#       sys.stdout.write(str(obj))
+#    
+#    else: 
+#       sys.stdout.write(str(obj))
     
 class CLI(inary.ui.UI):
     "Command Line Interface"
@@ -109,7 +109,7 @@ class CLI(inary.ui.UI):
                                       "column": _column,
                                       "rest": rest}
             if not noln:
-                new_msg = "%s\n" % new_msg
+                new_msg = "{}\n".format(new_msg)
         msg = new_msg
         self.output(str(msg), verbose=verbose)
 
@@ -117,7 +117,7 @@ class CLI(inary.ui.UI):
         # TODO: need to look at more kinds of info messages
         # let's cheat from KDE :)
         if not noln:
-            msg = '%s\n' % msg
+            msg = '%s\n'%(msg)
         self.output(str(msg), verbose=verbose)
 
     def warning(self, msg, verbose = False):
@@ -149,7 +149,7 @@ class CLI(inary.ui.UI):
 
     def choose(self, msg, opts):
         msg = str(msg)
-        prompt = msg + inary.util.colorize(' (%s)' % "/".join(opts), 'red')
+        prompt = msg + inary.util.colorize(' (%s)' %("/".join(opts)), 'red')
         while True:
             s = input(prompt.encode('utf-8'))
             for opt in opts:
@@ -204,15 +204,15 @@ class CLI(inary.ui.UI):
 
     def notify(self, event, **keywords):
         if event == inary.ui.installed:
-            msg = _('Installed %s') % keywords['package'].name
+            msg = _('Installed {}').format(keywords['package'].name)
         elif event == inary.ui.removed:
-            msg = _('Removed %s') % keywords['package'].name
+            msg = _('Removed {}').format(keywords['package'].name)
         elif event == inary.ui.upgraded:
-            msg = _('Upgraded %s') % keywords['package'].name
+            msg = _('Upgraded {}').format(keywords['package'].name)
         elif event == inary.ui.configured:
-            msg = _('Configured %s') % keywords['package'].name
+            msg = _('Configured {}').format(keywords['package'].name)
         elif event == inary.ui.extracting:
-            msg = _('Extracting the files of %s') % keywords['package'].name
+            msg = _('Extracting the files of {}').format(keywords['package'].name)
         else:
             msg = None
         if msg:
diff --git i/inary/cli/addrepo.py w/inary/cli/addrepo.py
index 6570bdea..68250f63 100644
--- i/inary/cli/addrepo.py
+++ w/inary/cli/addrepo.py
@@ -59,10 +59,10 @@ NB: We support only local files (e.g., /a/b/c) and http:// URIs at the moment
             name, indexuri = self.args
 
             if ctx.get_option('no_fetch'):
-                if not ctx.ui.confirm(_('Add %s repository without updating the database?\nBy confirming '
+                if not ctx.ui.confirm(_('Add {} repository without updating the database?\nBy confirming '
                                         'this you are also adding the repository to your system without '
                                         'checking the distribution of the repository.\n'
-                                        'Do you want to continue?') % name):
+                                        'Do you want to continue?').format(name)):
                     return
 
             Reactor.add_repo(name, indexuri, ctx.get_option('at'))
@@ -71,7 +71,7 @@ NB: We support only local files (e.g., /a/b/c) and http:// URIs at the moment
                 try:
                     Reactor.update_repo(name)
                 except (inary.Error, IOError):
-                    warning = _("%s repository could not be reached. Removing %s from system.") % (name, name)
+                    warning = _("{0} repository could not be reached. Removing {0} from system.").format(name)
                     self.warn_and_remove(warning, name)
         else:
             self.help()
diff --git i/inary/cli/blame.py w/inary/cli/blame.py
index 5d8fdde4..ba50343e 100644
--- i/inary/cli/blame.py
+++ w/inary/cli/blame.py
@@ -63,10 +63,10 @@ Usage: blame <package> ... <package>
                             return
 
     def print_package_info(self, package, hno=0):
-        s = _('Name: %s, version: %s, release: %s\n') % (
+        s = _('Name: {0}, version: {1}, release: {2}\n').format(
               package.name, package.history[hno].version, package.history[hno].release)
-        s += _('Package Maintainer: %s <%s>\n') % (str(package.source.packager.name), package.source.packager.email)
-        s += _('Release Updater: %s <%s>\n') % (package.history[hno].name, package.history[hno].email)
-        s += _('Update Date: %s\n') % package.history[hno].date
-        s += '\n%s\n' % package.history[hno].comment
+        s += _('Package Maintainer: {0} <{1}>\n').format(str(package.source.packager.name), package.source.packager.email)
+        s += _('Release Updater: {0.name} <{0.email}>\n').format(package.history[hno])
+        s += _('Update Date: {}\n').format(package.history[hno].date)
+        s += '\n{}\n'.format(package.history[hno].comment)
         ctx.ui.info(s)
diff --git i/inary/cli/check.py w/inary/cli/check.py
index bc50367a..59798d4c 100644
--- i/inary/cli/check.py
+++ w/inary/cli/check.py
@@ -87,7 +87,7 @@ class Check(command.Command, metaclass=command.autocommand):
         check_config = ctx.get_option('config')
 
         # Line prefix
-        prefix = _('Checking integrity of %s')
+        prefix = _('Checking integrity of {}')
 
         # Determine maximum length of messages for proper formatting
         maxpkglen = max([len(_p) for _p in pkgs])
@@ -95,8 +95,8 @@ class Check(command.Command, metaclass=command.autocommand):
         for pkg in pkgs:
             if self.installdb.has_package(pkg):
                 check_results = Reactor.check(pkg, check_config)
-                ctx.ui.info("%s    %s" % ((prefix % pkg),
-                                          ' ' * (maxpkglen - len(pkg))),
+                ctx.ui.info("{0}    {1}".format((prefix.format(pkg),
+                                          ' ' * (maxpkglen - len(pkg)))),
                             noln=True)
 
                 if check_results['missing'] or check_results['corrupted'] \
@@ -114,24 +114,24 @@ class Check(command.Command, metaclass=command.autocommand):
                 # Dump per file stuff
                 for fpath in check_results['missing']:
                     ctx.ui.info(util.colorize(
-                        _("Missing file: /%s") % fpath, 'brightred'))
+                        _("Missing file: /{}").format(fpath), 'brightred'))
 
                 for fpath in check_results['denied']:
                     ctx.ui.info(util.colorize(
-                        _("Access denied: /%s") % fpath, 'yellow'))
+                        _("Access denied: /{}").format(fpath), 'yellow'))
 
                 for fpath in check_results['corrupted']:
                     ctx.ui.info(util.colorize(
-                        _("Corrupted file: /%s") % fpath, 'brightyellow'))
+                        _("Corrupted file: /{}").format(fpath), 'brightyellow'))
 
                 for fpath in check_results['config']:
                     ctx.ui.info(util.colorize(
-                        _("Modified configuration file: /%s") % fpath,
+                        _("Modified configuration file: /{}").format(fpath),
                         'brightyellow'))
 
             else:
                 # Package is not installed
-                ctx.ui.info(_('Package %s not installed') % pkg)
+                ctx.ui.info(_('Package {} not installed').format(pkg))
 
         if not necessary_permissions:
             ctx.ui.info("")
diff --git i/inary/cli/command.py w/inary/cli/command.py
index 1beb094a..bc299132 100644
--- i/inary/cli/command.py
+++ w/inary/cli/command.py
@@ -31,7 +31,7 @@ class autocommand(type):
         longname, shortname = name
         def add_cmd(cmd):
             if cmd in Command.cmd_dict:
-                raise inary.cli.Error(_('Duplicate command %s') % cmd)
+                raise inary.cli.Error(_('Duplicate command {}').format(cmd))
             else:
                 Command.cmd_dict[cmd] = cls
         add_cmd(longname)
@@ -57,7 +57,7 @@ class Command(object):
             summary = trans.gettext(commandcls.__doc__).split('\n')[0]
             name = commandcls.name[0]
             if commandcls.name[1]:
-                name += ' (%s)' % commandcls.name[1]
+                name += ' ({})'.format(commandcls.name[1])
             s += ' %23s - %s\n' % (name, summary)
         return s
 
@@ -68,7 +68,7 @@ class Command(object):
             return Command.cmd_dict[cmd](args)
 
         if fail:
-            raise inary.cli.Error(_("Unrecognized command: %s") % cmd)
+            raise inary.cli.Error(_("Unrecognized command: {}").format(cmd))
         else:
             return None
 
@@ -127,7 +127,7 @@ class Command(object):
         if self.options.destdir:
             d = str(self.options.destdir)
             if not os.path.exists(d):
-                inary.cli.printu(_('Destination directory %s does not exist. Creating directory.\n') % d)
+                inary.cli.printu(_('Destination directory {} does not exist. Creating directory.\n').format(d))
                 os.makedirs(d)
             self.options.destdir = os.path.realpath(d)
 
@@ -176,14 +176,14 @@ class Command(object):
     def format_name(self):
         (name, shortname) = self.get_name()
         if shortname:
-            return "%s (%s)" % (name, shortname)
+            return "{0} ({1})".format(name, shortname)
         else:
             return name
 
     def help(self):
         """print help for the command"""
         trans = gettext.translation('inary', fallback=True)
-        print("%s: %s\n" % (self.format_name(), trans.gettext(self.__doc__)))
+        print("{0}: {1}".format(self.format_name(), trans.gettext(self.__doc__)))
         print(self.parser.format_option_help())
 
     def die(self):
@@ -222,11 +222,11 @@ class PisiHelpFormatter(optparse.HelpFormatter):
         optparse.HelpFormatter.__init__(
             self, indent_increment, max_help_position, width, short_first)
 
-        self._short_opt_fmt = "%s"
-        self._long_opt_fmt = "%s"
+        self._short_opt_fmt = "{}"
+        self._long_opt_fmt = "{}"
 
     def format_usage(self, usage):
-        return _("usage: %s\n") % usage
+        return _("usage: {}\n").format(usage)
 
     def format_heading(self, heading):
         return "%*s%s:\n" % (self.current_indent, "", heading)
@@ -234,16 +234,16 @@ class PisiHelpFormatter(optparse.HelpFormatter):
     def format_option_strings(self, option):
         """Return a comma-separated list of option strings & metavariables."""
         if option.takes_value():
-            short_opts = [self._short_opt_fmt % sopt
+            short_opts = [self._short_opt_fmt.format(sopt)
                           for sopt in option._short_opts]
-            long_opts = [self._long_opt_fmt % lopt
+            long_opts = [self._long_opt_fmt.format(lopt)
                          for lopt in option._long_opts]
         else:
             short_opts = option._short_opts
             long_opts = option._long_opts
 
         if long_opts and short_opts:
-            opt = "%s [%s]" % (short_opts[0], long_opts[0])
+            opt = "{0} [{1}]".format(short_opts[0], long_opts[0])
         else:
             opt = long_opts[0] or short_opts[0]
 
diff --git i/inary/cli/delta.py w/inary/cli/delta.py
index 774c50f1..612cb15c 100644
--- i/inary/cli/delta.py
+++ w/inary/cli/delta.py
@@ -71,9 +71,9 @@ class Delta(command.Command, metaclass=command.autocommand):
             ctx.ui.info(_("Supported package formats:"))
             for format in inary.package.Package.formats:
                 if format == inary.package.Package.default_format:
-                    ctx.ui.info(_("  %s (default)") % format)
+                    ctx.ui.info(_("  {} (default)").format(format))
                 else:
-                    ctx.ui.info("  %s" % format)
+                    ctx.ui.info("  {}".format(format))
             return
 
         new_package = ctx.get_option("newest_package")
diff --git i/inary/cli/emerge.py w/inary/cli/emerge.py
index 75511a68..73b50079 100644
--- i/inary/cli/emerge.py
+++ w/inary/cli/emerge.py
@@ -67,7 +67,7 @@ You can also give the name of a component.
             sources = self.args
 
         if ctx.get_option('output_dir'):
-            ctx.ui.info(_('Output directory: %s') % ctx.config.options.output_dir)
+            ctx.ui.info(_('Output directory: {}').format(ctx.config.options.output_dir))
         else:
             ctx.ui.info(_('Outputting binary packages in the package cache.'))
             ctx.config.options.output_dir = ctx.config.cached_packages_dir()
diff --git i/inary/cli/graph.py w/inary/cli/graph.py
index 5482c981..99848a11 100644
--- i/inary/cli/graph.py
+++ w/inary/cli/graph.py
@@ -68,7 +68,7 @@ the package in graphviz format to 'pgraph.dot'.
 
             if ctx.get_option('repository'):
                 repo = ctx.get_option('repository')
-                ctx.ui.info(_('Plotting packages in repository %s') % repo)
+                ctx.ui.info(_('Plotting packages in repository {}').format(repo))
             else:
                 repo = None
                 ctx.ui.info(_('Plotting a graph of relations among all repository packages'))
diff --git i/inary/cli/history.py w/inary/cli/history.py
index a9185a49..51b3a3ca 100644
--- i/inary/cli/history.py
+++ w/inary/cli/history.py
@@ -62,9 +62,9 @@ Lists previous operations.""")
 
     def print_history(self):
         for operation in self.historydb.get_last(ctx.get_option('last')):
-            print(_("Operation #%d: %s") % (operation.no, opttrans[operation.type]))
-            print(_("Date: %s %s") % (operation.date, operation.time))
-            print()
+            print(_("Operation #{0}: {1}").format(operation.no, opttrans[operation.type]))
+            print(_("Date: {0.date} {0.time}").format(operation))
+
 
             if operation.type == "snapshot":
                 print(_("    * There are %d packages in this snapshot.") % len(operation.packages))
diff --git i/inary/cli/inarycli.py w/inary/cli/inarycli.py
index d69a75ec..58af2c6e 100644
--- i/inary/cli/inarycli.py
+++ w/inary/cli/inarycli.py
@@ -135,7 +135,7 @@ class InaryCLI(object):
 
         self.command = command.Command.get_command(cmd_name, args=orig_args)
         if not self.command:
-            raise inary.cli.Error(_("Unrecognized command: %s") % cmd_name)
+            raise inary.cli.Error(_("Unrecognized command: {}").format(cmd_name))
 
     def die(self):
         inary.cli.printu('\n' + self.parser.format_help())
diff --git i/inary/cli/info.py w/inary/cli/info.py
index 239f3cef..fe4efa6c 100644
--- i/inary/cli/info.py
+++ w/inary/cli/info.py
@@ -82,7 +82,7 @@ Usage: info <package1> <package2> ... <packagen>
                         if not self.options.short:
                             ctx.ui.info(str(component))
                         else:
-                            ctx.ui.info("%s - %s" % (component.name, component.summary))
+                            ctx.ui.info("{0.name} - {0.summary}".format(component))
 
         # info of packages
         for arg in self.args:
@@ -141,7 +141,7 @@ Usage: info <package1> <package2> ... <packagen>
 
     def inaryfile_info(self, package):
         metadata, files = Reactor.info_file(package)
-        ctx.ui.formatted_output(_("Package file: %s") % package)
+        ctx.ui.formatted_output(_("Package file: {}").format(package))
 
         self.print_metadata(metadata)
         if self.options.files or self.options.files_path:
@@ -162,7 +162,7 @@ Usage: info <package1> <package2> ... <packagen>
 
             self.print_metadata(metadata, self.installdb)
         else:
-            ctx.ui.info(_("%s package is not installed") % package)
+            ctx.ui.info(_("{} package is not installed").format(package))
 
     def packagedb_info(self, package):
         if self.packagedb.has_package(package):
@@ -170,10 +170,10 @@ Usage: info <package1> <package2> ... <packagen>
             if self.options.short:
                 ctx.ui.formatted_output(_("[binary] "), noln=True, column=" ")
             else:
-                ctx.ui.info(_('Package found in %s repository:') % repo)
+                ctx.ui.info(_('Package found in {} repository:').format(repo))
             self.print_metadata(metadata, self.packagedb)
         else:
-            ctx.ui.info(_("%s package is not found in binary repositories") % package)
+            ctx.ui.info(_("{} package is not found in binary repositories").format(package))
 
     def sourcedb_info(self, package):
         if self.sourcedb.has_spec(package):
@@ -182,7 +182,7 @@ Usage: info <package1> <package2> ... <packagen>
             if self.options.short:
                 ctx.ui.formatted_output(_("[source] "), noln=True, column=" ")
             else:
-                ctx.ui.info(_('Package found in %s repository:') % repo)
+                ctx.ui.info(_('Package found in {} repository:').format(repo))
             self.print_specdata(spec, self.sourcedb)
         else:
-            ctx.ui.info(_("%s package is not found in source repositories") % package)
+            ctx.ui.info(_("{} package is not found in source repositories").format(package))
diff --git i/inary/cli/install.py w/inary/cli/install.py
index 47bc6ab4..7b0d8f64 100644
--- i/inary/cli/install.py
+++ w/inary/cli/install.py
@@ -91,7 +91,7 @@ expanded to package names.
                     else:
                         packages.extend(self.componentdb.get_union_packages(name, walk=True))
                 else:
-                    ctx.ui.info(_('There is no component named %s') % name)
+                    ctx.ui.info(_('There is no component named {}').format(name))
 
         packages.extend(self.args)
 
diff --git i/inary/cli/listavailable.py w/inary/cli/listavailable.py
index 28933865..3aca4f56 100644
--- i/inary/cli/listavailable.py
+++ w/inary/cli/listavailable.py
@@ -63,7 +63,7 @@ all repositories.
         else:
             # print for all repos
             for repo in Reactor.list_repos():
-                ctx.ui.info(_("Repository : %s\n") % repo)
+                ctx.ui.info(_("Repository : {}\n").format(str(repo)))
                 self.print_packages(repo)
 
     def print_packages(self, repo):
@@ -99,4 +99,4 @@ all repositories.
                 ctx.ui.info(str(package)+'\n')
             else:
                 package.name += ' ' * max(0, maxlen - len(p))
-                ctx.ui.info('%s - %s ' % (package.name, str(package.summary)))
+                ctx.ui.info('{0} - {1} '.format(package.name, str(package.summary)))
diff --git i/inary/cli/listcomponents.py w/inary/cli/listcomponents.py
index 1dda5048..1ce215ae 100644
--- i/inary/cli/listcomponents.py
+++ w/inary/cli/listcomponents.py
@@ -58,4 +58,4 @@ repositories.
                 #if p in installed_list:
                 #    p = util.colorize(p, 'cyan')
                 p = p + ' ' * max(0, 15 - lenp)
-                ctx.ui.info('%s - %s ' % (component.name, str(component.summary)))
+                ctx.ui.info('{0} - {1} '.format(component.name, str(component.summary)))
diff --git i/inary/cli/listinstalled.py w/inary/cli/listinstalled.py
index aa33682a..3a19c9d8 100644
--- i/inary/cli/listinstalled.py
+++ w/inary/cli/listinstalled.py
@@ -85,4 +85,4 @@ Usage: list-installed
                 ctx.ui.info('%-20s  |%s' % (package.name, inst_info.one_liner()))
             else:
                 package.name = package.name + ' ' * (maxlen - len(package.name))
-                ctx.ui.info('%s - %s' % (package.name, str(package.summary)))
+                ctx.ui.info('{0} - {1}'.format(package.name, str(package.summary)))
diff --git i/inary/cli/listnewest.py w/inary/cli/listnewest.py
index 5ca06984..f42402c3 100644
--- i/inary/cli/listnewest.py
+++ w/inary/cli/listnewest.py
@@ -72,9 +72,9 @@ packages from all repositories.
             return
 
         if since:
-            ctx.ui.info(_("Packages added to %s since %s:\n") % (repo, since))
+            ctx.ui.info(_("Packages added to {0} since {1}:\n").format(repo, since))
         else:
-            ctx.ui.info(_("Packages added to %s:") % (repo))
+            ctx.ui.info(_("Packages added to {}:").format(repo))
 
         # maxlen is defined dynamically from the longest package name (#9021)
         maxlen = max([len(_p) for _p in l])
@@ -84,7 +84,7 @@ packages from all repositories.
             package = self.packagedb.get_package(p, repo)
             lenp = len(p)
             p = p + ' ' * max(0, maxlen - lenp)
-            ctx.ui.info('%s - %s ' % (p, str(package.summary)))
+            ctx.ui.info('{0} - {1} '.format(p, str(package.summary)))
 
         print()
 
diff --git i/inary/cli/listrepo.py w/inary/cli/listrepo.py
index 62ee2fd0..b3be61ec 100644
--- i/inary/cli/listrepo.py
+++ w/inary/cli/listrepo.py
@@ -39,8 +39,8 @@ Lists currently tracked repositories.
         for repo in self.repodb.list_repos(only_active=False):
             active = _("active") if self.repodb.repo_active(repo) else _("inactive")
             if active == _("active"):
-                ctx.ui.info(util.colorize(_("%s [%s]") % (repo, active), 'green'))
+                ctx.ui.info(util.colorize(_("{0} [{1}]").format(repo, active), 'green'))
             else:
-                ctx.ui.info(util.colorize(_("%s [%s]") % (repo, active), 'red'))
+                ctx.ui.info(util.colorize(_("{0} [{1}]").format(repo, active), 'red'))
             print('  ', self.repodb.get_repo_url(repo))
 
diff --git i/inary/cli/listsources.py w/inary/cli/listsources.py
index fea726cf..c1238d24 100644
--- i/inary/cli/listsources.py
+++ w/inary/cli/listsources.py
@@ -56,4 +56,4 @@ Gives a brief list of sources published in the repositories.
                 #if p in installed_list:
                 #    p = util.colorize(p, 'cyan')
                 p = p + ' ' * max(0, 15 - lenp)
-                ctx.ui.info('%s - %s' % (sf.source.name, str(sf.source.summary)))
+                ctx.ui.info('{0} - {1}'.format(sf.source.name, str(sf.source.summary)))
diff --git i/inary/cli/listupgrades.py w/inary/cli/listupgrades.py
index 0d027e97..69d7a283 100644
--- i/inary/cli/listupgrades.py
+++ w/inary/cli/listupgrades.py
@@ -81,4 +81,4 @@ Lists the packages that will be upgraded.
                 ctx.ui.info('%-20s |%s ' % (package.name, inst_info.one_liner()))
             else:
                 package.name = package.name + ' ' * (maxlen - len(package.name))
-                ctx.ui.info('%s - %s' % (package.name, str(package.summary)))
+                ctx.ui.info('{0} - {1}'.format(package.name, str(package.summary)))
diff --git i/inary/cli/search.py w/inary/cli/search.py
index e2db783f..984556e8 100644
--- i/inary/cli/search.py
+++ w/inary/cli/search.py
@@ -67,7 +67,7 @@ database.
             return
 
         cs = ctx.get_option("case_sensitive")
-        replace = re.compile("(%s)" % "|".join(self.args), 0 if cs else re.I)
+        replace = re.compile("({})".format("|".join(self.args)), 0 if cs else re.I)
         lang = ctx.get_option('language')
         repo = ctx.get_option('repository')
         name = ctx.get_option('name')
@@ -110,4 +110,4 @@ database.
 
             name += ' ' * max(0, maxlen - lenp)
 
-            ctx.ui.info('%s - %s' % (name, summary))
+            ctx.ui.info('{0} - {1}'.format(name, summary))
diff --git i/inary/cli/searchfile.py w/inary/cli/searchfile.py
index 8b2b8a97..a88e096a 100644
--- i/inary/cli/searchfile.py
+++ w/inary/cli/searchfile.py
@@ -45,10 +45,10 @@ Finds the installed package which contains the specified file.
         found = Reactor.search_file(path)
         for pkg, files in found:
             for pkg_file in files:
-                ctx.ui.info(_("Package %s has file /%s") % (pkg, pkg_file))
+                ctx.ui.info(_("Package {0} has file /{1}").format(pkg, pkg_file))
 
         if not found:
-            ctx.ui.error(_("Path '%s' does not belong to an installed package") % path)
+            ctx.ui.error(_("Path '{}' does not belong to an installed package").format(path))
 
     def run(self):
 
@@ -61,5 +61,5 @@ Finds the installed package which contains the specified file.
         # search among existing files
         for path in self.args:
             if not ctx.config.options.quiet:
-                ctx.ui.info(_('Searching for %s') % path)
+                ctx.ui.info(_('Searching for {}').format(path))
             self.search_file(path)
diff --git i/inary/config.py w/inary/config.py
index 998ee2bd..3a1ff341 100644
--- i/inary/config.py
+++ w/inary/config.py
@@ -80,8 +80,7 @@ class Config(object, metaclass=inary.util.Singleton):
                 self.__dest_dir = self.values.general.destinationdirectory
 
             if not os.path.exists(self.__dest_dir):
-                ctx.ui.warning(_("Destination directory %s does not exist. "
-                                 "Creating it.") % self.__dest_dir)
+                ctx.ui.warning(_("Destination directory {} does not exist. Creating it.").format(self.__dest_dir))
                 os.makedirs(self.__dest_dir)
 
         return self.__dest_dir
diff --git i/inary/configfile.py w/inary/configfile.py
index d3bf9f3a..890c6ada 100644
--- i/inary/configfile.py
+++ w/inary/configfile.py
@@ -127,7 +127,7 @@ class ConfigurationSection(object):
         elif section == "directories":
             self.defaults = DirectoriesDefaults
         else:
-            e = _("No section by name '%s'") % section
+            e = _("No section by name '{}'").format(section)
             raise Error(e)
 
         self.section = section
@@ -288,7 +288,7 @@ class ConfigurationFile(object):
                             value = self.parser.get(sect, opt)
                             # Fix continuations.
                             value = value.replace("\n", "\n\t")
-                            current.write("%s%s%s%s\n" % (opt, padded_vi,
+                            current.write("{0}{1}{2}{3}\n".format(opt, padded_vi,
                                                           value, comment))
                             written.append((sect, opt))
         if sect:
@@ -312,14 +312,14 @@ class ConfigurationFile(object):
                     output = current
                     if len(written) > 0:
                     	output.write("\n")
-                    output.write("[%s]\n" % (sect,))
+                    output.write("[{}]\n".format(sect))
                     sections[sect] = None
                 for opt in opts:
                     if opt != "__name__" and not (sect, opt) in written:
                         value = self.parser.get(sect, opt)
                         # Fix continuations.
                         value = value.replace("\n", "\n\t")
-                        output.write("%s%s%s\n" % (opt, padded_vi, value))
+                        output.write("{0}{1}{2}\n".format(opt, padded_vi, value))
                         written.append((sect, opt))
         # Copy across the new file.
         fp.seek(0)
diff --git i/inary/constants.py w/inary/constants.py
index 6514efae..1ae61605 100644
--- i/inary/constants.py
+++ w/inary/constants.py
@@ -27,13 +27,13 @@ class _constant:
 
     def __setattr__(self, name, value):
         if name in self.__dict__:
-            raise self.ConstError(_("Can't rebind constant: %s") % name)
+            raise self.ConstError(_("Can't rebind constant: {}").format(name))
         # Binding an attribute once to a const is available
         self.__dict__[name] = value
 
     def __delattr__(self, name):
         if name in self.__dict__:
-            raise self.ConstError(_("Can't unbind constant: %s") % name)
+            raise self.ConstError(_("Can't unbind constant: {}").format(name))
         # we don't have an attribute by this name
         raise NameError(name)
 
diff --git i/inary/data/component.py w/inary/data/component.py
index 3aece9e0..155cf952 100644
--- i/inary/data/component.py
+++ w/inary/data/component.py
@@ -45,7 +45,7 @@ class Maintainer(xmlfile.XmlFile, metaclass=autoxml.autoxml):
     t_Email = [autoxml.String, autoxml.mandatory]
 
     def __str__(self):
-        s = "%s <%s>" % (self.name, self.email)
+        s = "{} <{}>".format(self.name, self.email)
         return s
 
 class Component(xmlfile.XmlFile, metaclass=autoxml.autoxml):
diff --git i/inary/data/files.py w/inary/data/files.py
index 66f283d5..1f91f0e2 100644
--- i/inary/data/files.py
+++ w/inary/data/files.py
@@ -30,7 +30,7 @@ class FileInfo(metaclass=autoxml.autoxml):
     t_Replace = [ autoxml.String, autoxml.optional ]
 
     def __str__(self):
-        s = "/%s, type: %s, size: %s, sha1sum: %s" %  (self.path, self.type,
+        s = "/{0}, type: {1}, size: {2}, sha1sum: {3}".format(self.path, self.type,
                                                       self.size, self.hash)
         return s
 
diff --git i/inary/data/history.py w/inary/data/history.py
index 7bd1addd..96021a49 100644
--- i/inary/data/history.py
+++ w/inary/data/history.py
@@ -42,7 +42,7 @@ class Repo(metaclass = autoxml.autoxml):
         # "update", "remove", "add"
         operation = ""
         if self.operation == "update":
-            return _("%s repository is updated.") % self.name
+            return _("{0} repository is updated.").format(self.name)
         elif self.operation == "add":
             pass # TBD
         elif self.operation == "remove":
@@ -62,17 +62,17 @@ class Package(metaclass = autoxml.autoxml):
         operation = ""
         if self.operation == "upgrade":
             if self.type == "delta":
-                return _("%s is upgraded from %s to %s with delta.") % (self.name, self.before, self.after)
+                return _("{0} is upgraded from {1} to {2} with delta.").format(self.name, self.before, self.after)
             else:
-                return _("%s is upgraded from %s to %s.") % (self.name, self.before, self.after)
+                return _("{0} is upgraded from {1} to {2}.").format(self.name, self.before, self.after)
         elif self.operation == "remove":
-            return _("%s %s is removed.") % (self.name, self.before)
+            return _("{0} {1} is removed.").format(self.name, self.before)
         elif self.operation == "install":
-            return _("%s %s is installed.") % (self.name, self.after)
+            return _("{0} {1} is installed.").format(self.name, self.after)
         elif self.operation == "reinstall":
-            return _("%s %s is reinstalled.") % (self.name, self.after)
+            return _("{0} {1} is reinstalled.").format(self.name, self.after)
         elif self.operation == "downgrade":
-            return _("%s is downgraded from %s to %s.") % (self.name, self.before, self.after)
+            return _("{0} is downgraded from {1} to {2}.").format(self.name, self.before, self.after)
         else:
             return ""
 
@@ -100,7 +100,7 @@ class History(xmlfile.XmlFile, metaclass=autoxml.autoxml):
             raise Exception(_("Unknown package operation"))
 
         opno = self._get_latest()
-        self.histfile = "%s_%s.xml" % (opno, operation)
+        self.histfile = "{}_{}.xml".format(opno, operation)
 
         year, month, day, hour, minute = time.localtime()[0:5]
         self.operation.type = operation
diff --git i/inary/data/index.py w/inary/data/index.py
index ed07a01a..e2e834c6 100644
--- i/inary/data/index.py
+++ w/inary/data/index.py
@@ -92,8 +92,8 @@ class Index(xmlfile.XmlFile, metaclass=autoxml.autoxml):
                 pkgpath = os.path.join(repo_uri,
                                        util.parse_package_dir_path(fn))
                 if not os.path.isdir(pkgpath): os.makedirs(pkgpath)
-                ctx.ui.info("%-80.80s\r" % (_('Sorting: %s ') %
-                    fn), noln = False if ctx.config.get_option("verbose") else True)
+                ctx.ui.info("%-80.80s\r" % (_('Sorting:  %s').format(fn)),
+                            noln = False if ctx.config.get_option("verbose") else True)
                 shutil.copy2(os.path.join(repo_uri, fn), pkgpath)
                 os.remove(os.path.join(repo_uri, fn))
                 pkgs_sorted = True
@@ -175,7 +175,7 @@ class Index(xmlfile.XmlFile, metaclass=autoxml.autoxml):
                     sorted_pkgs[key] = [pkg]
             self.packages = []
             for key, pkgs in sorted(sorted_pkgs.items()):
-                ctx.ui.info("%-80.80s\r" % (_("Adding packages from directory %s... " % key)), noln=True)
+                ctx.ui.info("%-80.80s\r" % (_("Adding packages from directory {}... ".format(key))), noln=True)
                 try:
                     # Add binary packages to index using a process pool
                     self.packages.extend(pool.map(add_package, pkgs))
@@ -184,7 +184,7 @@ class Index(xmlfile.XmlFile, metaclass=autoxml.autoxml):
                     pool.join()
                     ctx.ui.info("")
                     raise
-                ctx.ui.info("%-80.80s\r" % (_("Adding packages from directory %s... done." % key)))
+                ctx.ui.info("%-80.80s\r" % (_("Adding packages from directory {}... done.".format(key))))
 
         ctx.ui.info("")
         pool.close()
@@ -194,8 +194,7 @@ def add_package(params):
     try:
         path, deltas, repo_uri = params
 
-        ctx.ui.info("%-80.80s\r" % (_('Adding package to index: %s') %
-            os.path.basename(path)), noln = True)
+        ctx.ui.info("%-80.80s\r" % (_('Adding package to index: {}').format(os.path.basename(path))), noln = True)
 
         package = inary.package.Package(path, 'r')
         md = package.get_metadata()
@@ -210,7 +209,7 @@ def add_package(params):
         errs = md.errors()
         if md.errors():
             ctx.ui.info("")
-            ctx.ui.error(_('Package %s: metadata corrupt, skipping...') % md.package.name)
+            ctx.ui.error(_('Package {}: metadata corrupt, skipping...').format(md.package.name))
             ctx.ui.error(str(Error(*errs)))
         else:
             # No need to carry these with index (#3965)
@@ -267,7 +266,7 @@ def add_components(path):
     #try:
     return components_xml.components
     #except:
-    #    raise Error(_('Component in %s is corrupt') % path)
+    #    raise Error(_('Component in {} is corrupt').format(path))
     #ctx.ui.error(str(Error(*errs)))
 
 def add_distro(path):
@@ -277,7 +276,7 @@ def add_distro(path):
     distro.read(path)
     return distro
     #except:
-    #    raise Error(_('Distribution in %s is corrupt') % path)
+    #    raise Error(_('Distribution in {} is corrupt').format(path))
     #ctx.ui.error(str(Error(*errs)))
 
 def add_spec(params):
@@ -292,8 +291,8 @@ def add_spec(params):
         else:
             sf.source.sourceURI = util.removepathprefix(repo_uri, path)
 
-        ctx.ui.info("%-80.80s\r" % (_('Adding %s to source index') %
-            path), noln = False if ctx.config.get_option("verbose") else True)
+        ctx.ui.info("%-80.80s\r" % (_('Adding {} to source index').format(path)),
+                                    noln = False if ctx.config.get_option("verbose") else True)
         return sf
 
     except KeyboardInterrupt:
diff --git i/inary/data/metadata.py w/inary/data/metadata.py
index d3505a09..94dceb86 100644
--- i/inary/data/metadata.py
+++ w/inary/data/metadata.py
@@ -70,17 +70,17 @@ class Package(specfile.Package, xmlfile.XmlFile, metaclass=autoxml.autoxml):
         i_size = util.human_readable_size(self.installedSize)
         size = "%.2f %s" % (i_size[0], i_size[1])
 
-        s += _('Distribution: %s, Dist. Release: %s\n') % \
-              (self.distribution, self.distributionRelease)
-        s += _('Architecture: %s, Installed Size: %s') % \
-              (self.architecture, size)
+        s += _('Distribution: {0}, Dist. Release: {1}\n').format(
+               self.distribution, self.distributionRelease)
+        s += _('Architecture: {0}, Installed Size: {1}').format(
+               self.architecture, size)
 
         if self.packageSize:
             p_size = util.human_readable_size(self.packageSize)
             size = "%.2f %s" % (p_size[0], p_size[1])
-            s += _(', Package Size: %s') % size
+            s += _(', Package Size: {}').format(size)
 
-        s += _(', install.tar.xz sha1sum: %s') % self.installTarHash
+        s += _(', install.tar.xz sha1sum: {}').format(self.installTarHash)
 
         return s
 
diff --git i/inary/data/pgraph.py w/inary/data/pgraph.py
index a08dfc91..32c1be5b 100644
--- i/inary/data/pgraph.py
+++ w/inary/data/pgraph.py
@@ -23,7 +23,7 @@ class CycleException(inary.Exception):
         self.cycle = cycle
 
     def __str__(self):
-        return _('Encountered cycle %s') % self.cycle
+        return _('Encountered cycle {}').format(self.cycle)
 
 class Digraph(object):
 
diff --git i/inary/data/specfile.py w/inary/data/specfile.py
index f89a7d16..0d827a5a 100644
--- i/inary/data/specfile.py
+++ w/inary/data/specfile.py
@@ -45,7 +45,7 @@ class Packager(metaclass= autoxml.autoxml):
     t_Email = [autoxml.String, autoxml.mandatory]
 
     def __str__(self):
-        s = "%s <%s>" % (self.name, self.email)
+        s = "{} <{}>".format(self.name, self.email)
         return s
 
 
@@ -58,9 +58,9 @@ class AdditionalFile(metaclass= autoxml.autoxml):
     a_group = [autoxml.String, autoxml.optional]
 
     def __str__(self):
-        s = "%s -> %s " % (self.filename, self.target)
+        s = "{0} -> {1} ".format(self.filename, self.target)
         if self.permission:
-            s += '(%s)' % self.permission
+            s += '({})'.format(self.permission)
         return s
 
 class Type(metaclass= autoxml.autoxml):
@@ -146,7 +146,7 @@ class ScomProvide(metaclass= autoxml.autoxml):
     def __str__(self):
         # FIXME: descriptive enough?
         s = self.script
-        s += ' (' + self.om + '%s' % (' for %s' % self.name if self.name else '') + ')'
+        s += ' (' + self.om + '{}'.format(' for {}'.format(self.name) if self.name else '') + ')'
         return s
 
 class Archive(metaclass= autoxml.autoxml):
@@ -160,7 +160,7 @@ class Archive(metaclass= autoxml.autoxml):
         self.name = os.path.basename(str(self.uri))
 
     def __str__(self):
-        s = _('URI: %s, type: %s, sha1sum: %s') % (self.uri, self.type, self.sha1sum)
+        s = _('URI: {0}, type: {1}, sha1sum: {2}') % (self.uri, self.type, self.sha1sum)
         return s
 
 class Source(metaclass= autoxml.autoxml):
@@ -190,10 +190,10 @@ class AnyDependency(metaclass= autoxml.autoxml):
     t_Dependencies = [[inary.analyzer.dependency.Dependency], autoxml.optional, "Dependency"]
 
     def __str__(self):
-        return "{%s}" % _(" or ").join([str(dep) for dep in self.dependencies])
+        return "{{}}".format(_(" or ").join([str(dep) for dep in self.dependencies]))
 
     def name(self):
-        return "{%s}" % _(" or ").join([dep.package for dep in self.dependencies])
+        return "{{}}".format(_(" or ").join([dep.package for dep in self.dependencies]))
 
     def decode_hook(self, node, errs, where):
         self.package = self.dependencies[0].package
@@ -270,7 +270,7 @@ class Package(metaclass= autoxml.autoxml):
     def satisfies_runtime_dependencies(self):
         for dep in self.runtimeDependencies():
             if not dep.satisfied_by_installed():
-                ctx.ui.error(_('%s dependency of package %s is not satisfied') % (dep, self.name))
+                ctx.ui.error(_('{0} dependency of package {1} is not satisfied').format(dep, self.name))
                 return False
         return True
 
@@ -366,12 +366,12 @@ class Package(metaclass= autoxml.autoxml):
         return actions
 
     def __str__(self):
-        s = _('Name: %s, version: %s, release: %s\n') \
-                % (self.name, self.version, self.release)
-        s += _('Summary: %s\n') % str(self.summary)
-        s += _('Description: %s\n') % str(self.description)
-        s += _('Licenses: %s\n') % ", ".join(self.license)
-        s += _('Component: %s\n') % str(self.partOf)
+        s = _('Name: {0}, version: {1}, release: {2}\n').format(
+              self.name, self.version, self.release)
+        s += _('Summary: {}\n').format(str(self.summary))
+        s += _('Description: {}\n').format(str(self.description))
+        s += _('Licenses: {}\n').format(", ".join(self.license))
+        s += _('Component: {}\n').format(str(self.partOf))
         s += _('Provides: ')
         for x in self.providesScom:
            s += x.om + ' '
@@ -437,7 +437,7 @@ class SpecFile(xmlfile.XmlFile, metaclass=autoxml.autoxml):
         try:
             doc = ciksemel.parse(path)
         except Exception as e:
-            raise Error(_("File '%s' has invalid XML") % (path) )
+            raise Error(_("File '{}' has invalid XML").format(path) )
 
         if doc.getTag("Source").getTagData("Name") == self.source.name:
             # Set source package translations
@@ -450,12 +450,12 @@ class SpecFile(xmlfile.XmlFile, metaclass=autoxml.autoxml):
                     break
 
     def __str__(self):
-        s = _('Name: %s, version: %s, release: %s\n') % (
+        s = _('Name: {}, version: {}, release: {}\n').format(
               self.source.name, self.history[0].version, self.history[0].release)
-        s += _('Summary: %s\n') % str(self.source.summary)
-        s += _('Description: %s\n') % str(self.source.description)
-        s += _('Licenses: %s\n') % ", ".join(self.source.license)
-        s += _('Component: %s\n') % str(self.source.partOf)
+        s += _('Summary: {}\n').format(str(self.source.summary))
+        s += _('Description: {}\n').format(str(self.source.description))
+        s += _('Licenses: {}\n').format(", ".join(self.source.license))
+        s += _('Component: {}\n').format(str(self.source.partOf))
         s += _('Build Dependencies: ')
         for x in self.source.buildDependencies:
            s += x.package + ' '
diff --git i/inary/db/componentdb.py w/inary/db/componentdb.py
index b9c112ce..931cbd1c 100644
--- i/inary/db/componentdb.py
+++ w/inary/db/componentdb.py
@@ -66,17 +66,17 @@ class ComponentDB(lazydb.LazyDB):
         return self.cdb.get_item_keys(repo)
 
     def search_component(self, terms, lang=None, repo=None):
-        rename = '<LocalName xml:lang="(%s|en)">.*?%s.*?</LocalName>'
-        resum = '<Summary xml:lang="(%s|en)">.*?%s.*?</Summary>'
-        redesc = '<Description xml:lang="(%s|en)">.*?%s.*?</Description>'
+        rename = '<LocalName xml:lang="({0}|en)">.*?{1}.*?</LocalName>'
+        resum = '<Summary xml:lang="({0}|en)">.*?{1}.*?</Summary>'
+        redesc = '<Description xml:lang="({0}|en)">.*?{1}.*?</Description>'
 
         if not lang:
             lang = inary.sxml.autoxml.LocalText.get_lang()
         found = []
         for name, xml in self.cdb.get_items_iter(repo):
-            if name not in found and terms == [term for term in terms if re.compile(rename % (lang, term), re.I).search(xml) or \
-                                                         re.compile(resum % (lang, term), re.I).search(xml) or \
-                                                         re.compile(redesc % (lang, term), re.I).search(xml)]:
+            if name not in found and terms == [term for term in terms if re.compile(rename.format(lang, term), re.I).search(xml) or \
+                                                         re.compile(resum.format(lang, term), re.I).search(xml) or \
+                                                         re.compile(redesc.format(lang, term), re.I).search(xml)]:
                 found.append(name)
         return found
 
@@ -84,7 +84,7 @@ class ComponentDB(lazydb.LazyDB):
     def get_component(self, component_name, repo = None):
 
         if not self.has_component(component_name, repo):
-            raise Exception(_('Component %s not found') % component_name)
+            raise Exception(_('Component {} not found').format(component_name))
 
         component = Component.Component()
         component.parse(self.cdb.get_item(component_name, repo))
diff --git i/inary/db/filesldb.py w/inary/db/filesldb.py
index 1c73e7a0..b8cd5733 100644
--- i/inary/db/filesldb.py
+++ w/inary/db/filesldb.py
@@ -40,7 +40,7 @@ class FilesLDB():
         ctx.ui.info(inary.util.colorize(_('Creating files database...'), 'blue'))
         installdb = inary.db.installdb.InstallDB()
         for pkg in installdb.list_installed():
-            #ctx.ui.info(inary.util.colorize(_('  ---> Adding \'%s\' to db... '), 'purple') % pkg, noln= True)
+            #ctx.ui.info(inary.util.colorize(_('  ---> Adding \'{}\' to db... '), 'purple')¿format(pkg), noln= True)
             files = installdb.get_files(pkg)
             self.add_files(pkg, files)
             #ctx.ui.info(inary.util.colorize(_('OK.'), 'backgroundmagenta'))
@@ -58,7 +58,7 @@ class FilesLDB():
         found = []
         for pkg in installdb.list_installed():
             files_xml = open(os.path.join(installdb.package_path(pkg), ctx.const.files_xml)).read()
-            paths = re.compile('<Path>(.*?%s.*?)</Path>' % re.escape(term), re.I).findall(files_xml)
+            paths = re.compile('<Path>(.*?{}.*?)</Path>'.format(re.escape(term)), re.I).findall(files_xml)
             if paths:
                 found.append((pkg, paths))
         return found
diff --git i/inary/db/groupdb.py w/inary/db/groupdb.py
index 2408bb8e..97beaf8c 100644
--- i/inary/db/groupdb.py
+++ w/inary/db/groupdb.py
@@ -63,7 +63,7 @@ class GroupDB(lazydb.LazyDB):
     def get_group(self, name, repo = None):
 
         if not self.has_group(name, repo):
-            raise GroupNotFound(_('Group %s not found') % name)
+            raise GroupNotFound(_('Group {} not found').format(name))
 
         group = Group.Group()
         group.parse(self.gdb.get_item(name, repo))
@@ -72,7 +72,7 @@ class GroupDB(lazydb.LazyDB):
 
     def get_group_components(self, name, repo=None):
         if not self.has_group(name, repo):
-            raise GroupNotFound(_('Group %s not found') % name)
+            raise GroupNotFound(_('Group {} not found').format(name))
 
         if self.gcdb.has_item(name):
             return self.gcdb.get_item(name, repo)
diff --git i/inary/db/installdb.py w/inary/db/installdb.py
index c958ec00..294aba5d 100644
--- i/inary/db/installdb.py
+++ w/inary/db/installdb.py
@@ -51,11 +51,11 @@ class InstallInfo:
         return s
 
     def __str__(self):
-        s = _("State: %s\nVersion: %s, Release: %s\n") % \
-            (InstallInfo.state_map[self.state], self.version, self.release)
+        s = _("State: {0}\nVersion: {1}, Release: {2}\n").format(
+            InstallInfo.state_map[self.state], self.version, self.release)
         import time
         time_str = time.strftime("%d %b %Y %H:%M", self.time)
-        s += _('Distribution: %s, Install Time: %s\n') % (self.distribution,
+        s += _('Distribution: {0}, Install Time: {1}\n').format(self.distribution,
                                                           time_str)
         return s
 
@@ -100,8 +100,8 @@ class InstallDB(lazydb.LazyDB):
 
         if pkg is None:
             # If package info is broken or not available, skip it.
-            ctx.ui.warning(_("Installation info for package '%s' is broken. "
-                             "Reinstall it to fix this problem.") % package)
+            ctx.ui.warning(_("Installation info for package '{}' is broken. "
+                             "Reinstall it to fix this problem.").format(package))
             del self.installed_db[package]
             return
 
@@ -197,8 +197,8 @@ class InstallDB(lazydb.LazyDB):
         This method will return only package that contents terms in the package
         name or summary
         """
-        resum = '<Summary xml:lang=.(%s|en).>.*?%s.*?</Summary>'
-        redesc = '<Description xml:lang=.(%s|en).>.*?%s.*?</Description>'
+        resum = '<Summary xml:lang=.({0}|en).>.*?{1}.*?</Summary>'
+        redesc = '<Description xml:lang=.({0}|en).>.*?{1}.*?</Description>'
         if not fields:
             fields = {'name': True, 'summary': True, 'desc': True}
         if not lang:
@@ -209,14 +209,14 @@ class InstallDB(lazydb.LazyDB):
             if terms == [term for term in terms if (fields['name'] and \
                     re.compile(term, re.I).search(name)) or \
                     (fields['summary'] and \
-                    re.compile(resum % (lang, term), 0 if cs else re.I).search(xml)) or \
+                    re.compile(resum.format(lang, term), 0 if cs else re.I).search(xml)) or \
                     (fields['desc'] and \
-                    re.compile(redesc % (lang, term), 0 if cs else re.I).search(xml))]:
+                    re.compile(redesc.format(lang, term), 0 if cs else re.I).search(xml))]:
                 found.append(name)
         return found
 
     def get_isa_packages(self, isa):
-        risa = '<IsA>%s</IsA>' % isa
+        risa = '<IsA>{}</IsA>'.format(isa)
         packages = []
         for name in self.list_installed():
             xml = open(os.path.join(self.package_path(name), ctx.const.metadata_xml)).read()
@@ -311,7 +311,7 @@ class InstallDB(lazydb.LazyDB):
             if pkginfo.name in revdep_info:
                 del revdep_info[pkginfo.name]
 
-        self.installed_db[pkginfo.name] = "%s-%s" % (pkginfo.version, pkginfo.release)
+        self.installed_db[pkginfo.name] = "{0.version}-{0.release}".format(pkginfo)
         self.__add_to_revdeps(pkginfo.name, self.rev_deps_db)
 
     def remove_package(self, package_name):
@@ -338,7 +338,7 @@ class InstallDB(lazydb.LazyDB):
         info_file = os.path.join(ctx.config.info_dir(), _type)
         config = open(info_file, "w")
         for pkg in set(packages):
-            config.write("%s\n" % pkg)
+            config.write("{}\n".format(pkg))
         config.close()
 
     def __clear_marked_packages(self, _type, package):
@@ -362,6 +362,6 @@ class InstallDB(lazydb.LazyDB):
     def package_path(self, package):
 
         if package in self.installed_db:
-            return os.path.join(ctx.config.packages_dir(), "%s-%s" % (package, self.installed_db[package]))
+            return os.path.join(ctx.config.packages_dir(), "{0}-{1}".format(package, self.installed_db[package]))
 
-        raise Exception(_('Package %s is not installed') % package)
+        raise Exception(_('Package {} is not installed').format(package))
diff --git i/inary/db/itembyrepo.py w/inary/db/itembyrepo.py
index 8dfa9e71..144d00b6 100644
--- i/inary/db/itembyrepo.py
+++ w/inary/db/itembyrepo.py
@@ -37,7 +37,7 @@ class ItemByRepo:
             if r in self.dbobj and item in self.dbobj[r]:
                 return r
 
-        raise Exception(_("%s not found in any repository.") % str(item))
+        raise Exception(_("{} not found in any repository.").format(str(item)))
 
     def get_item_repo(self, item, repo=None):
         for r in self.item_repos(repo):
@@ -47,7 +47,7 @@ class ItemByRepo:
                 else:
                     return self.dbobj[r][item], r
 
-        raise Exception(_("Repo item %s not found") % str(item))
+        raise Exception(_("Repo item {} not found").format(str(item)))
 
     def get_item(self, item, repo=None):
         item, repo = self.get_item_repo(item, repo)
@@ -57,7 +57,7 @@ class ItemByRepo:
         items = []
         for r in self.item_repos(repo):
             if not self.has_repo(r):
-                raise Exception(_('Repository %s does not exist.') % repo)
+                raise Exception(_('Repository {} does not exist.').format(repo))
 
             if r in self.dbobj:
                 items.extend(list(self.dbobj[r].keys()))
@@ -68,7 +68,7 @@ class ItemByRepo:
         items = []
         for r in self.item_repos(repo):
             if not self.has_repo(r):
-                raise Exception(_('Repository %s does not exist.') % repo)
+                raise Exception(_('Repository {} does not exist.').format(repo))
 
             if r in self.dbobj:
                 items.extend(self.dbobj[r])
@@ -78,7 +78,7 @@ class ItemByRepo:
     def get_items_iter(self, repo=None):
         for r in self.item_repos(repo):
             if not self.has_repo(r):
-                raise Exception(_('Repository %s does not exist.') % repo)
+                raise Exception(_('Repository {} does not exist.').format(repo))
 
             if self.compressed:
                 for item in list(self.dbobj[r].keys()):
diff --git i/inary/db/lazydb.py w/inary/db/lazydb.py
index e71a0f78..176b29db 100644
--- i/inary/db/lazydb.py
+++ w/inary/db/lazydb.py
@@ -49,10 +49,10 @@ class LazyDB(Singleton):
         return self.initialized
 
     def __cache_file(self):
-        return util.join_path(ctx.config.cache_root_dir(), "%s.cache" % self.__class__.__name__.translate(lower_map))
+        return util.join_path(ctx.config.cache_root_dir(), "{}.cache".format(self.__class__.__name__.translate(lower_map)))
 
     def __cache_version_file(self):
-        return "%s.version" % self.__cache_file()
+        return "{}.version".format(self.__cache_file())
 
     def __cache_file_version(self):
         try:
@@ -114,7 +114,7 @@ class LazyDB(Singleton):
             start = time.time()
             self.__init()
             end = time.time()
-            ctx.ui.debug("%s initialized in %s." % (self.__class__.__name__, end - start))
+            ctx.ui.debug("{0} initialized in {1}.".format(self.__class__.__name__, end - start))
             self.initialized = True
 
         if attr not in self.__dict__:
diff --git i/inary/db/packagedb.py w/inary/db/packagedb.py
index 1fc75a41..94a7ab48 100644
--- i/inary/db/packagedb.py
+++ w/inary/db/packagedb.py
@@ -88,16 +88,16 @@ class PackageDB(lazydb.LazyDB):
         return pkg
 
     def search_in_packages(self, packages, terms, lang=None):
-        resum = '<Summary xml:lang=.(%s|en).>.*?%s.*?</Summary>'
-        redesc = '<Description xml:lang=.(%s|en).>.*?%s.*?</Description>'
+        resum = '<Summary xml:lang=.({0}|en).>.*?{1}.*?</Summary>'
+        redesc = '<Description xml:lang=.({0}|en).>.*?{1}.*?</Description>'
         if not lang:
             lang = inary.sxml.autoxml.LocalText.get_lang()
         found = []
         for name in packages:
             xml = self.pdb.get_item(name)
             if terms == [term for term in terms if re.compile(term, re.I).search(name) or \
-                                            re.compile(resum % (lang, term), re.I).search(xml) or \
-                                            re.compile(redesc % (lang, term), re.I).search(xml)]:
+                                            re.compile(resum.format(lang, term), re.I).search(xml) or \
+                                            re.compile(redesc.format(lang, term), re.I).search(xml)]:
                 found.append(name)
         return found
 
@@ -111,8 +111,8 @@ class PackageDB(lazydb.LazyDB):
         This method will return only package that contents terms in the package
         name or summary
         """
-        resum = '<Summary xml:lang=.(%s|en).>.*?%s.*?</Summary>'
-        redesc = '<Description xml:lang=.(%s|en).>.*?%s.*?</Description>'
+        resum = '<Summary xml:lang=.({0}|en).>.*?{1}.*?</Summary>'
+        redesc = '<Description xml:lang=.({0}|en).>.*?{1}.*?</Description>'
         if not lang:
             lang = inary.sxml.autoxml.LocalText.get_lang()
         if not fields:
@@ -122,9 +122,9 @@ class PackageDB(lazydb.LazyDB):
             if terms == [term for term in terms if (fields['name'] and \
                     re.compile(term, re.I).search(name)) or \
                     (fields['summary'] and \
-                    re.compile(resum % (lang, term), 0 if cs else re.I).search(xml)) or \
+                    re.compile(resum.format(lang, term), 0 if cs else re.I).search(xml)) or \
                     (fields['desc'] and \
-                    re.compile(redesc % (lang, term), 0 if cs else re.I).search(xml))]:
+                    re.compile(redesc(lang, term), 0 if cs else re.I).search(xml))]:
                 found.append(name)
         return found
 
@@ -144,14 +144,14 @@ class PackageDB(lazydb.LazyDB):
 
     def get_version_and_distro_release(self, name, repo):
         if not self.has_package(name, repo):
-            raise Exception(_('Package %s not found.') % name)
+            raise Exception(_('Package {} not found.').format(name))
 
         pkg_doc = ciksemel.parseString(self.pdb.get_item(name, repo))
         return self.__get_version(pkg_doc) + self.__get_distro_release(pkg_doc)
 
     def get_version(self, name, repo):
         if not self.has_package(name, repo):
-            raise Exception(_('Package %s not found.') % name)
+            raise Exception(_('Package {} not found.').format(name))
 
         pkg_doc = ciksemel.parseString(self.pdb.get_item(name, repo))
         return self.__get_version(pkg_doc)
diff --git i/inary/db/repodb.py w/inary/db/repodb.py
index c1ee9d49..1ed56b04 100644
--- i/inary/db/repodb.py
+++ w/inary/db/repodb.py
@@ -113,7 +113,7 @@ class RepoOrder:
 
     def _update(self, doc):
         repos_file = os.path.join(ctx.config.info_dir(), ctx.const.repos)
-        open(repos_file, "w").write("%s\n" % doc.toPrettyString())
+        open(repos_file, "w").write("{}\n".format(doc.toPrettyString()))
         self._doc = None
         self.repos = self._get_repos()
 
@@ -165,7 +165,7 @@ class RepoDB(lazydb.LazyDB):
                 index_path = os.path.splitext(index_path)[0]
 
         if not os.path.exists(index_path):
-            ctx.ui.warning(_("%s repository needs to be updated") % repo_name)
+            ctx.ui.warning(_("{} repository needs to be updated").format(repo_name))
             return ciksemel.newDocument("INARY")
 
         try:
@@ -267,5 +267,5 @@ class RepoDB(lazydb.LazyDB):
         if not compatible:
             self.deactivate_repo(name)
             raise IncompatibleRepoError(
-                    _("Repository '%s' is not compatible with your "
-                      "distribution. Repository is disabled.") % name)
+                    _("Repository '{}' is not compatible with your distribution. Repository is disabled.").format(name))
+
diff --git i/inary/db/sourcedb.py w/inary/db/sourcedb.py
index 42b2b593..15eb1657 100644
--- i/inary/db/sourcedb.py
+++ w/inary/db/sourcedb.py
@@ -89,8 +89,8 @@ class SourceDB(lazydb.LazyDB):
         This method will return only package that contents terms in the package
         name or summary
         """
-        resum = '<Summary xml:lang=.(%s|en).>.*?%s.*?</Summary>'
-        redesc = '<Description xml:lang=.(%s|en).>.*?%s.*?</Description>'
+        resum = '<Summary xml:lang=.({0}|en).>.*?{1}.*?</Summary>'
+        redesc = '<Description xml:lang=.({0}|en).>.*?{1}.*?</Description>'
         if not fields:
             fields = {'name': True, 'summary': True, 'desc': True}
         if not lang:
@@ -100,9 +100,9 @@ class SourceDB(lazydb.LazyDB):
             if terms == [term for term in terms if (fields['name'] and \
                     re.compile(term, re.I).search(name)) or \
                     (fields['summary'] and \
-                    re.compile(resum % (lang, term), 0 if cs else re.I).search(xml)) or \
+                    re.compile(resum.format(lang, term), 0 if cs else re.I).search(xml)) or \
                     (fields['desc'] and \
-                    re.compile(redesc % (lang, term), 0 if cs else re.I).search(xml))]:
+                    re.compile(redesc.format(lang, term), 0 if cs else re.I).search(xml))]:
                 found.append(name)
         return found
 
diff --git i/inary/fetcher.py w/inary/fetcher.py
index b5f214f6..d7b41df0 100644
--- i/inary/fetcher.py
+++ w/inary/fetcher.py
@@ -13,13 +13,11 @@
 # python standard library modules
 import os
 import time
-import base64
 import shutil
 import socket
 import sys
 
 from base64 import encodestring
-from shutil import move
 
 # Network libraries
 from http.client import HTTPException
@@ -150,17 +148,17 @@ class Fetcher:
                            )
 
         except ValueError as e:
-            msg = _("Url Problem: \n %s") % e
+            msg = _("Url Problem: \n {}").format(e)
             raise FetchError(msg)
             return False
 
         except urlerror.HTTPError as e:
-            msg = _("Reaised an HTTP Error: \n %s") % e
+            msg = _("Reaised an HTTP Error: \n {}").format(e)
             raise FetchError(msg)
             return False
 
         except Error as e:
-            msg = _("Can not avaible remote server: \n %s") % e
+            msg = _("Can not avaible remote server: \n {}").format(e)
             raise FetchError(msg)
             return False
 
@@ -172,10 +170,10 @@ class Fetcher:
             raise FileError(_('Filename error'))
 
         if not os.access(self.destdir, os.W_OK):
-            raise FileError(_('Access denied to write to destination directory: "%s"') % (self.destdir))
+            raise FileError(_('Access denied to write to destination directory: "{}"').format(self.destdir))
 
         if os.path.exists(self.archive_file) and not os.access(self.archive_file, os.W_OK):
-            raise FileError(_('Access denied to destination file: "%s"') % (self.archive_file))
+            raise FileError(_('Access denied to destination file: "{}"').format(self.archive_file))
 
         else:
             self.exist_size = 0
@@ -195,18 +193,18 @@ class Fetcher:
                 handler= UIHandler()
 
             except ValueError as e:
-                raise FetchError(_('Could not fetch destination file: "%s" \nRaised Value error: "%s"') % (uri, e))
+                raise FetchError(_('Could not fetch destination file: "{0}" \nRaised Value error: "{1}"').format(uri, e))
             except OSError as e:
-                raise FetchError(_('Could not fetch destination file: "%s"; \n"%s"') % (uri, e))
+                raise FetchError(_('Could not fetch destination file: "{0}"; \n"{1}"').format(uri, e))
             except urllib.error.HTTPError as e:
-                raise FetchError(_('Could not fetch destination file: "%s"; \n"%s"') % (uri, e))
+                raise FetchError(_('Could not fetch destination file: "{0}"; \n"{1}"').format(uri, e))
             except urllib.error.URLError as e:
-                raise FetchError(_('Could not fetch destination file: "%s"; \n"%s"') % (uri, e[-1][-1]))
+                raise FetchError(_('Could not fetch destination file: "{0}"; \n"{1}"').format(uri, e[-1][-1]))
             except HTTPException as e:
-                raise FetchError(_('Could not fetch destination file: "%s"; ("%s"): "%s"') % (uri, e.__class__.__name__, e))
+                raise FetchError(_('Could not fetch destination file: "{0}"; ("{1}"): "{2}"').format(uri, e.__class__.__name__, e))
 
         except FetchError as e:
-            raise FetchError(_('A problem occurred. Please check the archive address and/or permissions again. %s') %e)
+            raise FetchError(_('A problem occurred. Please check the archive address and/or permissions again. {}').format(e))
 
         total_length = int(headers['Content-Length'])
 
@@ -243,8 +241,8 @@ class Fetcher:
 
     def formatRequest(self, request):
         if self.url.auth_info():
-            enc = encodestring('%s:%s' % self.url.auth_info())
-            request.add_header('Authorization', 'Basic %s' % enc)
+            enc = encodestring('{0}:{0}'.format(self.url.auth_info()))
+            headers.append(('Authorization', 'Basic {}'.format(enc)))
 
         range_handlers = {
             'http' : HTTPRangeHandler,
@@ -269,7 +267,7 @@ class Fetcher:
             ftp_proxy = ctx.config.values.general.ftp_proxy
             proxy_handler = urllib.request.ProxyHandler({URI(http_proxy): ftp_proxy})
         if proxy_handler:
-            ctx.ui.info(_("Proxy configuration has been found for '%s' protocol") % self.url.scheme())
+            ctx.ui.info(_("Proxy configuration has been found for '{}' protocol").format(self.url.scheme()))
             opener = urllib.request.build_opener(proxy_handler)
             urllib.request.install_opener(opener)
         return request
@@ -277,15 +275,15 @@ class Fetcher:
     def _get_http_headers(self):
         headers = []
         if self.url.auth_info() and (self.url.scheme() == "http" or self.url.scheme() == "https"):
-            enc = base64.encodestring('%s:%s' % self.url.auth_info())
-            headers.append(('Authorization', 'Basic %s' % enc),)
+            enc = encodestring('{0}:{0}'.format(self.url.auth_info()))
+            headers.append(('Authorization', 'Basic {}'.format(enc)))
         return tuple(headers)
 
     def _get_ftp_headers(self):
         headers = []
         if self.url.auth_info() and self.url.scheme() == "ftp":
-            enc = base64.encodestring('%s:%s' % self.url.auth_info())
-            headers.append(('Authorization', 'Basic %s' % enc),)
+            enc = encodestring('{0}:{0}'.format(self.url.auth_info()))
+            headers.append(('Authorization', 'Basic {}'.format(enc)))
         return tuple(headers)
 
     def _get_proxies(self):
@@ -301,14 +299,14 @@ class Fetcher:
             proxies[inary.uri.URI(ctx.config.values.general.ftp_proxy).scheme()] = ctx.config.values.general.ftp_proxy
 
         if self.url.scheme() in proxies:
-            ctx.ui.info(_("Proxy configuration has been found for '%s' protocol") % self.url.scheme())
+            ctx.ui.info(_("Proxy configuration has been found for '{}' protocol").format(self.url.scheme()))
 
         return proxies
 
     def _get_bandwith_limit(self):
         bandwidth_limit = ctx.config.options.bandwidth_limit or ctx.config.values.general.bandwidth_limit
         if bandwidth_limit and bandwidth_limit != "0":
-            ctx.ui.warning(_("Bandwidth usage is limited to %s KB/s") % bandwidth_limit)
+            ctx.ui.warning(_("Bandwidth usage is limited to {} KB/s").format(bandwidth_limit))
             return 1024 * int(bandwidth_limit)
         else:
             return 0
@@ -391,9 +389,9 @@ class FTPRangeHandler(urllib.request.FTPHandler):
             headers = ''
             mtype = guess_type(req.get_full_url())[0]
             if mtype:
-                headers += 'Content-Type: %s\n' % mtype
+                headers += 'Content-Type: {}\n'.format(mtype)
             if retrlen is not None and retrlen >= 0:
-                headers += 'Content-Length: %d\n' % retrlen
+                headers += 'Content-Length: {}\n'.format(retrlen)
 
             from io import StringIO
 
diff --git i/inary/file.py w/inary/file.py
index b3d9a437..e8f758f3 100644
--- i/inary/file.py
+++ w/inary/file.py
@@ -32,14 +32,13 @@ import inary.context as ctx
 
 class AlreadyHaveException(inary.Exception):
     def __init__(self, url, localfile):
-        inary.Exception.__init__(self, _("URL %s already downloaded as %s")
-                                      % (url, localfile))
+        inary.Exception.__init__(self, _("URL {0} already downloaded as {1}").format(url, localfile))
         self.url = url
         self.localfile = localfile
 
 class NoSignatureFound(inary.Exception):
     def __init__(self, url):
-        inary.Exception.__init__(self, _("No signature found for %s") % url)
+        inary.Exception.__init__(self, _("No signature found for {}").format(url))
         self.url = url
 
 class Error(inary.Error):
@@ -47,7 +46,7 @@ class Error(inary.Error):
 
 class InvalidSignature(inary.Error):
     def __init__(self, url):
-        inary.Exception.__init__(self, _(" invalid for %s") % url)
+        inary.Exception.__init__(self, _(" invalid for {}").format(url))
         self.url = url
 
 class File:
@@ -136,16 +135,16 @@ class File:
                     raise AlreadyHaveException(uri, origfile)
 
             if uri.is_remote_file():
-                ctx.ui.info(_("Fetching %s") % uri.get_uri(), verbose=True)
+                ctx.ui.info(_("Fetching {}").format(uri.get_uri()), verbose=True)
                 inary.fetcher.fetch_url(uri, transfer_dir, ctx.ui.Progress, tmpfile)
             else:
                 # copy to transfer dir
-                ctx.ui.info(_("Copying %s to transfer dir") % uri.get_uri(), verbose=True)
+                ctx.ui.info(_("Copying {} to transfer dir").format(uri.get_uri()), verbose=True)
                 shutil.copy(uri.get_uri(), localfile)
         else:
             localfile = uri.get_uri() #TODO: use a special function here?
             if not os.path.exists(localfile):
-                raise IOError(_("File '%s' not found.") % localfile)
+                raise IOError(_("File '{}' not found.").format(localfile))
             if not os.access(localfile, os.W_OK):
                 oldfn = localfile
                 localfile = inary.util.join_path(transfer_dir, os.path.basename(localfile))
@@ -166,7 +165,7 @@ class File:
         if sha1sum:
             if (inary.util.sha1_file(localfile) != newsha1):
                 clean_temporary()
-                raise Error(_("File integrity of %s compromised.") % uri)
+                raise Error(_("File integrity of {} compromised.").format(uri))
 
         if check_integrity:
             shutil.move(localfile, origfile)
@@ -248,10 +247,10 @@ class File:
 
             if self.sign==File.detached:
                 if inary.util.run_batch('gpg --detach-sig ' + self.localfile)[0]:
-                    raise Error(_("ERROR: gpg --detach-sig %s failed") % self.localfile)
+                    raise Error(_("ERROR: gpg --detach-sig {} failed").format(self.localfile))
                 for compressed_file in compressed_files:
                     if inary.util.run_batch('gpg --detach-sig ' + compressed_file)[0]:
-                        raise Error(_("ERROR: gpg --detach-sig %s failed") % compressed_file)
+                        raise Error(_("ERROR: gpg --detach-sig {} failed").format(compressed_file))
 
     @staticmethod
     def check_signature(uri, transfer_dir, sign=detached):
diff --git i/inary/mirrors.py w/inary/mirrors.py
index 67941673..562618be 100644
--- i/inary/mirrors.py
+++ w/inary/mirrors.py
@@ -43,5 +43,5 @@ class Mirrors:
                       (name, url) = mirror
                       self._add_mirror(name, url)
         else:
-            raise inary.Error(_('Mirrors file %s does not exist. Could not resolve mirrors://') % config)
+            raise inary.Error(_('Mirrors file {} does not exist. Could not resolve mirrors://').format(config))
 
diff --git i/inary/oo.py w/inary/oo.py
index f95903fa..cf75a68a 100644
--- i/inary/oo.py
+++ w/inary/oo.py
@@ -12,14 +12,14 @@ class autoprop(type):
             if name.startswith("_get_") or name.startswith("_set_"):
                 props[name[5:]] = 1
         for name in list(props.keys()):
-            fget = getattr(cls, "_get_%s" % name, None)
-            fset = getattr(cls, "_set_%s" % name, None)
+            fget = getattr(cls, "_get_{}".format(name), None)
+            fset = getattr(cls, "_set_{}".format(name), None)
             setattr(cls, name, property(fget, fset))
 
 class autosuper(type):
     def __init__(cls, name, bases, dict):
         super(autosuper, cls).__init__(name, bases, dict)
-        setattr(cls, "_%s__super" % name, super(cls))
+        setattr(cls, "_{}__super".format(name), super(cls))
 
 class autosuprop(autosuper, autoprop):
     pass
diff --git i/inary/operations/build.py w/inary/operations/build.py
index 4b8eff47..63966622 100644
--- i/inary/operations/build.py
+++ w/inary/operations/build.py
@@ -62,7 +62,7 @@ def get_file_type(path, pinfo_list):
     """Return the file type of a path according to the given PathInfo
     list"""
 
-    path = "/%s" % re.sub("/+", "/", path)
+    path = "/{}".format(re.sub("/+", "/", path))
     info = None
     glob_match = parent_match = None
 
@@ -112,8 +112,7 @@ def check_path_collision(package, pkgList):
 
                 if util.subpath(pinfo.path, path.path):
                     collisions.append(path.path.rstrip("/"))
-                    ctx.ui.debug(_('Path %s belongs in multiple packages') %
-                                 path.path)
+                    ctx.ui.debug(_('Path {} belongs in multiple packages').format(path.path))
     return collisions
 
 def exclude_special_files(filepath, fileinfo, ag):
@@ -131,8 +130,8 @@ def exclude_special_files(filepath, fileinfo, ag):
         if re.match(patterns["libtool"], fileinfo) and \
                 not os.path.islink(filepath):
             ladata = open(filepath).read()
-            new_ladata = re.sub("-L%s/\S*" % ctx.config.tmp_dir(), "", ladata)
-            new_ladata = re.sub("%s/\S*/install/" % ctx.config.tmp_dir(), "/",
+            new_ladata = re.sub("-L{}/\S*".format(ctx.config.tmp_dir()), "", ladata)
+            new_ladata = re.sub("{}/\S*/install/".format(ctx.config.tmp_dir()), "/",
                                 new_ladata)
             if new_ladata != ladata:
                 open(filepath, "w").write(new_ladata)
@@ -142,10 +141,10 @@ def exclude_special_files(filepath, fileinfo, ag):
             continue
 
         if fileinfo == None:
-            ctx.ui.warning(_("Removing special file skipped for: %s") % filepath)
+            ctx.ui.warning(_("Removing special file skipped for: {}").format(filepath))
             return
         elif re.match(pattern, fileinfo):
-            ctx.ui.debug("Removing special %s file: %s" % (name, filepath))
+            ctx.ui.debug("Removing special {0} file: {1}".format(name, filepath))
             os.unlink(filepath)
             # Remove dir if it becomes empty (Bug #11588)
             util.rmdirs(os.path.dirname(filepath))
@@ -165,7 +164,7 @@ def strip_debug_action(filepath, fileinfo, install_dir, ag):
                                 path)
 
     if util.strip_file(filepath, fileinfo, outputpath):
-        ctx.ui.debug("%s [%s]" % (path, "stripped"))
+        ctx.ui.debug("{0} [{1}]".format(path, "stripped"))
 
 class Builder:
     """Provides the package build and creation routines"""
@@ -191,12 +190,11 @@ class Builder:
                                     os.path.dirname(repo.indexuri.get_uri()),
                                     str(src_uri.path()))
 
-            ctx.ui.debug(_("Source URI: %s") % src_path)
+            ctx.ui.debug(_("Source URI: {}").format(src_path))
 
             return Builder(src_path)
         else:
-            raise Error(_("Source %s not found in any active repository.")
-                        % name)
+            raise Error(_("Source {} not found in any active repository.").format(name))
 
     def __init__(self, specuri):
 
@@ -296,7 +294,7 @@ class Builder:
                               packageDir)
 
     def pkg_work_dir(self):
-        suffix = "-%s" % self.build_type if self.build_type else ""
+        suffix = "-{}".format(self.build_type) if self.build_type else ""
         return self.pkg_dir() + ctx.const.work_dir_suffix + suffix
 
     def pkg_debug_dir(self):
@@ -321,11 +319,11 @@ class Builder:
         architecture = ctx.config.values.general.architecture
         if architecture in self.spec.source.excludeArch:
             raise ExcludedArchitectureException(
-                    _("pspec.xml avoids this package from building for '%s'")
-                    % architecture)
+                    _("pspec.xml avoids this package from building for '{}'").format(
+                      architecture))
 
-        ctx.ui.status(_("Building source package: %s")
-                      % self.spec.source.name)
+        ctx.ui.status(_("Building source package: {}").format(
+                        self.spec.source.name))
 
         # check if all patch files exists, if there are missing no need
         # to unpack!
@@ -376,7 +374,7 @@ class Builder:
 
     def set_build_type(self, build_type):
         if build_type:
-            ctx.ui.action(_("Rebuilding for %s") % build_type)
+            ctx.ui.action(_("Rebuilding for {}").format(build_type))
 
         self.build_type = build_type
         self.set_environment_vars()
@@ -399,8 +397,8 @@ class Builder:
                "SRC_RELEASE": self.spec.getSourceRelease(),
                "PYTHONDONTWRITEBYTECODE": '1'}
         if self.build_type == "emul32":
-            env["CC"] = "%s -m32" % os.getenv("CC")
-            env["CXX"] = "%s -m32" % os.getenv("CXX")
+            env["CC"] = "{} -m32".format(os.getenv("CC"))
+            env["CXX"] = "{} -m32".format(os.getenv("CXX"))
             env["CFLAGS"] = os.getenv("CFLAGS").replace("-fPIC", "")
             env["CXXFLAGS"] = os.getenv("CXXFLAGS").replace("-fPIC", "")
             env["PKG_CONFIG_PATH"] = "/usr/lib32/pkgconfig"
@@ -483,7 +481,7 @@ class Builder:
                                 ctx.const.scom_dir, pscom.script)
                 self.download(scomuri, util.join_path(self.specdir,
                                                        ctx.const.scom_dir))
-                ctx.ui.info("Scom Script Fetched %s" %pscom.script)
+                ctx.ui.info("Scom Script Fetched {}".format(pscom.script))
 
 
     def download(self, uri, transferdir):
@@ -533,7 +531,7 @@ class Builder:
 
         # apply the patches and prepare a source directory for build.
         if self.apply_patches():
-            ctx.ui.info(_(" unpacked (%s)") % self.pkg_work_dir())
+            ctx.ui.info(_(" unpacked ({})").format(self.pkg_work_dir()))
             self.set_state("unpack")
 
     def run_setup_action(self):
@@ -631,11 +629,11 @@ class Builder:
             buf = open(fname).read()
             return compile(buf, fname, "exec")
         except IOError as e:
-            raise Error(_("Unable to read Actions Script (%s): %s")
-                        % (fname, e))
+            raise Error(_("Unable to read Actions Script ({0}): {1}").format(
+                          fname, e))
         except SyntaxError as e:
-            raise Error(_("SyntaxError in Actions Script (%s): %s")
-                        % (fname, e))
+            raise Error(_("SyntaxError in Actions Script ({0}): {1}").format(
+                          fname, e))
 
     def load_action_script(self):
         """Compiles and executes the action script"""
@@ -663,11 +661,11 @@ class Builder:
                     buf = open(fname).read()
                     compile(buf, "error", "exec")
                 except IOError as e:
-                    raise Error(_("Unable to read SCOM script (%s): %s")
-                                 % (fname, e))
+                    raise Error(_("Unable to read SCOM script ({0}): {1}").format(
+                                  fname, e))
                 except SyntaxError as e:
-                    raise Error(_("SyntaxError in SCOM file (%s): %s")
-                                 % (fname, e))
+                    raise Error(_("SyntaxError in SCOM file ({0}): {1}").format(
+                                  fname, e))
     def pkg_src_dir(self):
         """Returns the real path of WorkDir for an unpacked archive."""
 
@@ -695,12 +693,12 @@ class Builder:
                     break
             if not os.path.exists(src_dir):
                 src_dir = util.join_path(self.pkg_work_dir(), [d for d in os.walk(self.pkg_work_dir()).__next__()[1] if not d.startswith(".")][0])
-                if self.get_state() == "unpack": ctx.ui.debug("Using %s as  WorkDir" % src_dir)
+                if self.get_state() == "unpack": ctx.ui.debug("Using {} as  WorkDir".format(src_dir))
 
         return src_dir
 
     def log_sandbox_violation(self, operation, path, canonical_path):
-        ctx.ui.error(_("Sandbox violation: %s (%s -> %s)") % (operation,
+        ctx.ui.error(_("Sandbox violation: {0} ({1} -> {2})").format(operation,
                                                               path,
                                                               canonical_path))
 
@@ -716,7 +714,7 @@ class Builder:
         if os.path.exists(src_dir):
             os.chdir(src_dir)
         else:
-            raise Error(_("ERROR: WorkDir (%s) does not exist\n") % src_dir)
+            raise Error(_("ERROR: WorkDir ({}) does not exist\n").format(src_dir))
 
         if func in self.actionLocals:
             if ctx.get_option('ignore_sandbox') or \
@@ -732,7 +730,7 @@ class Builder:
                 valid_paths = [self.pkg_dir()]
                 conf_file = ctx.const.sandbox_conf
                 if os.path.exists(conf_file):
-                    for line in file(conf_file):
+                    for line in open(conf_file):
                         line = line.strip()
                         if len(line) > 0 and not line.startswith("#"):
                             if line.startswith("~"):
@@ -752,7 +750,7 @@ class Builder:
                 if ret.violations != []:
                     ctx.ui.error(_("Sandbox violation result:"))
                     for result in ret.violations:
-                        ctx.ui.error("%s (%s -> %s)" % (result[0],
+                        ctx.ui.error("{0} ({1} -> {2})".format(result[0],
                                                         result[1],
                                                         result[2]))
                     raise Error(_("Sandbox violations!"))
@@ -761,8 +759,7 @@ class Builder:
                     raise ActionScriptException
         else:
             if mandatory:
-                raise Error(_("unable to call function from actions: %s")
-                            % func)
+                raise Error(_("unable to call function from actions: {}").format(func))
 
         os.chdir(curDir)
         return True
@@ -775,12 +772,12 @@ class Builder:
                 path = os.path.normpath(path_info.path)
 
                 if not path.startswith("/"):
-                    raise Error(_("Source package '%s' defines a relative 'Path' element: "
-                                  "%s") % (self.spec.source.name, path_info.path))
+                    raise Error(_("Source package '{0}' defines a relative 'Path' element: "
+                                  "{1}").format(self.spec.source.name, path_info.path))
 
                 if path in paths:
-                    raise Error(_("Source package '%s' defines multiple 'Path' tags "
-                                  "for %s") % (self.spec.source.name, path_info.path))
+                    raise Error(_("Source package '{0}' defines multiple 'Path' tags "
+                                  "for {1}").format(self.spec.source.name, path_info.path))
 
                 paths.append(path)
 
@@ -789,8 +786,7 @@ class Builder:
             int(release)
             inary.version.make_version(version)
         except (ValueError, inary.version.InvalidVersionError):
-            raise Error(_("%s-%s is not a valid INARY version format")
-                        % (version, release))
+            raise Error(_("{0}-{1} is not a valid INARY version format").format(version, release))
 
     def check_build_dependencies(self):
         """check and try to install build dependencies, otherwise fail."""
@@ -831,7 +827,7 @@ class Builder:
             if not ctx.config.get_option('ignore_dependency'):
                 for dep in dep_unsatis:
                     if not dep.satisfied_by_repo():
-                        raise Error(_('Build dependency %s cannot be satisfied') % str(dep))
+                        raise Error(_('Build dependency {} cannot be satisfied').format(str(dep)))
                 if ctx.ui.confirm(
                 _('Do you want to install the unsatisfied build dependencies')):
                     ctx.ui.info(_('Installing build dependencies.'))
@@ -850,9 +846,9 @@ class Builder:
         for patch in self.spec.source.patches:
             patchFile = util.join_path(files_dir, patch.filename)
             if not os.access(patchFile, os.F_OK):
-                raise Error(_("Patch file is missing: %s\n") % patch.filename)
+                raise Error(_("Patch file is missing: {}\n").format(patch.filename))
             if os.stat(patchFile).st_size == 0:
-                ctx.ui.warning(_('Patch file is empty: %s') % patch.filename)
+                ctx.ui.warning(_('Patch file is empty: {}').format(patch.filename))
 
     def apply_patches(self):
         files_dir = os.path.abspath(util.join_path(self.specdir,
@@ -866,9 +862,9 @@ class Builder:
                 patchFile = util.uncompress(patchFile,
                                             compressType=patch.compressionType,
                                             targetDir=ctx.config.tmp_dir())
-                relativePath = relativePath.rsplit(".%s" % patch.compressionType, 1)[0]
+                relativePath = relativePath.rsplit(".{}".format(patch.compressionType, 1))[0]
 
-            ctx.ui.action(_("Applying patch: %s") % patch.filename)
+            ctx.ui.action(_("Applying patch: {}").format(patch.filename))
             util.do_patch(self.pkg_src_dir(), patchFile,
                           level=patch.level,
                           name=relativePath,
@@ -888,8 +884,8 @@ class Builder:
         static_package_obj = Specfile.Package()
         static_package_obj.name = self.spec.source.name + ctx.const.static_name_suffix
         # FIXME: find a better way to deal with the summary and description constants.
-        static_package_obj.summary['en'] = 'Ar files for %s' % (self.spec.source.name)
-        static_package_obj.description['en'] = 'Ar files for %s' % (self.spec.source.name)
+        static_package_obj.summary['en'] = 'Ar files for {}'.format(self.spec.source.name)
+        static_package_obj.description['en'] = 'Ar files for {}'.format(self.spec.source.name)
         static_package_obj.partOf = self.spec.source.partOf
         for f in ar_files:
             static_package_obj.files.append(Specfile.Path(path=f[len(self.pkg_install_dir()):], fileType="library"))
@@ -906,8 +902,8 @@ class Builder:
         debug_package_obj.debug_package = True
         debug_package_obj.name = package.name + ctx.const.debug_name_suffix
         # FIXME: find a better way to deal with the summary and description constants.
-        debug_package_obj.summary['en'] = 'Debug files for %s' % (package.name)
-        debug_package_obj.description['en'] = 'Debug files for %s' % (package.name)
+        debug_package_obj.summary['en'] = 'Debug files for {}'.format(package.name)
+        debug_package_obj.description['en'] = 'Debug files for {}'.format(package.name)
         debug_package_obj.partOf = package.partOf
 
         dependency = inary.analyzer.dependency.Dependency()
@@ -989,7 +985,7 @@ class Builder:
                                      mode=oct(stat.S_IMODE(st.st_mode)))
 
                 if stat.S_IMODE(st.st_mode) & stat.S_ISUID:
-                    ctx.ui.warning(_("/%s has suid bit set") % frpath)
+                    ctx.ui.warning(_("/{} has suid bit set").format(frpath))
 
         for pinfo in package.files:
             wildcard_path = util.join_path(install_dir, pinfo.path)
@@ -1067,14 +1063,14 @@ class Builder:
 #                    try:
 #                        os.chown(dest, pwd.getpwnam(afile.owner)[2], -1)
 #                    except KeyError:
-#                        ctx.ui.warning(_("No user named '%s' found "
-#                                         "on the system") % afile.owner)
+#                        ctx.ui.warning(_("No user named '{}' found on the system").format(afile.owner))
+#
 #                if afile.group:
 #                    try:
 #                        os.chown(dest, -1, grp.getgrnam(afile.group)[2])
 #                    except KeyError:
-#                        ctx.ui.warning(_("No group named '%s' found "
-#                                         "on the system") % afile.group)
+#                        ctx.ui.warning(_("No group named '{}' found on the system").format(afile.group))
+#
 
         os.chdir(c)
 
@@ -1082,10 +1078,10 @@ class Builder:
         abandoned_files = self.get_abandoned_files()
         if abandoned_files:
             ctx.ui.error(_("There are abandoned files "
-                           "under the install dir (%s):") % install_dir)
+                           "under the install dir ({}):").format(install_dir))
 
             for f in abandoned_files:
-                ctx.ui.info("    - %s" % f)
+                ctx.ui.info("    - {}".format(f))
 
             raise AbandonedFilesException
 
@@ -1117,11 +1113,10 @@ class Builder:
 
             if not self.files.list:
                 if not package.debug_package:
-                    ctx.ui.warning(_("Ignoring empty package %s") \
-                                     % package.name)
+                    ctx.ui.warning(_("Ignoring empty package {}").format(package.name))
                 continue
 
-            ctx.ui.action(_("Building package: %s") % package.name)
+            ctx.ui.action(_("Building package: {}").format(package.name))
 
             self.gen_metadata_xml(package)
 
@@ -1138,7 +1133,7 @@ class Builder:
             else:
                 self.new_packages.append(name)
 
-            ctx.ui.info(_("Creating %s...") % name)
+            ctx.ui.info(_("Creating {}...").format(name))
 
             pkg = inary.package.Package(name, "w",
                                        format=self.target_package_format,
@@ -1166,7 +1161,7 @@ class Builder:
                     orgname = util.join_path("debug", finfo.path)
                 pkg.add_to_install(orgname, finfo.path)
 
-            self.metadata.package.installTarHash = util.sha1_file("%s/install.tar.xz" % self.pkg_dir())
+            self.metadata.package.installTarHash = util.sha1_file("{}/install.tar.xz".format(self.pkg_dir()))
             self.metadata.write(util.join_path(self.pkg_dir(), ctx.const.metadata_xml))
             pkg.add_metadata_xml(ctx.const.metadata_xml)
 
@@ -1367,7 +1362,7 @@ def build_until(pspec, state):
 
 
 def __build_until(pb, state, last):
-    ctx.ui.info(_("Last state was '%s'") % last)
+    ctx.ui.info(_("Last state was '{}'").format(last))
 
     if state == "unpack":
         __buildState_unpack(pb, last)
diff --git i/inary/operations/delta.py w/inary/operations/delta.py
index 2fa54de8..94b27bb5 100644
--- i/inary/operations/delta.py
+++ w/inary/operations/delta.py
@@ -40,14 +40,11 @@ def create_delta_packages_from_obj(old_packages, new_package_obj, specdir):
         old_pkg_info = old_pkg.metadata.package
 
         if old_pkg_info.name != new_pkg_info.name:
-            ctx.ui.warning(_("The file '%s' belongs to a different package "
-                             "other than '%s'. Skipping it...")
-                             % (old_package, new_pkg_info.name))
+            ctx.ui.warning(_("The file '{0}' belongs to a different package other than '{1}'. Skipping it...").format(old_package, new_pkg_info.name))
             continue
 
         if old_pkg_info.release == new_pkg_info.release:
-            ctx.ui.warning(_("Package '%s' has the same release number with "
-                             "the new package. Skipping it...") % old_package)
+            ctx.ui.warning(_("Package '{}' has the same release number with the new package. Skipping it...").format(old_package))
             continue
 
         delta_name = "-".join((old_pkg_info.name,
@@ -56,7 +53,7 @@ def create_delta_packages_from_obj(old_packages, new_package_obj, specdir):
                                new_distro_id,
                                new_arch)) + ctx.const.delta_package_suffix
 
-        ctx.ui.info(_("Creating %s...") % delta_name)
+        ctx.ui.info(_("Creating {}...").format(delta_name))
 
         if out_dir:
             delta_name = util.join_path(out_dir, delta_name)
@@ -66,9 +63,7 @@ def create_delta_packages_from_obj(old_packages, new_package_obj, specdir):
         files_delta = find_delta(old_pkg_files, new_pkg_files)
 
         if len(files_delta) == len(new_pkg_files.list):
-            ctx.ui.warning(_("All files in the package '%s' are different "
-                             "from the files in the new package. Skipping "
-                             "it...") % old_package)
+            ctx.ui.warning(_("All files in the package '{}' are different from the files in the new package. Skipping it...").format(old_package))
             continue
 
         delta_pkg = inary.package.Package(delta_name, "w", format=target_format)
@@ -110,8 +105,7 @@ def create_delta_packages_from_obj(old_packages, new_package_obj, specdir):
 
 def create_delta_packages(old_packages, new_package):
     if new_package in old_packages:
-        ctx.ui.warning(_("New package '%s' exists in the list of old "
-                         "packages. Skipping it...") % new_package)
+        ctx.ui.warning(_("New package '{}' exists in the list of old packages. Skipping it...").format(new_package))
         while new_package in old_packages:
             old_packages.remove(new_package)
 
diff --git i/inary/operations/downgrade.py w/inary/operations/downgrade.py
index 80674efe..d26a3894 100644
--- i/inary/operations/downgrade.py
+++ w/inary/operations/downgrade.py
@@ -52,14 +52,14 @@ def check_update_actions(packages):
         ctx.ui.warning(_("You must restart the following service(s) manually "
                          "for the updated software to take effect:"))
         for package, target in actions["serviceRestart"]:
-            ctx.ui.info("    - %s" % target)
+            ctx.ui.info("    - {}".format(target))
 
     if "systemRestart" in actions:
         has_actions = True
         ctx.ui.warning(_("You must restart your system for the updates "
                          "in the following package(s) to take effect:"))
         for package, target in actions["systemRestart"]:
-            ctx.ui.info("    - %s" % package)
+            ctx.ui.info("    - {}".format(package))
 
     return has_actions
 
@@ -84,11 +84,11 @@ def find_downgrades(packages, replaces):
             ctx.ui.debug(_("Warning: package *name* ends with '.inary'"))
 
         if not installdb.has_package(i_pkg):
-            ctx.ui.info(_('Package %s is not installed.') % i_pkg, True)
+            ctx.ui.info(_('Package {} is not installed.').format(i_pkg), True)
             continue
 
         if not packagedb.has_package(i_pkg):
-            ctx.ui.info(_('Package %s is not available in repositories.') % i_pkg, True)
+            ctx.ui.info(_('Package {} is not available in repositories.').format(i_pkg), True)
             continue
 
         pkg = packagedb.get_package(i_pkg)
@@ -111,8 +111,7 @@ def find_downgrades(packages, replaces):
                 Ap.append(i_pkg)
                 ds.append(i_pkg)
             else:
-                ctx.ui.info(_('Package %s is already at the first release %s.')
-                            % (pkg.name, pkg.release), True)
+                ctx.ui.info(_('Package {0.name} is already at the first release {0.release}.').format(pkg), True)
 
     if debug and ds:
         ctx.ui.status(_('The following packages have different sha1sum:'))
@@ -153,13 +152,13 @@ def downgrade(A=[], repo=None):
     if ctx.get_option('exclude'):
         A = inary.blacklist.exclude(A, ctx.get_option('exclude'))
 
-    ctx.ui.debug('A = %s' % str(A))
+    ctx.ui.debug('A = {}'.format(str(A)))
 
     if len(A)==0:
         ctx.ui.info(_('No packages to downgrade.'))
         return True
 
-    ctx.ui.debug('A = %s' % str(A))
+    ctx.ui.debug('A = {}'.format(str(A)))
 
     if not ctx.config.get_option('ignore_dependency'):
         G_f, order = plan_downgrade(A, replaces=replaces)
@@ -264,7 +263,7 @@ def plan_downgrade(A, force_replaced=True, replaces=None):
                 # previous ones.
                 G_f.add_dep(pkg.name, dep)
             else:
-                ctx.ui.error(_('Dependency %s of %s cannot be satisfied') % (dep, pkg.name))
+                ctx.ui.error(_('Dependency {0} of {1} cannot be satisfied').format(dep, pkg.name))
                 raise Exception(_("Downgrade is not possible."))
 
     def add_resolvable_conflicts(pkg, Bp):
diff --git i/inary/operations/emerge.py w/inary/operations/emerge.py
index 7aab5b7d..b06cefef 100644
--- i/inary/operations/emerge.py
+++ w/inary/operations/emerge.py
@@ -29,7 +29,7 @@ def emerge(A):
     # A was a list, remove duplicates and expand components
     A = [str(x) for x in A]
     A_0 = A = inary.operations.helper.expand_src_components(set(A))
-    ctx.ui.debug('A = %s' % str(A))
+    ctx.ui.debug('A = {}'.format(str(A)))
 
     if len(A)==0:
         ctx.ui.info(_('No packages to emerge.'))
@@ -92,7 +92,7 @@ def plan_emerge(A):
         if sourcedb.has_spec(name):
             return sourcedb.get_spec(name)
         else:
-            raise Exception(_('Cannot find source package: %s') % name)
+            raise Exception(_('Cannot find source package: {}').format(name))
     def get_src(name):
         return get_spec(name).source
     def add_src(src):
diff --git i/inary/operations/helper.py w/inary/operations/helper.py
index 745d2972..92ffcb7c 100644
--- i/inary/operations/helper.py
+++ w/inary/operations/helper.py
@@ -48,16 +48,14 @@ def check_conflicts(order, packagedb):
     (C, D, pkg_conflicts) = inary.analyzer.conflict.calculate_conflicts(order, packagedb)
 
     if D:
-        raise Exception(_("Selected packages [%s] are in conflict with each other.") %
-                    util.strlist(list(D)))
+        raise Exception(_("Selected packages [{}] are in conflict with each other.").format(util.strlist(list(D))))
 
     if pkg_conflicts:
         conflicts = ""
         for pkg in list(pkg_conflicts.keys()):
-            conflicts += _("[%s conflicts with: %s]\n") % (pkg, util.strlist(pkg_conflicts[pkg]))
+            conflicts += _("[{0} conflicts with: {1}]\n").format(pkg, util.strlist(pkg_conflicts[pkg]))
 
-        ctx.ui.info(_("The following packages have conflicts:\n%s") %
-                    conflicts)
+        ctx.ui.info(_("The following packages have conflicts:\n{}").format(conflicts))
 
         if not ctx.ui.confirm(_('Remove the following conflicting packages?')):
             raise Exception(_("Conflicting packages should be removed to continue"))
@@ -111,8 +109,8 @@ def calculate_download_sizes(order):
             # check the file and sha1sum to be sure it _is_ the cached package
             if os.path.exists(path) and util.sha1_file(path) == pkg_hash:
                 cached_size += pkg_size
-            elif os.path.exists("%s.part" % path):
-                cached_size += os.stat("%s.part" % path).st_size
+            elif os.path.exists("{}.part".format(path)):
+                cached_size += os.stat("{}.part".format(path)).st_size
 
         total_size += pkg_size
 
diff --git i/inary/operations/history.py w/inary/operations/history.py
index a29ed462..51bc5f8a 100644
--- i/inary/operations/history.py
+++ w/inary/operations/history.py
@@ -43,11 +43,11 @@ def __listactions(actions):
         if action == "install":
             if __pkg_already_installed(pkg, pkginfo):
                 continue
-            beinstalled.append("%s-%s" % (pkg, pkginfo))
+            beinstalled.append("{0}-{1}".format(pkg, pkginfo))
             configs.append((pkg, operation))
         else:
             if installdb.has_package(pkg):
-                beremoved.append("%s" % pkg)
+                beremoved.append("{}".format(pkg))
 
     return beinstalled, beremoved, configs
 
@@ -69,7 +69,7 @@ def __getpackageurl(package):
         raise PackageNotFound
 
     repourl = repodb.get_repo_url(reponame)
-    ctx.ui.info(_("Package %s found in repository %s") % (pkg, reponame))
+    ctx.ui.info(_("Package {0} found in repository {1}").format(pkg, reponame))
 
     #return _possible_ url for this package
     return os.path.join(os.path.dirname(repourl),
@@ -81,7 +81,7 @@ def fetch_remote_file(package, errors):
         uri = inary.file.File.make_uri(__getpackageurl(package))
     except PackageNotFound:
         errors.append(package)
-        ctx.ui.info(inary.util.colorize(_("%s could not be found") % (package), "red"))
+        ctx.ui.info(inary.util.colorize(_("{} could not be found").format(package), "red"))
         return False
 
     dest = ctx.config.cached_packages_dir()
@@ -91,10 +91,10 @@ def fetch_remote_file(package, errors):
             inary.fetcher.fetch_url(uri, dest, ctx.ui.Progress)
         except inary.fetcher.FetchError as e:
             errors.append(package)
-            ctx.ui.info(inary.util.colorize(_("%s could not be found") % (package), "red"))
+            ctx.ui.info(inary.util.colorize(_("{} could not be found").format(package), "red"))
             return False
     else:
-        ctx.ui.info(_('%s [cached]') % uri.filename())
+        ctx.ui.info(_('{} [cached]').format(uri.filename()))
     return True
 
 def get_snapshot_actions(operation):
diff --git i/inary/operations/install.py w/inary/operations/install.py
index 33b94be0..84e13409 100644
--- i/inary/operations/install.py
+++ w/inary/operations/install.py
@@ -118,7 +118,7 @@ def install_pkg_names(A, reinstall = False, extra = False):
         install_op.install(False)
         try:
             with open(os.path.join(ctx.config.info_dir(), ctx.const.installed_extra), "a") as ie_file:
-                ie_file.write("%s\n" % extra_paths[path])
+                ie_file.write("{}\n".format(extra_paths[path]))
             installdb.installed_extra.append(extra_paths[path])
         except KeyError:
             pass
@@ -129,7 +129,7 @@ def install_pkg_files(package_URIs, reinstall = False):
     """install a number of inary package files"""
 
     installdb = inary.db.installdb.InstallDB()
-    ctx.ui.debug('A = %s' % str(package_URIs))
+    ctx.ui.debug('A = {}'.format(str(package_URIs)))
 
     for x in package_URIs:
         if not x.endswith(ctx.const.package_suffix):
@@ -177,12 +177,11 @@ def install_pkg_files(package_URIs, reinstall = False):
         for x in list(d_t.keys()):
             pkg = d_t[x]
             if pkg.distributionRelease != ctx.config.values.general.distribution_release:
-                raise Exception(_('Package %s is not compatible with your distribution release %s %s.') \
-                        % (x, ctx.config.values.general.distribution, \
+                raise Exception(_('Package {0} is not compatible with your distribution release {1} {2}.').format(
+                        x, ctx.config.values.general.distribution, \
                         ctx.config.values.general.distribution_release))
             if pkg.architecture != ctx.config.values.general.architecture:
-                raise Exception(_('Package %s (%s) is not compatible with your %s architecture.') \
-                        % (x, pkg.architecture, ctx.config.values.general.architecture))
+                raise Exception(_('Package {0} ({1}) is not compatible with your {2} architecture.').format(x, pkg.architecture, ctx.config.values.general.architecture))
 
     def satisfiesDep(dep):
         # is dependency satisfied among available packages
@@ -204,7 +203,7 @@ def install_pkg_files(package_URIs, reinstall = False):
     # be satisfied by installing packages from the repo
     for dep in dep_unsatis:
         if not dep.satisfied_by_repo():
-            raise Exception(_('External dependencies not satisfied: %s') % dep)
+            raise Exception(_('External dependencies not satisfied: {}').format(dep))
 
     # if so, then invoke install_pkg_names
     extra_packages = [x.package for x in dep_unsatis]
@@ -287,11 +286,11 @@ def plan_install_pkg_names(A):
         for x in B:
             pkg = packagedb.get_package(x)
             for dep in pkg.runtimeDependencies():
-                ctx.ui.debug('checking %s' % str(dep))
+                ctx.ui.debug('checking {}'.format(str(dep)))
                 # we don't deal with already *satisfied* dependencies
                 if not dep.satisfied_by_installed():
                     if not dep.satisfied_by_repo():
-                        raise Exception(_('%s dependency of package %s is not satisfied') % (dep, pkg.name))
+                        raise Exception(_('{0} dependency of package {1} is not satisfied').format(dep, pkg.name))
                     if not dep.package in G_f.vertices():
                         Bp.add(str(dep.package))
                     G_f.add_dep(x, dep)
diff --git i/inary/operations/remove.py w/inary/operations/remove.py
index eeaed8fa..3c451294 100644
--- i/inary/operations/remove.py
+++ w/inary/operations/remove.py
@@ -53,7 +53,7 @@ def remove(A, ignore_dep = False, ignore_safety = False):
         if installdb.has_package(x):
             Ap.append(x)
         else:
-            ctx.ui.info(_('Package %s does not exist. Cannot remove.') % x)
+            ctx.ui.info(_('Package {} does not exist. Cannot remove.').format(x))
     A = set(Ap)
 
     if len(A)==0:
@@ -88,7 +88,7 @@ in the respective order to satisfy dependencies:
                     ie_file.write("\n".join(installdb.installed_extra) + ("\n" if installdb.installed_extra else ""))
 
         else:
-            ctx.ui.info(_('Package %s is not installed. Cannot remove.') % x)
+            ctx.ui.info(_('Package {} is not installed. Cannot remove.').format(x))
 
 def plan_remove(A):
     # try to construct a inary graph of packages to
diff --git i/inary/operations/upgrade.py w/inary/operations/upgrade.py
index 99cb80ea..816e7b75 100644
--- i/inary/operations/upgrade.py
+++ w/inary/operations/upgrade.py
@@ -52,14 +52,14 @@ def check_update_actions(packages):
         ctx.ui.warning(_("You must restart the following service(s) manually "
                          "for the updated software to take effect:"))
         for package, target in actions["serviceRestart"]:
-            ctx.ui.info("    - %s" % target)
+            ctx.ui.info("    - {}".format(target))
 
     if "systemRestart" in actions:
         has_actions = True
         ctx.ui.warning(_("You must restart your system for the updates "
                          "in the following package(s) to take effect:"))
         for package, target in actions["systemRestart"]:
-            ctx.ui.info("    - %s" % package)
+            ctx.ui.info("    - {}".format(package))
 
     return has_actions
 
@@ -84,11 +84,11 @@ def find_upgrades(packages, replaces):
             ctx.ui.debug(_("Warning: package *name* ends with '.inary'"))
 
         if not installdb.has_package(i_pkg):
-            ctx.ui.info(_('Package %s is not installed.') % i_pkg, True)
+            ctx.ui.info(_('Package {} is not installed.').format(i_pkg), True)
             continue
 
         if not packagedb.has_package(i_pkg):
-            ctx.ui.info(_('Package %s is not available in repositories.') % i_pkg, True)
+            ctx.ui.info(_('Package {} is not available in repositories.').format(i_pkg), True)
             continue
 
         pkg = packagedb.get_package(i_pkg)
@@ -111,8 +111,8 @@ def find_upgrades(packages, replaces):
                 Ap.append(i_pkg)
                 ds.append(i_pkg)
             else:
-                ctx.ui.info(_('Package %s is already at the latest release %s.')
-                            % (pkg.name, pkg.release), True)
+                ctx.ui.info(_('Package {0.name} is already at the latest release {0.release}.').format(
+                             pkg), True)
 
     if debug and ds:
         ctx.ui.status(_('The following packages have different sha1sum:'))
@@ -153,13 +153,13 @@ def upgrade(A=[], repo=None):
     if ctx.get_option('exclude'):
         A = inary.blacklist.exclude(A, ctx.get_option('exclude'))
 
-    ctx.ui.debug('A = %s' % str(A))
+    ctx.ui.debug('A = {}'.format(str(A)))
 
     if len(A)==0:
         ctx.ui.info(_('No packages to upgrade.'))
         return True
 
-    ctx.ui.debug('A = %s' % str(A))
+    ctx.ui.debug('A = {}'.format(str(A)))
 
     if not ctx.config.get_option('ignore_dependency'):
         G_f, order = plan_upgrade(A, replaces=replaces)
@@ -264,7 +264,7 @@ def plan_upgrade(A, force_replaced=True, replaces=None):
                 # previous ones.
                 G_f.add_dep(pkg.name, dep)
             else:
-                ctx.ui.error(_('Dependency %s of %s cannot be satisfied') % (dep, pkg.name))
+                ctx.ui.error(_('Dependency {0} of {1} cannot be satisfied').format(dep, pkg.name))
                 raise Exception(_("Upgrade is not possible."))
 
     def add_resolvable_conflicts(pkg, Bp):
diff --git i/inary/package.py w/inary/package.py
index f41003c0..8a98344c 100644
--- i/inary/package.py
+++ w/inary/package.py
@@ -65,7 +65,7 @@ class Package:
         try:
             self.impl = archive.ArchiveZip(self.filepath, 'zip', mode)
         except IOError as e:
-            raise Error(_("Cannot open package file: %s") % e)
+            raise Error(_("Cannot open package file: {}").format(e))
 
         self.install_archive = None
 
@@ -86,7 +86,7 @@ class Package:
         self.format = format or Package.default_format
 
         if self.format not in Package.formats:
-            raise Error(_("Unsupported package format: %s") % format)
+            raise Error(_("Unsupported package format: {}").format(format))
 
         self.tmp_dir = tmp_dir or ctx.config.tmp_dir()
 
@@ -100,11 +100,10 @@ class Package:
             except inary.fetcher.FetchError:
                 # Bug 3465
                 if ctx.get_option('reinstall'):
-                    raise Error(_("There was a problem while fetching '%s'.\nThe package "
-                    "may have been upgraded. Please try to upgrade the package.") % url);
+                    raise Error(_("There was a problem while fetching '{}'.\nThe package may have been upgraded. Please try to upgrade the package.").format(url))
                 raise
         else:
-            ctx.ui.info(_('%s [cached]') % url.filename())
+            ctx.ui.info(_('{} [cached]').format(url.filename()))
 
     def add_to_package(self, fn, an=None):
         """Add a file or directory to package"""
diff --git i/inary/reactor.py w/inary/reactor.py
index ad925117..3df8fb41 100644
--- i/inary/reactor.py
+++ w/inary/reactor.py
@@ -318,11 +318,11 @@ def fetch(packages=[], path=os.path.curdir):
     repodb = inary.db.repodb.RepoDB()
     for name in packages:
         package, repo = packagedb.get_package_repo(name)
-        ctx.ui.info(_("%s package found in %s repository") % (package.name, repo))
+        ctx.ui.info(_("{0} package found in {1} repository").format(package.name, repo))
         uri = inary.uri.URI(package.packageURI)
         output = os.path.join(path, uri.path())
         if os.path.exists(output) and package.packageHash == inary.util.sha1_file(output):
-            ctx.ui.warning(_("%s package already fetched") % uri.path())
+            ctx.ui.warning(_("{} package already fetched").format(uri.path()))
             continue
         if uri.is_absolute_path():
             url = str(pkg_uri)
@@ -440,15 +440,15 @@ def delete_cache():
     """
     Deletes cached packages, cached archives, build dirs, db caches
     """
-    ctx.ui.info(_("Cleaning package cache %s...") % ctx.config.cached_packages_dir())
+    ctx.ui.info(_("Cleaning package cache {}...").format(ctx.config.cached_packages_dir()))
     inary.util.clean_dir(ctx.config.cached_packages_dir())
-    ctx.ui.info(_("Cleaning source archive cache %s...") % ctx.config.archives_dir())
+    ctx.ui.info(_("Cleaning source archive cache {}...").format(ctx.config.archives_dir()))
     inary.util.clean_dir(ctx.config.archives_dir())
-    ctx.ui.info(_("Cleaning temporary directory %s...") % ctx.config.tmp_dir())
+    ctx.ui.info(_("Cleaning temporary directory {}...").format(ctx.config.tmp_dir()))
     inary.util.clean_dir(ctx.config.tmp_dir())
     for cache in [x for x in os.listdir(ctx.config.cache_root_dir()) if x.endswith(".cache")]:
         cache_file = inary.util.join_path(ctx.config.cache_root_dir(), cache)
-        ctx.ui.info(_("Removing cache file %s...") % cache_file)
+        ctx.ui.info(_("Removing cache file {}...").format(cache_file))
         os.unlink(cache_file)
 
 @locked
@@ -536,7 +536,7 @@ def package_graph(A, packagedb, ignore_installed = False, reverse=False):
 
     """
 
-    ctx.ui.debug('A = %s' % str(A))
+    ctx.ui.debug('A = {}'.format(str(A)))
 
     # try to construct a inary graph of packages to
     # install / reinstall
@@ -652,7 +652,7 @@ def info(package, installed = False):
 def info_file(package_fn):
 
     if not os.path.exists(package_fn):
-        raise inary.Error (_('File %s not found') % package_fn)
+        raise inary.Error (_('File {} not found').format(package_fn))
 
     package = inary.package.Package(package_fn)
     package.read()
@@ -694,7 +694,7 @@ def index(dirs=None, output='inary-index.xml',
         dirs = ['.']
     for repo_dir in dirs:
         repo_dir = str(repo_dir)
-        ctx.ui.info(_('Building index of Inary files under %s') % repo_dir)
+        ctx.ui.info(_('Building index of Inary files under {}').format(repo_dir))
         index.index(repo_dir, skip_sources)
 
     sign = None if skip_signing else inary.file.File.detached
@@ -704,19 +704,19 @@ def index(dirs=None, output='inary-index.xml',
 @locked
 def add_repo(name, indexuri, at = None):
     import re
-    if not re.match("^[0-9%s\-\\_\\.\s]*$" % str(inary.util.letters()), name):
+    if not re.match("^[0-9{}\-\\_\\.\s]*$".format(str(inary.util.letters())), name):
         raise inary.Error(_('Not a valid repo name.'))
     repodb = inary.db.repodb.RepoDB()
     if repodb.has_repo(name):
-        raise inary.Error(_('Repo %s already present.') % name)
+        raise inary.Error(_('Repo {} already present.').format(name))
     elif repodb.has_repo_url(indexuri, only_active = False):
         repo = repodb.get_repo_by_url(indexuri)
-        raise inary.Error(_('Repo already present with name %s.') % repo)
+        raise inary.Error(_('Repo already present with name {}.').format(repo))
     else:
         repo = inary.db.repodb.Repo(inary.uri.URI(indexuri))
         repodb.add_repo(name, repo, at = at)
         inary.db.flush_caches()
-        ctx.ui.info(_('Repo %s added to system.') % name)
+        ctx.ui.info(_('Repo {} added to system.').format(name))
 
 @locked
 def remove_repo(name):
@@ -724,10 +724,9 @@ def remove_repo(name):
     if repodb.has_repo(name):
         repodb.remove_repo(name)
         inary.db.flush_caches()
-        ctx.ui.info(_('Repo %s removed from system.') % name)
+        ctx.ui.info(_('Repo {} removed from system.').format(name))
     else:
-        raise inary.Error(_('Repository %s does not exist. Cannot remove.')
-                 % name)
+        raise inary.Error(_('Repository {} does not exist. Cannot remove.').format(name))
 
 @locked
 def update_repos(repos, force=False):
@@ -748,7 +747,7 @@ def update_repo(repo, force=False):
         inary.db.regenerate_caches()
 
 def __update_repo(repo, force=False):
-    ctx.ui.action(_('Updating repository: %s') % repo)
+    ctx.ui.action(_('Updating repository: {}').format(repo))
     ctx.ui.notify(inary.ui.updatingrepo, name = repo)
     repodb = inary.db.repodb.RepoDB()
     index = inary.data.index.Index()
@@ -757,7 +756,7 @@ def __update_repo(repo, force=False):
         try:
             index.read_uri_of_repo(repouri, repo)
         except inary.file.AlreadyHaveException as e:
-            ctx.ui.info(_('%s repository information is up-to-date.') % repo)
+            ctx.ui.info(_('{} repository information is up-to-date.').format(repo))
             if force:
                 ctx.ui.info(_('Updating database at any rate as requested'))
                 index.read_uri_of_repo(repouri, repo, force = force)
@@ -774,7 +773,7 @@ def __update_repo(repo, force=False):
 
         ctx.ui.info(_('Package database updated.'))
     else:
-        raise inary.Error(_('No repository named %s found.') % repo)
+        raise inary.Error(_('No repository named {} found.').format(repo))
 
     return True
 
@@ -834,7 +833,7 @@ def clearCache(all=False):
 
         latestVersions = []
         for pkg in latest:
-            latestVersions.append("%s-%s" % (pkg, latest[pkg][0]))
+            latestVersions.append("{0}-{1}".format(pkg, latest[pkg][0]))
 
         oldVersions = list(set(pkgList) - set(latestVersions))
         return oldVersions, latestVersions
@@ -859,7 +858,7 @@ def clearCache(all=False):
                     pass
 
     def removeAll(cacheDir):
-        cached = glob.glob("%s/*.inary" % cacheDir) + glob.glob("%s/*.part" % cacheDir)
+        cached = glob.glob("{}/*.inary".format(cacheDir)) + glob.glob("{}/*.part".format(cacheDir))
         for pkg in cached:
             try:
                 os.remove(pkg)
@@ -868,7 +867,7 @@ def clearCache(all=False):
 
     cacheDir = ctx.config.cached_packages_dir()
 
-    pkgList = [os.path.basename(x).split(ctx.const.package_suffix)[0] for x in glob.glob("%s/*.inary" % cacheDir)]
+    pkgList = [os.path.basename(x).split(ctx.const.package_suffix)[0] for x in glob.glob("{}/*.inary".format(cacheDir))]
     if not all:
         # Cache limits from inary.conf
         config = inary.configfile.ConfigurationFile("/etc/inary/inary.conf")
diff --git i/inary/scomiface.py w/inary/scomiface.py
index 957b2020..c40255f0 100644
--- i/inary/scomiface.py
+++ w/inary/scomiface.py
@@ -48,7 +48,7 @@ def safe_script_name(package):
         if not is_char_valid(char):
             object = object.replace(char, '_')
     if object[0].isdigit():
-        object = '_%s' % object
+        object = '_{}'.format(object)
     return object
 
 def get_link():
@@ -85,8 +85,7 @@ def get_link():
             exceptions.append(str(e))
         time.sleep(0.2)
         timeout -= 0.2
-    raise Error(_("Cannot connect to SCOM: \n  %s\n")
-                % "\n  ".join(exceptions))
+    raise Error(_("Cannot connect to SCOM: \n  {}\n").format("\n  ".join(exceptions)))
 
 
 def post_install(package_name, provided_scripts,
@@ -94,7 +93,7 @@ def post_install(package_name, provided_scripts,
                  fromVersion, fromRelease, toVersion, toRelease):
     """Do package's post install operations"""
 
-    ctx.ui.info(_("Configuring %s package") % package_name)
+    ctx.ui.info(_("Configuring {} package").format(package_name))
     self_post = False
 
     package_name = safe_script_name(package_name)
@@ -107,7 +106,7 @@ def post_install(package_name, provided_scripts,
     link = get_link()
 
     for script in provided_scripts:
-        ctx.ui.debug(_("Registering %s scom script") % script.om)
+        ctx.ui.debug(_("Registering {} scom script").format(script.om))
         script_name = safe_script_name(script.name) \
                 if script.name else package_name
         if script.om == "System.Package":
@@ -116,12 +115,12 @@ def post_install(package_name, provided_scripts,
             link.register(script_name, script.om,
                           os.path.join(scriptpath, script.script))
         except dbus.DBusException as exception:
-            raise Error(_("Script error: %s") % exception)
+            raise Error(_("Script error: {}").format(exception))
         if script.om == "System.Service":
             try:
                 link.System.Service[script_name].registerState()
             except dbus.DBusException as exception:
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
     ctx.ui.debug(_("Calling post install handlers"))
     for handler in link.System.PackageHandler:
@@ -134,7 +133,7 @@ def post_install(package_name, provided_scripts,
             # Do nothing if setupPackage method is not defined
             # in package script
             if not is_method_missing(exception):
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
     if self_post:
         if not fromVersion:
@@ -150,13 +149,13 @@ def post_install(package_name, provided_scripts,
         except dbus.DBusException as exception:
             # Do nothing if postInstall method is not defined in package script
             if not is_method_missing(exception):
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
 
 def pre_remove(package_name, metapath, filepath):
     """Do package's pre removal operations"""
 
-    ctx.ui.info(_("Running pre removal operations for %s") % package_name)
+    ctx.ui.info(_("Running pre removal operations for {}").format(package_name))
     link = get_link()
 
     package_name = safe_script_name(package_name)
@@ -169,7 +168,7 @@ def pre_remove(package_name, metapath, filepath):
         except dbus.DBusException as exception:
             # Do nothing if preRemove method is not defined in package script
             if not is_method_missing(exception):
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
     ctx.ui.debug(_("Calling pre remove handlers"))
     for handler in list(link.System.PackageHandler):
@@ -180,13 +179,13 @@ def pre_remove(package_name, metapath, filepath):
             # Do nothing if cleanupPackage method is not defined
             # in package script
             if not is_method_missing(exception):
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
 
 def post_remove(package_name, metapath, filepath, provided_scripts=[]):
     """Do package's post removal operations"""
 
-    ctx.ui.info(_("Running post removal operations for %s") % package_name)
+    ctx.ui.info(_("Running post removal operations for {}").format(package_name))
     link = get_link()
 
     package_name = safe_script_name(package_name)
@@ -202,7 +201,7 @@ def post_remove(package_name, metapath, filepath, provided_scripts=[]):
         except dbus.DBusException as exception:
             # Do nothing if postRemove method is not defined in package script
             if not is_method_missing(exception):
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
     ctx.ui.debug(_("Calling post remove handlers"))
     for handler in list(link.System.PackageHandler):
@@ -213,11 +212,11 @@ def post_remove(package_name, metapath, filepath, provided_scripts=[]):
             # Do nothing if postCleanupPackage method is not defined
             # in package script
             if not is_method_missing(exception):
-                raise Error(_("Script error: %s") % exception)
+                raise Error(_("Script error: {}").format(exception))
 
     ctx.ui.debug(_("Unregistering scom scripts"))
     for scr in scripts:
         try:
             link.remove(scr, timeout=ctx.dbus_timeout)
         except dbus.DBusException as exception:
-            raise Error(_("Script error: %s") % exception)
+            raise Error(_("Script error: {}").format(exception))
diff --git i/inary/sourcearchive.py w/inary/sourcearchive.py
index 8726a9ca..a89fb274 100644
--- i/inary/sourcearchive.py
+++ w/inary/sourcearchive.py
@@ -59,7 +59,7 @@ class SourceArchive:
                 self.progress = None
 
             try:
-                ctx.ui.info(_("Fetching source from: %s") % self.url.uri)
+                ctx.ui.info(_("Fetching source from: {}").format(self.url.uri))
                 if self.url.get_uri().startswith("mirrors://"):
                     self.fetch_from_mirror()
                 if self.url.get_uri().startswith("file://"):
@@ -72,13 +72,12 @@ class SourceArchive:
                 else:
                     raise
 
-            ctx.ui.info(_("\nSource archive is stored: %s/%s")
-                % (ctx.config.archives_dir(), self.url.filename()))
+            ctx.ui.info(_("\nSource archive is stored: {0}/{1}").format(ctx.config.archives_dir(), self.url.filename()))
 
     def fetch_from_fallback(self):
         archive = os.path.basename(self.url.get_uri())
         src = os.path.join(ctx.config.values.build.fallback, archive)
-        ctx.ui.warning(_('Trying fallback address: %s') % src)
+        ctx.ui.warning(_('Trying fallback address: {}').format(src))
         inary.fetcher.fetch_url(src, ctx.config.archives_dir(), self.progress)
 
     def fetch_from_locale(self):
@@ -97,18 +96,18 @@ class SourceArchive:
 
         mirrors = inary.mirrors.Mirrors().get_mirrors(name)
         if not mirrors:
-            raise Error(_("%s mirrors are not defined.") % name)
+            raise Error(_("{} mirrors are not defined.").format(name))
 
         for mirror in mirrors:
             try:
                 url = os.path.join(mirror, archive)
-                ctx.ui.warning(_('Fetching source from mirror: %s') % url)
+                ctx.ui.warning(_('Fetching source from mirror: {}').format(url))
                 inary.fetcher.fetch_url(url, ctx.config.archives_dir(), self.progress)
                 return
             except inary.fetcher.FetchError:
                 pass
 
-        raise inary.fetcher.FetchError(_('Could not fetch source from %s mirrors.') % name);
+        raise inary.fetcher.FetchError(_('Could not fetch source from {} mirrors.').format(name))
 
     def is_cached(self, interactive=True):
         if not os.access(self.archiveFile, os.R_OK):
@@ -117,7 +116,7 @@ class SourceArchive:
         # check hash
         if util.check_file_hash(self.archiveFile, self.archive.sha1sum):
             if interactive:
-                ctx.ui.info(_('%s [cached]') % self.archive.name)
+                ctx.ui.info(_('{} [cached]').format(self.archive.name))
             return True
 
         return False
@@ -131,11 +130,9 @@ class SourceArchive:
         try:
             archive = inary.archive.Archive(self.archiveFile, self.archive.type)
         except inary.archive.UnknownArchiveType:
-            raise Error(_("Unknown archive type '%s' is given for '%s'.")
-                        % (self.archive.type, self.url.filename()))
+            raise Error(_("Unknown archive type '{0}' is given for '{1}'.").format(self.archive.type, self.url.filename()))
         except inary.archive.ArchiveHandlerNotInstalled:
-            raise Error(_("Inary needs %s to unpack this archive but it is not installed.")
-                        % self.archive.type)
+            raise Error(_("Inary needs {} to unpack this archive but it is not installed.").format(self.archive.type))
 
         target_dir = os.path.join(target_dir, self.archive.target or "")
         archive.unpack(target_dir, clean_dir)
diff --git i/inary/sxml/autoxml.py w/inary/sxml/autoxml.py
index 9460ab4e..b444f06a 100644
--- i/inary/sxml/autoxml.py
+++ w/inary/sxml/autoxml.py
@@ -76,15 +76,13 @@ class LocalText(dict):
         nodes = xmlext.getAllNodes(node, self.tag)
         if not nodes:
             if self.req == mandatory:
-                errs.append(where + ': ' + _("At least one '%s' tag should have local text") %
-                                    self.tag )
+                errs.append(where + ': ' + _("At least one '{}' tag should have local text").format(self.tag))
         else:
             for node in nodes:
                 lang = xmlext.getNodeAttribute(node, 'xml:lang')
                 c = xmlext.getNodeText(node)
                 if not c:
-                    errs.append(where + ': ' + _("'%s' language of tag '%s' is empty") %
-                                (lang, self.tag))
+                    errs.append(where + ': ' + _("'{0}' language of tag '{1}' is empty").format(lang, self.tag))
                 # FIXME: check for dups and 'en'
                 if not lang:
                     lang = 'en'
@@ -367,7 +365,7 @@ class autoxml(oo.autosuper, oo.autoprop):
         def check(self):
             errs = self.errors()
             if errs:
-                errs.append(_("autoxml.check: '%s' errors") % len(errs))
+                errs.append(_("autoxml.check: '{}' errors").format(len(errs)))
                 raise Error(*errs)
         cls.check = check
 
@@ -423,7 +421,7 @@ class autoxml(oo.autosuper, oo.autoprop):
                 errs = []
                 self.decode(self.rootNode(), errs)
                 if errs:
-                    errs.append(_("autoxml.parse: String '%s' has errors") % xml)
+                    errs.append(_("autoxml.parse: String '{}' has errors").format(xml))
                     raise Error(*errs)
                 if hasattr(self, 'read_hook'):
                     self.read_hook(errs)
@@ -433,7 +431,7 @@ class autoxml(oo.autosuper, oo.autoprop):
 
                 errs = self.errors()
                 if errs:
-                    errs.append(_("autoxml.parse: String '%s' has errors") % xml)
+                    errs.append(_("autoxml.parse: String '{}' has errors").format(xml))
 
             def read(self, uri, keepDoc = False, tmpDir = '/tmp',
                      sha1sum = False, compress = None, sign = None, copylocal = False, nodecode = False):
@@ -447,7 +445,7 @@ class autoxml(oo.autosuper, oo.autoprop):
                 errs = []
                 self.decode(self.rootNode(), errs)
                 if errs:
-                    errs.append(_("autoxml.read: File '%s' has errors") % uri)
+                    errs.append(_("autoxml.read: File '{}' has errors").format(uri))
                     raise Error(*errs)
                 if hasattr(self, 'read_hook'):
                     self.read_hook(errs)
@@ -457,7 +455,7 @@ class autoxml(oo.autosuper, oo.autoprop):
 
                 errs = self.errors()
                 if errs:
-                    errs.append(_("autoxml.read: File '%s' has errors") % uri)
+                    errs.append(_("autoxml.read: File '{}' has errors").format(uri))
                     raise Error(*errs)
 
             def write(self, uri, keepDoc = False, tmpDir = '/tmp',
@@ -473,7 +471,7 @@ class autoxml(oo.autosuper, oo.autoprop):
                 if hasattr(self, 'write_hook'):
                     self.write_hook(errs)
                 if errs:
-                    errs.append(_("autoxml.write: File encoding '%s' has errors") % uri)
+                    errs.append(_("autoxml.write: File encoding '{}' has errors").format(uri))
                     raise Error(*errs)
                 self.writexml(uri, tmpDir, sha1sum=sha1sum, compress=compress, sign=sign)
                 if not keepDoc:
@@ -523,8 +521,7 @@ class autoxml(oo.autosuper, oo.autoprop):
         elif type(tag_type) is autoxml or type(tag_type) is type:
             return cls.gen_class_tag(tag, spec)
         else:
-            raise Error(_('gen_tag: unrecognized tag type %s in spec') %
-                        str(tag_type))
+            raise Error(_('gen_tag: unrecognized tag type {} in spec').format(str(tag_type)))
 
     def gen_str_member(cls, token):
         """generate readers and writers for a string member"""
@@ -571,7 +568,7 @@ class autoxml(oo.autosuper, oo.autoprop):
                 errs.extend(errors_a(value, where + '.' + name))
             else:
                 if req == mandatory:
-                    errs.append(where + ': ' + _('Mandatory variable %s not available') % name)
+                    errs.append(where + ': ' + _('Mandatory variable {} not available').format(name))
             return errs
 
         def format(self, f, errs):
@@ -582,7 +579,7 @@ class autoxml(oo.autosuper, oo.autoprop):
                 f.add_line_break()
             else:
                 if req == mandatory:
-                    errs.append(_('Mandatory variable %s not available') % name)
+                    errs.append(_('Mandatory variable {} not available').format(name))
 
         return (name, init, decode, encode, errors, format)
 
@@ -656,7 +653,7 @@ class autoxml(oo.autosuper, oo.autoprop):
                 return value
             else:
                 if req == mandatory:
-                    errs.append(where + ': ' + _('Mandatory token %s not available') % token)
+                    errs.append(where + ': ' + _('Mandatory token {} not available').format(token))
                 return None
 
         def encode(node, value, errs):
@@ -665,13 +662,12 @@ class autoxml(oo.autosuper, oo.autoprop):
                 writetext(node, token, str(value))
             else:
                 if req == mandatory:
-                    errs.append(_('Mandatory token %s not available') % token)
+                    errs.append(_('Mandatory token {} not available').format(token))
 
         def errors(value, where):
             errs = []
             if value and not isinstance(value, token_type):
-                errs.append(where + ': ' + _('Type mismatch. Expected %s, got %s') %
-                                    (token_type, type(value)) )
+                errs.append(where + ': ' + _('Type mismatch. Expected {0}, got {1}').format(token_type, type(value)) )
             return errs
 
         def format(value, f, errs):
@@ -759,13 +755,12 @@ class autoxml(oo.autosuper, oo.autoprop):
             nodes = xmlext.getAllNodes(node, path)
             #print node, tag + '/' + comp_tag, nodes
             if len(nodes)==0 and req==mandatory:
-                errs.append(where + ': ' + _('Mandatory list "%s" under "%s" node is empty.') % (path, node.name()))
+                errs.append(where + ': ' + _('Mandatory list "{0}" under "{1}" node is empty.').format(path, node.name()))
             ix = 1
             for node in nodes:
                 dummy = xmlext.newNode(node, "Dummy")
                 xmlext.addNode(dummy, '', node)
-                l.append(decode_item(dummy, errs, where + str("[%s]" % ix)))
-                #l.append(decode_item(node, errs, where + unicode("[%s]" % ix)))
+                l.append(decode_item(dummy, errs, where + str("[{}]".format(ix))))
                 ix += 1
             return l
 
@@ -780,13 +775,13 @@ class autoxml(oo.autosuper, oo.autoprop):
                     #encode_item(node, item, errs)
             else:
                 if req is mandatory:
-                    errs.append(_('Mandatory list "%s" under "%s" node is empty.') % (path, node.name()))
+                    errs.append(_('Mandatory list "{0}" under "{1}" node is empty.').format(path, node.name()))
 
         def errors(l, where):
             errs = []
             ix = 1
             for node in l:
-                errs.extend(errors_item(node, where + '[%s]' % ix))
+                errs.extend(errors_item(node, where + '[{}]'.format(ix)))
                 ix += 1
             return errs
 
diff --git i/inary/sxml/xmlfile.py w/inary/sxml/xmlfile.py
index 12696519..55d25fbe 100644
--- i/inary/sxml/xmlfile.py
+++ w/inary/sxml/xmlfile.py
@@ -60,7 +60,7 @@ class XmlFile(object):
         self.doc = iks.parseString(str(file))
         return self.doc
         #except Exception as e:
-            #raise Error(_("File '%s' has invalid XML") % (file) )
+            #raise Error(_("File '{}' has invalid XML").format(file) )
 
 
     def readxml(self, uri, tmpDir='/tmp', sha1sum=False, 
@@ -70,7 +70,7 @@ class XmlFile(object):
             localpath = File.download(uri, tmpDir, sha1sum=sha1sum, 
                                   compress=compress,sign=sign, copylocal=copylocal)
         except IOError as e:
-            raise Error(_("Cannot read URI %s: %s") % (uri, str(e)) )
+            raise Error(_("Cannot read URI {0}: {1}").format(uri, str(e)) )
         
         st = io.StringIO()
         
@@ -85,7 +85,7 @@ class XmlFile(object):
             self.doc = iks.parse(localpath)
             return self.doc
         except Exception as e:
-            raise Error(_("File '%s' has invalid XML") % (localpath) )
+            raise Error(_("File '{}' has invalid XML").format(localpath) )
 
     def writexml(self, uri, tmpDir = '/tmp', sha1sum=False, compress=None, sign=None):
         f = inary.file.File(uri, inary.file.File.write, sha1sum=sha1sum, compress=compress, sign=sign)
diff --git i/inary/system_literals/diskutils.py w/inary/system_literals/diskutils.py
index 69751944..2134d8da 100644
--- i/inary/system_literals/diskutils.py
+++ w/inary/system_literals/diskutils.py
@@ -38,13 +38,13 @@ def idsQuery(name, vendor, device):
         else:
             if line.startswith("\t"):
                 if line.startswith("\t" + device):
-                    return "%s - %s" % (line[6:].strip(), company)
+                    return "{0} - {1}" % (line[6:].strip(), company)
             elif not line.startswith("#"):
                 flag = 0
     if company != "":
-        return "%s (%s)" % (company, device)
+        return "{0} ({1})".format(company, device)
     else:
-        return "Unknown (%s:%s)" % (vendor, device)
+        return "Unknown ({0}:{1})".format(vendor, device)
 
 class EDD:
     def __init__(self):
@@ -67,7 +67,7 @@ class EDD:
         return "0x"+b[3]+b[2]+b[1]+b[0]
 
     def get_edd_sig(self, _n):
-        sigfile = "%s/int13_dev%s/mbr_signature" % (self.edd_dir, _n)
+        sigfile = "{0}/int13_dev{1}/mbr_signature".format(self.edd_dir, _n)
         if os.path.exists(sigfile):
             sig = open(sigfile).read().strip("\n")
         else:
@@ -132,7 +132,7 @@ def getDeviceMap():
     for bios_num in edd_keys:
         edd_sig = edd_list[bios_num]
         if edd_sig in mbr_list:
-            devices.append(("hd%s" % i, mbr_list[edd_sig]))
+            devices.append(("hd{}".format(i), mbr_list[edd_sig]))
             i += 1
 
     return devices
@@ -184,7 +184,7 @@ def parseGrubDevice(device):
             # If device address ends with a number,
             # "p" is used before partition number
             if linux_disk[-1].isdigit():
-                linux_part = "p%s" % linux_part
+                linux_part = "p{}".format(linux_part)
             return grub_disk, part, linux_disk, linux_part
     return None
 
@@ -202,7 +202,7 @@ def grubAddress(device):
         linux_disk, linux_part, grub_disk, grub_part = parseLinuxDevice(device)
     except (ValueError, TypeError):
         return None
-    return "(%s,%s)" % (grub_disk, grub_part)
+    return "({0},{1})".format(grub_disk, grub_part)
 
 def linuxAddress(device):
     """
@@ -218,7 +218,7 @@ def linuxAddress(device):
         grub_disk, grub_part, linux_disk, linux_part = parseGrubDevice(device)
     except (ValueError, TypeError):
         return None
-    return "%s%s" % (linux_disk, linux_part)
+    return "{0}{1}".format(linux_disk, linux_part)
 
 def getDeviceByLabel(label):
     """
@@ -230,9 +230,9 @@ def getDeviceByLabel(label):
             None on error, Linux device on success
     """
 
-    fn = os.path.join("/dev/disk/by-label/%s" % label)
+    fn = os.path.join("/dev/disk/by-label/{}".format(label))
     if os.path.islink(fn):
-        return "/dev/%s" % os.readlink(fn)[6:]
+        return "/dev/{}".format(os.readlink(fn)[6:])
     else:
         return None
 
@@ -246,9 +246,9 @@ def getDeviceByUUID(uuid):
             None on error, Linux device on success
     """
 
-    fn = os.path.join("/dev/disk/by-uuid/%s" % uuid)
+    fn = os.path.join("/dev/disk/by-uuid/{}".format(uuid))
     if os.path.islink(fn):
-        return "/dev/%s" % os.readlink(fn)[6:]
+        return "/dev/{}".format(os.readlink(fn)[6:])
     else:
         return None
 
diff --git i/inary/system_literals/firmwares.py w/inary/system_literals/firmwares.py
index 457a1b5f..0fb99d51 100644
--- i/inary/system_literals/firmwares.py
+++ w/inary/system_literals/firmwares.py
@@ -30,12 +30,12 @@ class Error(inary.Error):
     pass
 
 def get_firmwares():
-    ctx.ui.info(inary.util.colorize("Extracting firmware list for %s..." % os.uname()[2], "green"))
+    ctx.ui.info(inary.util.colorize("Extracting firmware list for {}...".format(os.uname()[2]), "green"))
     d = {}
     modules = [os.path.basename(mod.replace(".ko", "")) for mod in \
             os.popen("modprobe -l").read().strip().split("\n")]
     for mod in modules:
-        fws = os.popen("modinfo -F firmware %s" % mod).read().strip()
+        fws = os.popen("modinfo -F firmware {}".format(mod)).read().strip()
         if fws:
             try:
                 d[mod].extend(fws.split("\n"))
@@ -54,15 +54,15 @@ def get_firmware_package(firmware):
             ctx.ui.info("\n".join(unavailable_fw_packages))
 
         for module, firmwares in list(get_firmwares().items()):
-            ctx.ui.info("\n %s requires the following firmwares:" % module)
+            ctx.ui.info("\n {} requires the following firmwares:".format(module))
             for fw in firmwares:
-                ctx.ui.info("  * %s" % fw, noln = True)
+                ctx.ui.info("  * {}".format(fw), noln = True)
                 try:
                     firmware = inary.api.search_file(fw)[0][0]
                 except:
                     pass
 
-                ctx.ui.info(" (%s)" % (inary.util.colorize(firmware, 'green') if firmware else \
+                ctx.ui.info(" ({})".format(inary.util.colorize(firmware, 'green') if firmware else \
                         inary.util.colorize("missing", 'red')))
     except:
         raise Error()
diff --git i/inary/system_literals/fstabutils.py w/inary/system_literals/fstabutils.py
index db698535..840cff7a 100644
--- i/inary/system_literals/fstabutils.py
+++ w/inary/system_literals/fstabutils.py
@@ -93,13 +93,13 @@ class FstabEntry(object):
 
     def __str__(self):
         return """\
-fs_spec: %s
-fs_file: %s
-fs_vfstype: %s
-fs_mntopts: %s
-fs_freq: %s
-fs_passno: %s
-""" % (self.__fs_spec,
+fs_spec: {0}
+fs_file: {1}
+fs_vfstype: {2}
+fs_mntopts: {3}
+fs_freq: {4}
+fs_passno: {5}
+""".format(self.__fs_spec,
                     self.__fs_file,
                     self.__fs_vfstype,
                     self.__fs_mntopts,
diff --git i/inary/system_literals/grubutils.py w/inary/system_literals/grubutils.py
index 1c95a529..81ef93f8 100644
--- i/inary/system_literals/grubutils.py
+++ w/inary/system_literals/grubutils.py
@@ -24,9 +24,9 @@ class grubCommand:
 
     def __str__(self):
         if self.options:
-            return "%s %s %s" % (self.key, " ".join(self.options), self.value)
+            return "{0} {1} {2}" % (self.key, " ".join(self.options), self.value)
         else:
-            return "%s %s" % (self.key, self.value)
+            return "{0} {1}".format(self.key, self.value)
 
 class grubEntry:
     """Grub menu entry"""
@@ -61,7 +61,7 @@ class grubEntry:
 
     def __str__(self):
         conf = []
-        conf.append("title %s" % self.title)
+        conf.append("title {}".format(self.title))
         for command in self.commands:
             conf.append(str(command))
         return "\n".join(conf)
@@ -150,11 +150,11 @@ class grubConf:
         conf = []
         if self.header:
             for h in self.header:
-                conf.append("# %s" % h)
+                conf.append("# {}".format(h))
             conf.append("")
         if self.options:
             for key, value in list(self.options.items()):
-                line = "%s %s" % (key, value)
+                line = "{0} {1}".format(key, value)
                 conf.append(line)
             conf.append("")
         for index, entry in enumerate(self.entries):
@@ -186,7 +186,7 @@ class grubConf:
 
     def getAllOptions(self):
         """Returns all options."""
-        return ["%s %s" % (key, value) for key, value in list(self.options.items())]
+        return ["{0} {1}".format(key, value) for key, value in list(self.options.items())]
 
     def listEntries(self):
         """Returns a list of entries."""
diff --git i/inary/system_literals/iniutils.py w/inary/system_literals/iniutils.py
index 0acf6571..2595d642 100644
--- i/inary/system_literals/iniutils.py
+++ w/inary/system_literals/iniutils.py
@@ -34,7 +34,7 @@ class iniDB:
         try:
             self.cp.read(db_file)
         except:
-            print(("Network configuration file %s is corrupt" % db_file))
+            print(("Network configuration file {} is corrupt".format(db_file)))
         self.__unlock()
 
     def __writelock(self):
@@ -175,7 +175,7 @@ class iniParser:
                 self.__fixIniFile()
                 return []
             else:
-                raise iniParserError("File is corrupt: %s" % self.inifile)
+                raise iniParserError("File is corrupt: {}".format(self.inifile))
         return ini.sections()
 
     def getSection(self, section):
@@ -190,7 +190,7 @@ class iniParser:
                 self.__fixIniFile()
                 return {}
             else:
-                raise iniParserError("File is corrupt: %s" % self.inifile)
+                raise iniParserError("File is corrupt: {}".format(self.inifile))
         if section not in ini.sections():
             return {}
         dct = {}
@@ -211,7 +211,7 @@ class iniParser:
                 self.setSection(section, dct)
                 return
             else:
-                raise iniParserError("File is corrupt: %s" % self.inifile)
+                raise iniParserError("File is corrupt: {}".format(self.inifile))
         if section not in ini.sections():
             ini.add_section(section)
         for key, value in list(dct.items()):
@@ -234,7 +234,7 @@ class iniParser:
                 self.__fixIniFile()
                 return
             else:
-                raise iniParserError("File is corrupt: %s" % self.inifile)
+                raise iniParserError("File is corrupt: {}".format(self.inifile))
         ini.remove_section(section)
         self.__writeIni(ini)
         self.__unlock()
diff --git i/inary/system_literals/netutils.py w/inary/system_literals/netutils.py
index da305d7c..bc057eb0 100644
--- i/inary/system_literals/netutils.py
+++ w/inary/system_literals/netutils.py
@@ -115,7 +115,7 @@ def deviceName(devuid):
             data = "/usr/share/misc/pci.ids"
         else:
             data = "/usr/share/misc/usb.ids"
-        return idsQuery(data, vendor, device) + " (%s)" % dev
+        return idsQuery(data, vendor, device) + " ({})".format(dev)
     if devuid.startswith("logic:"):
         return devuid.split(":", 1)[1]
     return devuid
@@ -174,19 +174,19 @@ class NetworkInterfaces:
 
         modalias = self.sysValue("device/modalias")
         if not modalias:
-            return "logic:%s" % self.name
+            return "logic:{}".format(self.name)
         bustype, rest = modalias.split(":", 1)
 
         if bustype == "pci":
             vendor = remHex(self.sysValue("device/vendor"))
             device = remHex(self.sysValue("device/device"))
-            return "pci:%s_%s_%s" % (vendor, device, self.name)
+            return "pci:{0}_{1}_{2}".format(vendor, device, self.name)
 
         if bustype == "usb":
             path = os.path.join("/sys/class/net", self.name, "device/driver")
             for item in os.listdir(path):
                 if ":" in item:
-                    path2 = "device/bus/devices/%s" % item.split(":", 1)[0]
+                    path2 = "device/bus/devices/{}".format(item.split(":", 1)[0])
                     try:
                         vendor = remHex(self.sysValue(path2 + "/idVendor"))
                         device = remHex(self.sysValue(path2 + "/idProduct"))
@@ -197,9 +197,9 @@ class NetworkInterfaces:
                                 product = line.split("=")[1]
                         vendor = product.split("/")[0]
                         device = product.split("/")[1]
-                    return "usb:%s_%s_%s" % (vendor, device, self.name)
+                    return "usb:{0}_{1}_{2}".format(vendor, device, self.name)
 
-        return "%s:%s" % (bustype, self.name)
+        return "{0}:{1}".format(bustype, self.name)
 
     def isEthernet(self):
         nettype = self.sysValue("type")
@@ -303,7 +303,7 @@ class NetworkInterfaces:
 
     def startAuto(self):
         try:
-            os.unlink("/var/lib/dhcpcd/dhcpcd-%s.info" % self.name)
+            os.unlink("/var/lib/dhcpcd/dhcpcd-{}.info".format(self.name))
         except OSError:
             pass
 
@@ -320,14 +320,14 @@ class NetworkInterfaces:
         # dhcpcd does not create a pid file until it gets 
         # an ip address so dhcpcd -k does not work while cancelling
         if subprocess.call(["/sbin/dhcpcd", "-k", self.name], stderr=file("/dev/null")):
-            subprocess.call(["pkill","-f","%s" % " ".join(self.autoCmd)])
+            subprocess.call(["pkill","-f","{}".format(" ".join(self.autoCmd))])
 
     def isAuto(self):
-        path = "/var/run/dhcpcd-%s.pid" % self.name
+        path = "/var/run/dhcpcd-{}.pid".format(self.name)
         if not os.path.exists(path):
             return False
         pid = file(path).read().rstrip("\n")
-        if not os.path.exists("/proc/%s" % pid):
+        if not os.path.exists("/proc/{}".format(pid)):
             return False
         return True
 
@@ -413,9 +413,9 @@ class NetworkFilter:
             elif rule.startswith(':'):
                 chain, policy, counter = rule[1:].split()
                 if chain in chains[table]:
-                    rules[table].append('-P %s %s' % (chain, policy))
+                    rules[table].append('-P {0} {1}'.format(chain, policy))
                 else:
-                    rules[table].append('-N %s' % chain)
+                    rules[table].append('-N {}'.format(chain))
             elif rule.startswith('-A'):
                 rules[table].append(rule)
         return rules
@@ -427,7 +427,7 @@ class NetworkFilter:
         for table in rules_dict:
             if not len(rules_dict[table]):
                 continue
-            rules.append('*%s' % table)
+            rules.append('*{}'.format(table))
             for rule in rules_dict[table]:
                 rules.append(rule)
             rules.append('COMMIT')
@@ -467,7 +467,7 @@ class NetworkFilter:
         opts = ''
         if not flush:
             opts = '--noflush'
-        p = os.popen('/sbin/iptables-restore %s' % opts, 'w')
+        p = os.popen('/sbin/iptables-restore {}'.format(opts), 'w')
         p.write(rules)
         p.close()
  
@@ -484,9 +484,9 @@ class NetworkFilter:
         '''Resets iptables.'''
         for table in chains:
             # Flush rules
-            os.popen('/sbin/iptables -t %s -F' % table)
-            os.popen('/sbin/iptables -t %s -X' % table)
+            os.popen('/sbin/iptables -t {} -F'.format(table))
+            os.popen('/sbin/iptables -t {} -X'.format(table))
             # Reset policies
             for chain in chains[table]:
-                os.popen('/sbin/iptables -t %s -P %s ACCEPT' % (table, chain))
+                os.popen('/sbin/iptables -t {0} -P {1} ACCEPT'.format(table, chain))
 
diff --git i/inary/util.py w/inary/util.py
index ed24b394..46def41c 100644
--- i/inary/util.py
+++ w/inary/util.py
@@ -190,7 +190,7 @@ def run_batch(cmd, ui_debug=True):
     p = subprocess.Popen(cmd, shell=True,
                          stdout=subprocess.PIPE, stderr=subprocess.PIPE)
     out, err = p.communicate()
-    if ui_debug: ctx.ui.debug(_('return value for "%s" is %s') % (cmd, p.returncode))
+    if ui_debug: ctx.ui.debug(_('return value for "{0}" is {1}').format(cmd, p.returncode))
     return (p.returncode, out, err)
 
 # TODO: it might be worthwhile to try to remove the
@@ -216,7 +216,7 @@ def run_logged(cmd):
 
     p = subprocess.Popen(cmd, shell=True, stdout=stdout, stderr=stderr)
     out, err = p.communicate()
-    ctx.ui.debug(_('return value for "%s" is %s') % (cmd, p.returncode))
+    ctx.ui.debug(_('return value for "{0}" is {1}').format(cmd, p.returncode))
 
     return p.returncode
 
@@ -390,9 +390,9 @@ def calculate_hash(path):
         # For symlinks, path string is hashed instead of the content
         value = sha1_data(read_link(path))
         if not os.path.exists(path):
-            ctx.ui.info(_("Including external link '%s'") % path)
+            ctx.ui.info(_("Including external link '{}'").format(path))
     elif os.path.isdir(path):
-        ctx.ui.info(_("Including directory '%s'") % path)
+        ctx.ui.info(_("Including directory '{}'").format(path))
         value = None
     else:
         if path.endswith('.a'):
@@ -480,7 +480,7 @@ def sha1_file(filename):
             # Permission denied, the file doesn't have read permissions, skip
             raise FilePermissionDeniedError(_("You don't have necessary read permissions"))
         else:
-            raise FileError(_("Cannot calculate SHA1 hash of %s") % filename)
+            raise FileError(_("Cannot calculate SHA1 hash of {}").format(filename))
 
 def sha1_data(data):
     """Calculate sha1 hash of given data."""
@@ -492,13 +492,13 @@ def uncompress(patchFile, compressType="gz", targetDir=""):
     """Uncompress the file and return the new path."""
     formats = ("gz", "gzip", "bz2", "bzip2", "lzma", "xz")
     if compressType not in formats:
-        raise Error(_("Compression type is not valid: '%s'") % compressType)
+        raise Error(_("Compression type is not valid: '{}'").format(compressType))
 
     archive = inary.archive.Archive(patchFile, compressType)
     try:
         archive.unpack(targetDir)
     except Exception as msg:
-        raise Error(_("Error while decompressing %s: %s") % (patchFile, msg))
+        raise Error(_("Error while decompressing {0}: {1}").format(patchFile, msg))
 
     # FIXME: Get file path from Archive instance
     filePath = join_path(targetDir, os.path.basename(patchFile))
@@ -506,12 +506,12 @@ def uncompress(patchFile, compressType="gz", targetDir=""):
     # remove suffix from file cause its uncompressed now
     extensions = {"gzip": "gz", "bzip2": "bz2"}
     extension = extensions.get(compressType, compressType)
-    return filePath.split(".%s" % extension)[0]
+    return filePath.split(".{}".format(extension))[0]
 
 def check_patch_level(workdir, path):
     level = 0
     while path:
-        if os.path.isfile("%s/%s" % (workdir, path)): return level
+        if os.path.isfile("{0}/{1}".format(workdir, path)): return level
         if path.find("/") == -1: return None
         level += 1
         path = path[path.find("/")+1:]
@@ -522,7 +522,7 @@ def do_patch(sourceDir, patchFile, level=0, name=None, reverse=False):
     if os.path.exists(sourceDir):
         os.chdir(sourceDir)
     else:
-        raise Error(_("ERROR: WorkDir (%s) does not exist\n") % (sourceDir))
+        raise Error(_("ERROR: WorkDir ({}) does not exist\n").format(sourceDir))
 
     check_file(patchFile)
 
@@ -551,7 +551,7 @@ def do_patch(sourceDir, patchFile, level=0, name=None, reverse=False):
                     if level == None and len(paths_m) -1 == paths_m.index(path_m):
                         level = check_patch_level(sourceDir, path_m)
                     if not level == None:
-                        ctx.ui.debug("Detected patch level=%s for %s" % (level, os.path.basename(patchFile)))
+                        ctx.ui.debug("Detected patch level={0} for {1}".format(level, os.path.basename(patchFile)))
                         break
 
     if level == None:
@@ -566,55 +566,55 @@ def do_patch(sourceDir, patchFile, level=0, name=None, reverse=False):
         if not os.path.exists(patchesDir):
             os.makedirs(patchesDir)
         # Import original patch into quilt tree
-        (ret, out, err) = run_batch('quilt import %s -p %d -P %s \"%s\"' % (("-R" if reverse else ""), level, name, patchFile))
+        (ret, out, err) = run_batch('quilt import {0} -p {1} -P {2} \"{3}\"'.format(("-R" if reverse else ""), level, name, patchFile))
         # run quilt push to apply original patch into tree
         (ret, out, err) = run_batch('quilt push')
     else:
         # run GNU patch to apply original patch into tree
-        (ret, out, err) = run_batch("patch --remove-empty-files --no-backup-if-mismatch %s -p%d -i \"%s\"" % (("-R" if reverse else ""), level, patchFile))
+        (ret, out, err) = run_batch("patch --remove-empty-files --no-backup-if-mismatch {0} -p{1} -i \"{2}\"".format(("-R" if reverse else ""), level, patchFile))
 
     if ret:
         if out is None and err is None:
             # Which means stderr and stdout directed so they are None
-            raise Error(_("ERROR: patch (%s) failed") % (patchFile))
+            raise Error(_("ERROR: patch ({}) failed").format((patchFile)))
         else:
-            raise Error(_("ERROR: patch (%s) failed: %s") % (patchFile, out))
+            raise Error(_("ERROR: patch ({}) failed: {}").format(patchFile, out))
 
     os.chdir(cwd)
 
 def strip_file(filepath, fileinfo, outpath):
     """Strip an elf file from debug symbols."""
     def run_strip(f, flags=""):
-        p = os.popen("strip %s %s" %(flags, f))
+        p = os.popen("strip {0} {1}".format(flags, f))
         ret = p.close()
         if ret:
-            ctx.ui.warning(_("strip command failed for file '%s'!") % f)
+            ctx.ui.warning(_("strip command failed for file '{}'!").format(f))
 
     def run_chrpath(f):
         """ remove rpath info from binary """
-        p = os.popen("chrpath -d %s" % f)
+        p = os.popen("chrpath -d {}".format(f))
         ret = p.close()
         if ret:
-            ctx.ui.warning(_("chrpath command failed for file '%s'!") % f)
+            ctx.ui.warning(_("chrpath command failed for file '{}'!").format(f))
 
     def save_elf_debug(f, o):
         """copy debug info into file.debug file"""
-        p = os.popen("objcopy --only-keep-debug %s %s%s" % (f, o, ctx.const.debug_file_suffix))
+        p = os.popen("objcopy --only-keep-debug {0} {1}{2}".format(f, o, ctx.const.debug_file_suffix))
         ret = p.close()
         if ret:
-            ctx.ui.warning(_("objcopy (keep-debug) command failed for file '%s'!") % f)
+            ctx.ui.warning(_("objcopy (keep-debug) command failed for file '{}'!").format(f))
 
         """mark binary/shared objects to use file.debug"""
-        p = os.popen("objcopy --add-gnu-debuglink=%s%s %s" % (o, ctx.const.debug_file_suffix, f))
+        p = os.popen("objcopy --add-gnu-debuglink={0}{1} {2}".format(o, ctx.const.debug_file_suffix, f))
         ret = p.close()
         if ret:
-            ctx.ui.warning(_("objcopy (add-debuglink) command failed for file '%s'!") % f)
+            ctx.ui.warning(_("objcopy (add-debuglink) command failed for file '{}'!").format(f))
 
     if fileinfo == None:        
-        ret, out, err = run_batch("file %s" % filepath, ui_debug=False)
+        ret, out, err = run_batch("file {}".format(filepath), ui_debug=False)
         if ret:
-            ctx.ui.warning(_("file command failed with return code %s for file: %s") % (ret, filepath))
-            ctx.ui.info(_("Output:\n%s") % out, verbose=True)
+            ctx.ui.warning(_("file command failed with return code {0} for file: {1}") % (ret, filepath))
+            ctx.ui.info(_("Output:\n{}").format(out), verbose=True)
 
     elif "current ar archive" in fileinfo:
         run_strip(filepath, "--strip-debug")
@@ -704,14 +704,14 @@ def parse_package_name(package_name):
         try:
             return parse_package_name_legacy(package_name)
         except:
-            raise Error(_("Invalid package name: %s") % package_name)
+            raise Error(_("Invalid package name: {}").format(package_name))
 
-    return name, "%s-%s" % (version, release)
+    return name, "{}-{}".format(version, release)
 
 def parse_package_dir_path(package_name):
     name = parse_package_name(package_name)[0]
     if name.split("-").pop() in ["devel", "32bit", "doc", "docs", "userspace"]: name = name[:-1 - len(name.split("-").pop())]
-    return "%s/%s" % (name[0:4].lower() if name.startswith("lib") and len(name) > 3 else name.lower()[0], name.lower())
+    return "{}/{}".format(name[0:4].lower() if name.startswith("lib") and len(name) > 3 else name.lower()[0], name.lower())
 
 def parse_delta_package_name_legacy(package_name):
     """Separate delta package name and release infos for package formats <= 1.1.
@@ -749,7 +749,7 @@ def parse_delta_package_name(package_name):
         try:
             return parse_delta_package_name_legacy(package_name)
         except:
-            raise Error(_("Invalid delta package name: %s") % package_name)
+            raise Error(_("Invalid delta package name: {}").format(package_name))
 
     return name, source_release, target_release
 
@@ -880,7 +880,7 @@ def config_changed(config_file):
 # recursively remove empty dirs starting from dirpath
 def rmdirs(dirpath):
     if os.path.isdir(dirpath) and not os.listdir(dirpath):
-        ctx.ui.debug("Removing empty dir: %s" % dirpath)
+        ctx.ui.debug("Removing empty dir: {}".format(dirpath))
         os.rmdir(dirpath)
         rmdirs(os.path.dirname(dirpath))
 
diff --git i/inary/version.py w/inary/version.py
index 9625a821..2105c0ae 100644
--- i/inary/version.py
+++ w/inary/version.py
@@ -61,7 +61,7 @@ def make_version(version):
         return list(map(__make_version_item, ver.split("."))), 0, [(0, None)]
 
     except ValueError:
-        raise InvalidVersionError(_("Invalid version string: '%s'") % version)
+        raise InvalidVersionError(_("Invalid version string: '{}'").format(version))
 
 class Version(object):
 
diff --git i/setup.py w/setup.py
index 3f04a9eb..3ca265e3 100755
--- i/setup.py
+++ w/setup.py
@@ -57,7 +57,7 @@ class BuildPo(build):
 
         # Collect headers for mimetype files
         for filename in IN_FILES:
-            os.system("intltool-extract --type=gettext/xml %s" % filename)
+            os.system("intltool-extract --type=gettext/xml {}".format(filename))
 
         for root,dirs,filenames in os.walk("inary"):
             for filename in filenames:
@@ -71,16 +71,16 @@ class BuildPo(build):
 
         # Generate POT file
         os.system("xgettext -L Python \
-                            --default-domain=%s \
+                            --default-domain={0} \
                             --keyword=_ \
                             --keyword=N_ \
-                            --files-from=%s \
-                            -o po/%s.pot" % (PROJECT, files, PROJECT))
+                            --files-from={1} \
+                            -o po/{2}.pot".format(PROJECT, files, PROJECT))
 
         # Update PO files
         for item in glob.glob1("po", "*.po"):
             print("Updating .. ", item)
-            os.system("msgmerge --update --no-wrap --sort-by-file po/%s po/%s.pot" % (item, PROJECT))
+            os.system("msgmerge --update --no-wrap --sort-by-file po/{0} po/{1}.pot".format(item, PROJECT))
 
         # Cleanup
         os.unlink(files)
@@ -106,14 +106,14 @@ class Install(install):
 #            if not name.endswith('.po'):
 #                continue
 #            lang = name[:-3]
-#            print("Installing '%s' translations..." % lang)
-#            os.popen("msgfmt po/%s.po -o po/%s.mo" % (lang, lang))
+#            print("Installing '{}' translations...".format(lang))
+#            os.popen("msgfmt po/{0}.po -o po/{0}.mo".format(lang))
 #            if not self.root:
 ##                self.root = "/"
-##            destpath = os.path.join(self.root, "usr/share/locale/%s/LC_MESSAGES" % lang)
+##            destpath = os.path.join(self.root, "usr/share/locale/{}/LC_MESSAGES".format(lang))
 #            if not os.path.exists(destpath):
 #                os.makedirs(destpath)
-#            shutil.copy("po/%s.mo" % lang, os.path.join(destpath, "inary.mo"))
+#            shutil.copy("po/{}.mo".format(lang), os.path.join(destpath, "inary.mo"))
 
     def installdoc(self):
         self.root ='/'
@@ -143,7 +143,7 @@ class Install(install):
 
         for d in defaults:
             section_name = d[0][:-len('Defaults')].lower()
-            inaryconf.write("[%s]\n" % section_name)
+            inaryconf.write("[{}]\n".format(section_name))
 
             section_members = [m for m in inspect.getmembers(d[1]) \
                                if not m[0].startswith('__') \
@@ -151,9 +151,9 @@ class Install(install):
 
             for member in section_members:
                 if member[1] == None or member[1] == "":
-                    inaryconf.write("# %s = %s\n" % (member[0], member[1]))
+                    inaryconf.write("# {0[0]} = {0[1]}\n".format(member))
                 else:
-                    inaryconf.write("%s = %s\n" % (member[0], member[1]))
+                    inaryconf.write("{0[0]} = {0[1]}\n".format(member))
             inaryconf.write('\n')
 
 class Uninstall(Command):
